{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reshaping.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonioMarsella/website/blob/master/reshaping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "graT_YEsRdng",
        "colab_type": "code",
        "outputId": "ee25945f-529a-4dd3-d812-409a54962aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnPcO22UYyb",
        "colab_type": "code",
        "outputId": "b835fbcb-cf84-4f4b-db92-df46a89755b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Y_PEn8UZPT",
        "colab_type": "code",
        "outputId": "4e86bf4e-0202-4389-e9bf-2c585e519c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlg7kgnUgoz",
        "colab_type": "code",
        "outputId": "f80e1001-a54a-40ec-e03a-fcc08dbd3d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow_addons as tfa\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from dataloader2 import Dataset\n",
        "import numpy as np\n",
        "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
        "\n",
        "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khxZCRShUhCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_dict = {'IXMAS': { \n",
        "    'allocentric': {\n",
        "        'train':['cam0','cam1','cam2','cam3'],\n",
        "        'test':['cam4']},\n",
        "    'lateral': {\n",
        "        'train':['cam0','cam3'],\n",
        "        'test':['cam1','cam2','cam4']},\n",
        "    'simple': {\n",
        "        'train':['cam0','cam1','cam2'],\n",
        "        'test':['cam3']},\n",
        "    'crazy': {\n",
        "        'train':['cam0'],\n",
        "        'test':['cam4']}\n",
        "                        }\n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEdoJgkRU0-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Dataset(batch_size = 4, data_path_index= 1)\n",
        "dataset.load_dataset_paths()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7RauplGU26U",
        "colab_type": "code",
        "outputId": "a464d5d4-394a-44d1-b53d-1208532bf501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "dataset.crossview_split(split_dict['IXMAS']['allocentric'])\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training samples: 1056\n",
            "Validation samples: 264\n",
            "Test samples: 330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo4nobFdU6A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 11\n",
        "width, height = 7, 7\n",
        "num_channels = 1024\n",
        "input_shape = (8, width, height, num_channels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkir0oeqU79O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GradientReversalOperator(x):\n",
        "    def grad(dy):\n",
        "        #tf.print(tf.math.reduce_mean(dy))\n",
        "        return -1 * dy\n",
        "    return x, grad\n",
        "\n",
        "class GradientReversalLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(GradientReversalLayer, self).__init__()\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return GradientReversalOperator(inputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVuItpISU-Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout, Conv3D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "MAX_STEP = 10000\n",
        "\n",
        "log_format = 'L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n'+ \\\n",
        "    'L2 Test: {:.4f}, Acc2 Test: {:.2f}\\n'+ \\\n",
        "    'L3 Test: {:.4f}, Acc3 Test: {:.2f}\\n'\n",
        "\n",
        "log_format_source_only = 'L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n' + \\\n",
        "    'L1 Target_1: {:.4f}, Acc3 Target_1: {:.2f}\\n' + \\\n",
        "    'L1 Target_2: {:.4f}, Acc3 Target_2: {:.2f}\\n'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0kvxKxLVAx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InvertedLoss(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='InvertedLoss'):\n",
        "        super().__init__(reduction=reduction, name=name)\n",
        "    \n",
        "    @tf.function \n",
        "    def call(self, y_true, y_pred, lp_loss = 1):\n",
        "        standard_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "        #return tf.math.maximum(standard_loss(y_true, y_pred),tf.math.log(tf.divide(tf.constant(1.0, dtype = 'float32'),(standard_loss(y_true, y_pred)))))\n",
        "        #return tf.math.maximum(standard_loss(y_true, y_pred), tf.multiply(2.0, tf.math.exp(tf.multiply(-1.0, tf.math.square(standard_loss(y_true, y_pred))))))\n",
        "        return tf.multiply(1.0, tf.math.exp(tf.multiply(-1.0, tf.math.abs(standard_loss(y_true, y_pred)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9G-tt9HaNKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EuclideanDistanceLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    def __init__(self, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='EuclideanDistanceLoss'):\n",
        "        super().__init__(reduction=reduction, name=name)\n",
        "    def call(self, y_true, y_pred):\n",
        "      return 0.5 * tf.math.sqrt(tf.math.reduce_sum(tf.math.square(y_true - y_pred), axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYu1o6ahVDak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling3D, Flatten, Dense, Dropout, Conv3D, UpSampling3D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "MAX_STEP = 10000\n",
        "\n",
        "log_format = 'L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n'+ \\\n",
        "    'L2 Test: {:.4f}, Acc2 Test: {:.2f}\\n'+ \\\n",
        "    'L3 Test: {:.4f}, Acc3 Test: {:.2f}\\n'\n",
        "\n",
        "log_format_source_only = 'L1 Test: {:.4f}, Acc1 Test: {:.2f}\\n' + \\\n",
        "    'L1 Target_1: {:.4f}, Acc3 Target_1: {:.2f}\\n' + \\\n",
        "    'L1 Target_2: {:.4f}, Acc3 Target_2: {:.2f}\\n'\n",
        "\n",
        "\n",
        "\n",
        "class Upsample():\n",
        "    def __init__(self, input_shape = input_shape, run_name = 'multiclass', lr = [0.1, 0.1, 0.1], source_only=False, category = (None, None)):\n",
        "        super(Upsample, self).__init__()\n",
        "\n",
        "        self.downsample = Sequential([\n",
        "                                             \n",
        "            Conv3D(filters=104, kernel_size=[2,2,5], kernel_regularizer=l2(0.001), padding='same', input_shape=input_shape),\n",
        "            BatchNormalization(),\n",
        "            Activation('relu'),\n",
        "            MaxPooling3D([2,2,2]),\n",
        "            Conv3D(filters=52,kernel_size=[1,1,3], kernel_regularizer=l2(0.001), padding='same'),\n",
        "            Activation('relu'),\n",
        "            Conv3D(filters=26,kernel_size=[1,1,2], kernel_regularizer=l2(0.001), padding='same'),\n",
        "            Activation('relu')\n",
        "            ])\n",
        "        \n",
        "        self.upsample = Sequential([\n",
        "            UpSampling3D([2,2,2]), \n",
        "            BatchNormalization(),\n",
        "            Activation('tanh')                    \n",
        "        ])\n",
        "        self.label_predictor = Sequential([\n",
        "            Flatten(),\n",
        "            #Dense(128, activation='relu'),\n",
        "            #BatchNormalization(),\n",
        "            Dropout(0.5),\n",
        "            Dense(11, activation = None),\n",
        "            BatchNormalization(),\n",
        "            Activation('softmax')\n",
        "        ])\n",
        "            \n",
        "        self.feature_extractor = Sequential([\n",
        "            self.downsample,\n",
        "            self.upsample                       \n",
        "        ])\n",
        "\n",
        "        self.domain_classifier = Sequential([\n",
        "            GradientReversalLayer(),                                 \n",
        "            Conv3D(filters=104, kernel_size=[1,1,1], kernel_regularizer=l2(0.001), padding='same'),\n",
        "            Activation('relu'),\n",
        "            Flatten(),\n",
        "            #Dense(128, kernel_regularizer=l2(0.001)),\n",
        "            #BatchNormalization(),\n",
        "            Activation('relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(5, activation='softmax'),\n",
        "                    \n",
        "            ])\n",
        "        \n",
        "       # self.domain_classifier2 = Sequential([\n",
        "       #     GradientReversalLayer(),\n",
        "       #     Flatten(),\n",
        "       #     Dropout(0.5),\n",
        "       #     Dense(5, activation='softmax')\n",
        "       # ])\n",
        "        \n",
        "        self.predict_label = Sequential([\n",
        "            self.feature_extractor,\n",
        "            self.label_predictor\n",
        "            ])\n",
        "\n",
        "        self.classify_domain = Sequential([\n",
        "            self.downsample,\n",
        "            self.domain_classifier\n",
        "            ])\n",
        "        \n",
        "        #self.classify_domain2 = Sequential([\n",
        "        #    self.downsample,\n",
        "        #    self.domain_classifier2\n",
        "        #    ])\n",
        "        \n",
        "        \n",
        "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "        self.inv_loss = InvertedLoss()\n",
        "        self.lp_lr = lr[0]\n",
        "        self.dc_lr = lr[1]\n",
        "        self.fe_lr = lr[2]\n",
        "\n",
        "        # self.lp_optimizer = tf.keras.optimizers.Adam(learning_rate=lr[0])\n",
        "        # self.dc_optimizer = tf.keras.optimizers.Adam(learning_rate=lr[1])\n",
        "        # self.fe_optimizer = tf.keras.optimizers.Adam(learning_rate=lr[2]) #fe_lr=0.0005\n",
        "\n",
        "\n",
        "        self.lp_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lp_lr, decay=0.0005)\n",
        "        self.dc_optimizer = tf.keras.optimizers.Adam(learning_rate=self.dc_lr, decay=0.0002)\n",
        "        self.fe_optimizer = tf.keras.optimizers.Adam(learning_rate=self.fe_lr, decay = 0.0002) #fe_lr=0.0005\n",
        "\n",
        "        self.train_lp_loss = tf.keras.metrics.Mean()\n",
        "        self.train_dc_loss = tf.keras.metrics.Mean()\n",
        "        \n",
        "        self.train_lp_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.train_dc_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "        self.test_lp_loss = tf.keras.metrics.Mean()\n",
        "        self.test_dc_loss = tf.keras.metrics.Mean()\n",
        "        self.test_target_lp_loss = tf.keras.metrics.Mean()\n",
        "        self.test_target_standard_lp_loss = tf.keras.metrics.Mean()\n",
        "        self.test_lp_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.test_dc_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.test_target_lp_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.test_target_standard_lp_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.train_target_lp_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.euclidean_loss = EuclideanDistanceLoss()\n",
        "        if source_only:\n",
        "            self.target_accuracy_1 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "            self.target_accuracy_2 = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "            self.target_loss_1 = tf.keras.metrics.Mean()\n",
        "            self.target_loss_2 = tf.keras.metrics.Mean()\n",
        "\n",
        "        self.create_logger(run_name, source_only, category)\n",
        "    \n",
        "    @tf.function\n",
        "    def single_train(self, x_class, y_class, views_class, x_domain, views_domain, minimize_distance = False):\n",
        "        domain_labels = tf.concat([views_class, views_domain], axis = 0)\n",
        "        x_both = tf.concat([x_class, x_domain], axis = 0)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "          y_class_pred = self.predict_label(x_class, training=True)\n",
        "          lp_loss = tf.multiply(2.0, self.loss(y_class, y_class_pred))\n",
        "          tf.print('lp_loss', lp_loss)\n",
        "          lp_grad = tape.gradient(lp_loss, self.predict_label.trainable_variables)\n",
        "\n",
        "        #with tf.GradientTape() as tape:    \n",
        "        #  y_domain_pred = self.classify_domain(x_both, training=True)\n",
        "        #  inv_loss = self.inv_loss(domain_labels, y_domain_pred)\n",
        "        #  tf.print('inv_loss', inv_loss)\n",
        "        #  fe_grad = tape.gradient(inv_loss, self.classify_domain.trainable_variables)\n",
        "\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "          y_domain_pred = self.classify_domain(x_both, training=True)\n",
        "          dc_loss = self.loss(domain_labels, y_domain_pred)\n",
        "          \n",
        "          tf.print('dc_loss', dc_loss)\n",
        "          dc_grad = tape.gradient(dc_loss, self.domain_classifier.trainable_variables)\n",
        "          \n",
        "          fe_inv_grad = tape.gradient(dc_loss, self.classify_domain.trainable_variables)\n",
        "       \n",
        "        #with tf.GradientTape(persistent = True) as tape:\n",
        "        #  y_domain_pred2 = self.classify_domain2(x_both, training=True)\n",
        "        #  dc_loss2 = self.loss(domain_labels, y_domain_pred2)\n",
        "          \n",
        "        #  tf.print('dc_loss2', dc_loss2)\n",
        "        #  dc_grad2 = tape.gradient(dc_loss2, self.domain_classifier2.trainable_variables)\n",
        "        #  downsample2_grad = tape.gradient(dc_loss2, self.classify_domain2.trainable_variables)\n",
        "\n",
        "        self.lp_optimizer.apply_gradients(zip(lp_grad, self.predict_label.trainable_variables))\n",
        "        #self.fe_optimizer.apply_gradients(zip(fe_grad, self.classify_domain.trainable_variables))\n",
        "        self.dc_optimizer.apply_gradients(zip(dc_grad, self.domain_classifier.trainable_variables))\n",
        "        #self.dc_optimizer.apply_gradients(zip(dc_grad2, self.domain_classifier2.trainable_variables))\n",
        "        #self.dc_optimizer.apply_gradients(zip(dc_grad3, self.domain_classifier_features.trainable_variables))\n",
        "        #self.fe_optimizer.apply_gradients(zip(fe_grad, self.downsample.trainable_variables))\n",
        "        #self.fe_optimizer.apply_gradients(zip(downsample2_grad, self.downsample.trainable_variables))\n",
        "        #self.fe_optimizer.apply_gradients(zip(dc_features_grad, self.feature_extractor.trainable_variables))\n",
        "        self.fe_optimizer.apply_gradients(zip(fe_inv_grad, self.downsample.trainable_variables))\n",
        "\n",
        "        if minimize_distance:\n",
        "            with tf.GradientTape(persistent = True) as tape:\n",
        "                distance_loss = self.euclidean_loss(self.return_latent_variables(x_class), x_class) \n",
        "            distance_grad = tape.gradient(distance_loss, self.feature_extractor.trainable_variables)\n",
        "            self.fe_optimizer.apply_gradients(zip(distance_grad, self.feature_extractor.trainable_variables))\n",
        "            tf.print(distance_loss)\n",
        "        del tape\n",
        "\n",
        "        #self.train_lp_loss(lp_loss)\n",
        "        #self.train_lp_accuracy(y_class, y_class_pred)\n",
        "        \n",
        "        #self.train_dc_loss(dc_loss)\n",
        "        #self.train_dc_accuracy(domain_labels, y_domain_pred)\n",
        "\n",
        "        return\n",
        "\n",
        "    @tf.function\n",
        "    def test_target_test(self, x_domain, y_domain):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_target_class_pred = self.predict_label(x_domain, training=False)\n",
        "            target_lp_loss = self.loss(y_domain, y_target_class_pred)\n",
        "        \n",
        "        self.test_target_lp_loss(target_lp_loss)\n",
        "        self.test_target_lp_accuracy(y_domain, y_target_class_pred)\n",
        "\n",
        "        return\n",
        "    @tf.function\n",
        "    def test_target(self, x_domain, y_domain):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_target_class_pred = self.predict_label(x_domain, training=False)\n",
        "            target_lp_loss = self.loss(y_domain, y_target_class_pred)\n",
        "        \n",
        "        self.test_target_standard_lp_loss(target_lp_loss)\n",
        "        self.test_target_standard_lp_accuracy(y_domain, y_target_class_pred)\n",
        "\n",
        "        return\n",
        "\n",
        "    @tf.function\n",
        "    def test_source_only(self, x_domain, y_domain, domain_labels):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_target_class_pred = self.predict_label(x_domain, training=False)\n",
        "            target_lp_loss = self.loss(y_domain, y_target_class_pred)\n",
        "\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "              predicted_view = self.classify_domain(x_domain, training=False)\n",
        "              dc_loss = self.loss(domain_labels, predicted_view)\n",
        "\n",
        "        self.train_lp_loss(target_lp_loss)\n",
        "        self.train_lp_accuracy(y_domain, y_target_class_pred)  \n",
        "\n",
        "        self.train_dc_loss(dc_loss)\n",
        "        self.train_dc_accuracy(domain_labels, predicted_view)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def test_only(self, x_domain, y_domain, mode):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_target_class_pred = self.predict_label(x_domain, training=False)\n",
        "            target_lp_loss = self.loss(y_domain, y_target_class_pred)\n",
        "\n",
        "        if mode == 0:\n",
        "            self.test_lp_loss(target_lp_loss)\n",
        "            self.test_lp_accuracy(y_domain, y_target_class_pred)\n",
        "\n",
        "        if mode == 1:\n",
        "            self.target_loss_1(target_lp_loss)\n",
        "            self.target_accuracy_1(y_domain, y_target_class_pred)\n",
        "\n",
        "        elif mode == 2:\n",
        "            self.target_loss_2(target_lp_loss)\n",
        "            self.target_accuracy_2(y_domain, y_target_class_pred)\n",
        "\n",
        "        return\n",
        "\n",
        "                          \n",
        "    def return_latent_variables(self, x_domain):\n",
        "    \n",
        "        latent_variable = self.feature_extractor(x_domain, training=False)\n",
        "\n",
        "        return latent_variable\n",
        "        \n",
        "    def log(self):\n",
        "        message = log_format.format(\n",
        "                self.test_lp_loss.result(),\n",
        "                self.test_lp_accuracy.result()*100,\n",
        "                self.test_dc_loss.result(),\n",
        "                self.test_dc_accuracy.result()*100,\n",
        "                self.test_target_lp_loss.result(),\n",
        "                self.test_target_lp_accuracy.result()*100)\n",
        "        \n",
        "        with self.train_writer.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.train_lp_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            \n",
        "            tf.summary.scalar('label_prediction_accuracy', self.train_lp_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('label_prediction_accuracy - Source: ',self.train_lp_accuracy.result())\n",
        "            tf.summary.scalar('domain_classification_loss', self.train_dc_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('domain_classification_accuracy', self.train_dc_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('domain_classification_accuracy:', self.train_dc_accuracy.result())\n",
        "            \n",
        "        with self.test_writer.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.test_lp_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.test_lp_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('domain_classification_loss', self.test_dc_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('domain_classification_accuracy', self.test_dc_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('label_prediction_accuracy - Test:', self.test_lp_accuracy.result(), self.lp_optimizer.iterations)\n",
        "        \n",
        "        with self.target_writer.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.test_target_lp_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.test_target_lp_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('label_prediction_accuracy - Target Test:', self.test_target_lp_accuracy.result())\n",
        "            tf.print('label_prediction_accuracy - Target :', self.test_target_standard_lp_accuracy.result())\n",
        "        self.reset_metrics('train')\n",
        "        self.reset_metrics('test')\n",
        "\n",
        "        return message\n",
        "\n",
        "    def log_source_only(self):\n",
        "        message = log_format.format(\n",
        "            self.test_lp_loss.result(),\n",
        "            self.test_lp_accuracy.result()*100,\n",
        "            self.target_loss_1.result(),\n",
        "            self.target_accuracy_1.result()*100,\n",
        "            self.target_loss_2.result(),\n",
        "            self.target_accuracy_2.result()*100)\n",
        "\n",
        "        with self.train_writer.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.train_lp_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.train_lp_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('label_prediction_accuracy - Train Only', self.train_lp_accuracy.result())\n",
        "        with self.test_writer.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.test_lp_loss.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.test_lp_accuracy.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.print('label_prediction_accuracy', self.test_lp_accuracy.result())\n",
        "        with self.target_writer_1.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.target_loss_1.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.target_accuracy_1.result(), step=self.lp_optimizer.iterations)\n",
        "\n",
        "        with self.target_writer_2.as_default():\n",
        "            tf.summary.scalar('label_prediction_loss', self.target_loss_2.result(), step=self.lp_optimizer.iterations)\n",
        "            tf.summary.scalar('label_prediction_accuracy', self.target_accuracy_2.result(), step=self.lp_optimizer.iterations)\n",
        "\n",
        "        self.reset_metrics('source_only')\n",
        "\n",
        "        return message\n",
        "\n",
        "    def create_logger(self, run_name, source_only, category):\n",
        "        if os.path.isdir(\"../log/{}\".format(run_name)):\n",
        "            for i in range(99):\n",
        "                if not os.path.isdir(\"../log/{}_{}\".format(run_name, i)):\n",
        "                    run_name = '{}_{}'.format(run_name, i)\n",
        "                    break\n",
        "\n",
        "        run_dir = \"../log/{}\".format(run_name)\n",
        "        train_dir = \"../log/{}/train\".format(run_name)\n",
        "        test_dir = \"../log/{}/test\".format(run_name)\n",
        "        os.mkdir(run_dir)\n",
        "        os.mkdir(train_dir)\n",
        "        os.mkdir(test_dir)\n",
        "\n",
        "        self.train_writer = tf.summary.create_file_writer(train_dir)\n",
        "        self.test_writer = tf.summary.create_file_writer(test_dir)\n",
        "\n",
        "        if source_only:\n",
        "            target_dir_1 = \"../log/{}/target_{}\".format(run_name, category[0])\n",
        "            target_dir_2 = \"../log/{}/target_{}\".format(run_name, category[1])\n",
        "            os.mkdir(target_dir_1)\n",
        "            os.mkdir(target_dir_2)\n",
        "            self.target_writer_1 = tf.summary.create_file_writer(target_dir_1)\n",
        "            self.target_writer_2 = tf.summary.create_file_writer(target_dir_2)\n",
        "\n",
        "        else:\n",
        "            target_dir = \"../log/{}/target\".format(run_name)\n",
        "            os.mkdir(target_dir)\n",
        "            self.target_writer = tf.summary.create_file_writer(target_dir)\n",
        "\n",
        "        print(\"Log folder created as {}\".format(run_dir))\n",
        "\n",
        "        return\n",
        "\n",
        "    def reset_metrics(self, target):\n",
        "\n",
        "        if target == 'train':\n",
        "            self.train_lp_loss.reset_states()\n",
        "            self.train_lp_accuracy.reset_states()\n",
        "            self.train_dc_loss.reset_states()\n",
        "            self.train_dc_accuracy.reset_states()\n",
        "\n",
        "        if target == 'test':\n",
        "            self.test_lp_loss.reset_states()\n",
        "            self.test_lp_accuracy.reset_states()\n",
        "            self.test_dc_loss.reset_states()\n",
        "            self.test_dc_accuracy.reset_states()\n",
        "            self.test_target_lp_loss.reset_states()\n",
        "            self.test_target_lp_accuracy.reset_states()\t\n",
        "\n",
        "        elif target == 'source_only':\n",
        "            self.train_lp_loss.reset_states()\n",
        "            self.train_lp_accuracy.reset_states()\n",
        "            self.test_lp_loss.reset_states()\n",
        "            self.test_lp_accuracy.reset_states()\n",
        "            self.target_loss_1.reset_states()\n",
        "            self.target_accuracy_1.reset_states()\n",
        "            self.target_loss_2.reset_states()\n",
        "            self.target_accuracy_2.reset_states()\n",
        "\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS-pU5mGZyrX",
        "colab_type": "code",
        "outputId": "4f074ed9-b38f-4c66-d4fd-91b05a9af04f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "upsampling = Upsample(lr = [0.0001, 0.0001, 0.0001], run_name = '0.0001-0.0001-0.0001-huge-batchsize5')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log folder created as ../log/0.0001-0.0001-0.0001-huge-batchsize5_23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAQ4abg3SVrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class Gen:\n",
        "  def __init__(self,x,y,v, epochs = 10):\n",
        "    self.xyv = iter(list(zip(x,y,v)))\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.v = v\n",
        "    self.epochs = epochs\n",
        "    self.epoch = 1\n",
        "  def __call__(self):\n",
        "    while self.epoch < self.epochs:\n",
        "      try: \n",
        "        yield next(self.xyv)\n",
        "      except StopIteration:\n",
        "        #break\n",
        "        self.epoch += 1\n",
        "        to_shuffle = list(zip(self.x,self.y,self.v))\n",
        "        random.shuffle(to_shuffle)\n",
        "        self.xyv = iter(to_shuffle)\n",
        "\n",
        "def train_upsample_loading(model, dataset, x_class = None, y_class = None, x_domain = None, batch_size = None, epochs = 10, loading = True, SOURCE = True, TEST = True, TARGET = True):\n",
        "\n",
        "        if batch_size == None:\n",
        "            batch_size = dataset.batch_size\n",
        "        if loading:\n",
        "            source = dataset.source_paths\n",
        "            size_source = len(source)\n",
        "            print('Source size:', size_source)\n",
        "          \n",
        "            source = tf.data.Dataset.from_tensor_slices((source))\n",
        "            source = list(source)\n",
        "            if len(dataset.x_train) == 0: \n",
        "              dataset.loading_batches(batch = source, source = True, batch_size = size_source)\n",
        "            source = tf.data.Dataset.from_generator(Gen(dataset.x_train, dataset.y_train, dataset.view_train, epochs = epochs),  (tf.float32, tf.int64, tf.int64))\n",
        "            source = source.batch(batch_size)\n",
        "        \n",
        "        if TEST:\n",
        "            test = dataset.test_paths\n",
        "            size_test = len(test)\n",
        "            print('Test size:', size_test)\n",
        "            test = tf.data.Dataset.from_tensor_slices((test))\n",
        "            test = test.shuffle(size_test, reshuffle_each_iteration=True)\n",
        "            test = list(test)\n",
        "\n",
        "            \n",
        "        if TARGET:\n",
        "            size = int(len(dataset.target_paths)/2)\n",
        "            target = dataset.target_paths[:size]\n",
        "            target_test = dataset.target_paths[size:]\n",
        "            size_target = len(target)\n",
        "            size_target_test = len(target_test)\n",
        "            print('Target size:', size_target)\n",
        "            print('Target_test size:', size_target_test)\n",
        "            target_test = tf.data.Dataset.from_tensor_slices((target_test))\n",
        "            target_test = target_test.shuffle(size_target_test, reshuffle_each_iteration=True)\n",
        "            target_test = list(target_test)\n",
        "            target = tf.data.Dataset.from_tensor_slices((target))\n",
        "            target = list(target)\n",
        "            if len(dataset.x_test) == 0:\n",
        "              dataset.loading_batches(batch = target, target = True, batch_size = size_target)\n",
        "            target = tf.data.Dataset.from_generator(Gen(dataset.x_test, dataset.y_test, dataset.view_test, epochs = epochs),  (tf.float32, tf.int64, tf.int64))\n",
        "            target = target.batch(1) \n",
        "\n",
        "        if len(dataset.x_val) == 0:\n",
        "          dataset.loading_batches(batch = test, test = True, batch_size = size_test)\n",
        "        if len(dataset.x_target_test) == 0:\n",
        "          dataset.loading_batches(batch = target_test, target_test = True, batch_size = size_target_test)\n",
        "        x_target_test, y_target_test = dataset.x_target_test, dataset.y_target_test\n",
        "        counter = 0\n",
        "        epoch = 0\n",
        "        print(datetime.datetime.now())\n",
        "        print('Beginning of epoch:', epoch + 1)\n",
        "        for (batch, batch_target) in zip(source,target):\n",
        "            counter += 1\n",
        "            if np.floor(counter * batch_size / size_source) > epoch:\n",
        "                print(datetime.datetime.now())\n",
        "                epoch = np.floor(counter * batch_size / size_source)\n",
        "             \n",
        "                tf.print('testing')\n",
        "                \n",
        "\n",
        "                \n",
        "                model.test_source_only(dataset.x_train, dataset.y_train, dataset.view_train)\n",
        "                model.test_only(dataset.x_val, dataset.y_val, mode = 0)\n",
        "                model.test_target_test(x_target_test,y_target_test)\n",
        "                model.test_target(dataset.x_test,dataset.y_test)\n",
        "                model.log()\n",
        "                    \n",
        "                \n",
        "                print('Beginning of epoch:', int(epoch + 1)) \n",
        "            x_class, y_class, x_domain, views_class, views_domain = batch[0], batch[1], batch_target[0], batch[2], batch_target[2]\n",
        "            \n",
        "               \n",
        "            model.single_train(x_class, y_class, views_class, x_domain, views_domain, minimize_distance = False)\n",
        "            \n",
        "            #if (counter % 10) == 0:\n",
        "            #    model.log()\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfWlzyU9Ythy",
        "colab_type": "code",
        "outputId": "261f4ca4-c7be-4baa-e8e7-934a70966f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_upsample_loading(upsampling, dataset, epochs =10)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source size: 1056\n",
            "Test size: 264\n",
            "Target size: 165\n",
            "Target_test size: 165\n",
            "2020-02-06 18:08:07.363161\n",
            "Beginning of epoch: 1\n",
            "lp_loss 3.49946761\n",
            "dc_loss 39.0641556\n",
            "lp_loss 2.54713058\n",
            "dc_loss 40.2730484\n",
            "lp_loss 3.62689209\n",
            "dc_loss 18.3539848\n",
            "lp_loss 3.15368629\n",
            "dc_loss 16.8620796\n",
            "lp_loss 2.62905574\n",
            "dc_loss 37.8601608\n",
            "lp_loss 3.11778879\n",
            "dc_loss 35.8976135\n",
            "lp_loss 3.06702876\n",
            "dc_loss 32.2674561\n",
            "lp_loss 3.26675606\n",
            "dc_loss 27.3756351\n",
            "lp_loss 2.5071702\n",
            "dc_loss 14.2174015\n",
            "lp_loss 3.24115157\n",
            "dc_loss 21.9157524\n",
            "lp_loss 2.46361685\n",
            "dc_loss 24.6340275\n",
            "lp_loss 4.00801659\n",
            "dc_loss 32.4018478\n",
            "lp_loss 3.43130922\n",
            "dc_loss 27.5224609\n",
            "lp_loss 3.84101033\n",
            "dc_loss 33.6922\n",
            "lp_loss 3.62832689\n",
            "dc_loss 47.8782082\n",
            "lp_loss 3.47401285\n",
            "dc_loss 34.5629158\n",
            "lp_loss 3.14904118\n",
            "dc_loss 42.1697\n",
            "lp_loss 3.28364301\n",
            "dc_loss 34.2444229\n",
            "lp_loss 3.75248075\n",
            "dc_loss 13.5921221\n",
            "lp_loss 2.95999098\n",
            "dc_loss 13.716116\n",
            "lp_loss 3.07089233\n",
            "dc_loss 16.4748516\n",
            "lp_loss 3.2929554\n",
            "dc_loss 54.5098457\n",
            "lp_loss 2.58272076\n",
            "dc_loss 20.4570713\n",
            "lp_loss 3.06955242\n",
            "dc_loss 27.5385246\n",
            "lp_loss 2.46456957\n",
            "dc_loss 25.4850159\n",
            "lp_loss 3.80512786\n",
            "dc_loss 37.2226677\n",
            "lp_loss 3.17059851\n",
            "dc_loss 17.1097603\n",
            "lp_loss 3.50084281\n",
            "dc_loss 16.3589592\n",
            "lp_loss 2.5922482\n",
            "dc_loss 34.2435684\n",
            "lp_loss 3.72070694\n",
            "dc_loss 7.25743198\n",
            "lp_loss 3.22802925\n",
            "dc_loss 38.7647896\n",
            "lp_loss 3.12870717\n",
            "dc_loss 43.7934799\n",
            "lp_loss 3.738729\n",
            "dc_loss 14.9860706\n",
            "lp_loss 3.0559535\n",
            "dc_loss 44.5014229\n",
            "lp_loss 3.05742931\n",
            "dc_loss 23.9917793\n",
            "lp_loss 2.87168455\n",
            "dc_loss 21.8666344\n",
            "lp_loss 3.44066238\n",
            "dc_loss 32.5084114\n",
            "lp_loss 2.96701813\n",
            "dc_loss 38.428463\n",
            "lp_loss 2.67464876\n",
            "dc_loss 26.3178215\n",
            "lp_loss 3.07135\n",
            "dc_loss 41.1671524\n",
            "lp_loss 2.83693504\n",
            "dc_loss 45.3598328\n",
            "lp_loss 3.14554429\n",
            "dc_loss 22.2548542\n",
            "lp_loss 3.28844786\n",
            "dc_loss 22.4168\n",
            "lp_loss 4.52233601\n",
            "dc_loss 38.1904221\n",
            "lp_loss 3.71491909\n",
            "dc_loss 24.7780399\n",
            "lp_loss 3.64723659\n",
            "dc_loss 40.9251938\n",
            "lp_loss 2.44750071\n",
            "dc_loss 47.5357475\n",
            "lp_loss 4.5258441\n",
            "dc_loss 26.5671806\n",
            "lp_loss 3.25123501\n",
            "dc_loss 46.9728775\n",
            "lp_loss 3.99586582\n",
            "dc_loss 29.3013039\n",
            "lp_loss 3.55905437\n",
            "dc_loss 25.2263451\n",
            "lp_loss 2.43312168\n",
            "dc_loss 22.3292656\n",
            "lp_loss 3.52551246\n",
            "dc_loss 38.9471512\n",
            "lp_loss 2.63338614\n",
            "dc_loss 22.4755058\n",
            "lp_loss 3.3994503\n",
            "dc_loss 47.0843658\n",
            "lp_loss 3.40348101\n",
            "dc_loss 19.9078846\n",
            "lp_loss 2.65631485\n",
            "dc_loss 45.0409584\n",
            "lp_loss 3.46931052\n",
            "dc_loss 43.3471718\n",
            "lp_loss 3.31051779\n",
            "dc_loss 30.9764709\n",
            "lp_loss 3.5929141\n",
            "dc_loss 41.5951958\n",
            "lp_loss 2.80963588\n",
            "dc_loss 17.128231\n",
            "lp_loss 2.76253343\n",
            "dc_loss 26.725769\n",
            "lp_loss 2.51276827\n",
            "dc_loss 34.9799728\n",
            "lp_loss 2.82238436\n",
            "dc_loss 14.8683729\n",
            "lp_loss 3.01849103\n",
            "dc_loss 22.671133\n",
            "lp_loss 3.34888339\n",
            "dc_loss 10.3146\n",
            "lp_loss 3.55869102\n",
            "dc_loss 37.0040779\n",
            "lp_loss 3.29790568\n",
            "dc_loss 27.5343437\n",
            "lp_loss 3.10076547\n",
            "dc_loss 47.3875694\n",
            "lp_loss 2.58327103\n",
            "dc_loss 22.5654259\n",
            "lp_loss 2.67799258\n",
            "dc_loss 53.1452026\n",
            "lp_loss 4.08300781\n",
            "dc_loss 59.9172668\n",
            "lp_loss 3.06312561\n",
            "dc_loss 59.8503952\n",
            "lp_loss 3.16798735\n",
            "dc_loss 25.0895233\n",
            "lp_loss 3.23983455\n",
            "dc_loss 37.7191162\n",
            "lp_loss 4.77471924\n",
            "dc_loss 19.074398\n",
            "lp_loss 3.80401611\n",
            "dc_loss 52.2772522\n",
            "lp_loss 3.18519163\n",
            "dc_loss 42.5676651\n",
            "lp_loss 4.01197767\n",
            "dc_loss 53.9119492\n",
            "lp_loss 2.43634748\n",
            "dc_loss 40.5662651\n",
            "lp_loss 2.58220506\n",
            "dc_loss 19.748745\n",
            "lp_loss 3.71218276\n",
            "dc_loss 49.8668404\n",
            "lp_loss 4.7777276\n",
            "dc_loss 42.7942924\n",
            "lp_loss 2.86030602\n",
            "dc_loss 47.2791214\n",
            "lp_loss 2.56376314\n",
            "dc_loss 22.7879601\n",
            "lp_loss 3.20445538\n",
            "dc_loss 25.8283596\n",
            "lp_loss 2.73877621\n",
            "dc_loss 27.7050076\n",
            "lp_loss 3.04420018\n",
            "dc_loss 71.731369\n",
            "lp_loss 3.12398577\n",
            "dc_loss 45.8643646\n",
            "lp_loss 2.69734454\n",
            "dc_loss 30.6954899\n",
            "lp_loss 3.28192139\n",
            "dc_loss 35.6802902\n",
            "lp_loss 2.39543819\n",
            "dc_loss 6.0399847\n",
            "lp_loss 3.02253699\n",
            "dc_loss 17.998867\n",
            "lp_loss 2.94082475\n",
            "dc_loss 18.4534664\n",
            "lp_loss 2.54345083\n",
            "dc_loss 50.0709763\n",
            "lp_loss 4.28487492\n",
            "dc_loss 15.6372986\n",
            "lp_loss 2.63768888\n",
            "dc_loss 38.0900955\n",
            "lp_loss 3.08793902\n",
            "dc_loss 30.7455559\n",
            "lp_loss 3.82924938\n",
            "dc_loss 34.5947075\n",
            "lp_loss 2.4140048\n",
            "dc_loss 27.7398376\n",
            "lp_loss 3.1978395\n",
            "dc_loss 27.5675659\n",
            "lp_loss 2.52679062\n",
            "dc_loss 28.9622765\n",
            "lp_loss 3.96101308\n",
            "dc_loss 10.4543638\n",
            "lp_loss 3.29374552\n",
            "dc_loss 28.5366879\n",
            "lp_loss 2.98150396\n",
            "dc_loss 15.8785706\n",
            "lp_loss 2.90159798\n",
            "dc_loss 24.4428062\n",
            "lp_loss 2.89039445\n",
            "dc_loss 25.1019344\n",
            "lp_loss 2.53708243\n",
            "dc_loss 38.8086777\n",
            "lp_loss 3.23364639\n",
            "dc_loss 30.0562248\n",
            "lp_loss 2.66305089\n",
            "dc_loss 41.2650871\n",
            "lp_loss 3.13287401\n",
            "dc_loss 27.5718193\n",
            "lp_loss 2.91298628\n",
            "dc_loss 22.2927914\n",
            "lp_loss 3.08682752\n",
            "dc_loss 26.1148224\n",
            "lp_loss 3.31635499\n",
            "dc_loss 26.3221931\n",
            "lp_loss 2.60514593\n",
            "dc_loss 37.4606934\n",
            "lp_loss 2.76889586\n",
            "dc_loss 32.9816322\n",
            "lp_loss 2.37978292\n",
            "dc_loss 41.8183899\n",
            "lp_loss 2.53913951\n",
            "dc_loss 27.0844269\n",
            "lp_loss 3.34110641\n",
            "dc_loss 51.0676804\n",
            "lp_loss 3.69777799\n",
            "dc_loss 32.2084351\n",
            "lp_loss 3.10729957\n",
            "dc_loss 27.8077602\n",
            "lp_loss 3.09000349\n",
            "dc_loss 43.974762\n",
            "lp_loss 3.50033236\n",
            "dc_loss 24.978344\n",
            "lp_loss 2.48023081\n",
            "dc_loss 37.9371567\n",
            "lp_loss 3.14531231\n",
            "dc_loss 31.4607849\n",
            "lp_loss 2.87313795\n",
            "dc_loss 38.5272827\n",
            "lp_loss 3.40616846\n",
            "dc_loss 63.6965256\n",
            "lp_loss 4.55147076\n",
            "dc_loss 46.7181511\n",
            "lp_loss 3.16207075\n",
            "dc_loss 53.1734123\n",
            "lp_loss 3.3794384\n",
            "dc_loss 21.330761\n",
            "lp_loss 4.41448545\n",
            "dc_loss 42.8840866\n",
            "lp_loss 3.37798834\n",
            "dc_loss 13.9034472\n",
            "lp_loss 2.59968662\n",
            "dc_loss 23.389431\n",
            "lp_loss 2.35132575\n",
            "dc_loss 17.8818169\n",
            "lp_loss 3.900913\n",
            "dc_loss 36.4639816\n",
            "lp_loss 3.17135096\n",
            "dc_loss 40.1656265\n",
            "lp_loss 3.15524\n",
            "dc_loss 32.1981239\n",
            "lp_loss 3.99977255\n",
            "dc_loss 35.9136429\n",
            "lp_loss 2.28412294\n",
            "dc_loss 25.1234398\n",
            "lp_loss 3.4366672\n",
            "dc_loss 13.6471786\n",
            "lp_loss 3.40610123\n",
            "dc_loss 15.3233519\n",
            "lp_loss 2.58917093\n",
            "dc_loss 60.5828934\n",
            "lp_loss 2.77445269\n",
            "dc_loss 41.0350456\n",
            "lp_loss 2.78906655\n",
            "dc_loss 23.8088875\n",
            "lp_loss 4.33586073\n",
            "dc_loss 27.1822548\n",
            "lp_loss 3.13124609\n",
            "dc_loss 19.6584911\n",
            "lp_loss 2.63524914\n",
            "dc_loss 43.650959\n",
            "lp_loss 3.76924396\n",
            "dc_loss 43.0127449\n",
            "lp_loss 3.60148954\n",
            "dc_loss 37.2355728\n",
            "lp_loss 3.6560359\n",
            "dc_loss 25.960186\n",
            "lp_loss 2.85256672\n",
            "dc_loss 22.8665428\n",
            "lp_loss 2.34363985\n",
            "dc_loss 31.556591\n",
            "lp_loss 2.80409718\n",
            "dc_loss 27.9145412\n",
            "lp_loss 3.3194778\n",
            "dc_loss 31.3151093\n",
            "lp_loss 2.55238295\n",
            "dc_loss 32.9500237\n",
            "lp_loss 2.98520088\n",
            "dc_loss 40.5238342\n",
            "lp_loss 3.43206215\n",
            "dc_loss 20.7875881\n",
            "lp_loss 2.85880303\n",
            "dc_loss 39.8511429\n",
            "lp_loss 3.31354904\n",
            "dc_loss 30.2604313\n",
            "lp_loss 2.43261337\n",
            "dc_loss 18.4399357\n",
            "lp_loss 2.489568\n",
            "dc_loss 28.505579\n",
            "lp_loss 3.23145866\n",
            "dc_loss 31.0098667\n",
            "lp_loss 2.87161303\n",
            "dc_loss 16.2468987\n",
            "lp_loss 3.21572518\n",
            "dc_loss 39.1893959\n",
            "lp_loss 3.35875893\n",
            "dc_loss 35.9514122\n",
            "lp_loss 3.25939822\n",
            "dc_loss 41.3726082\n",
            "lp_loss 3.10084581\n",
            "dc_loss 36.9345284\n",
            "lp_loss 3.0636313\n",
            "dc_loss 36.1884155\n",
            "lp_loss 2.688905\n",
            "dc_loss 41.8416252\n",
            "lp_loss 4.10856104\n",
            "dc_loss 14.2301731\n",
            "lp_loss 3.71591282\n",
            "dc_loss 40.9048233\n",
            "lp_loss 3.23657227\n",
            "dc_loss 38.0109558\n",
            "lp_loss 2.79429317\n",
            "dc_loss 11.4879656\n",
            "lp_loss 3.51241827\n",
            "dc_loss 26.3121529\n",
            "lp_loss 3.18844509\n",
            "dc_loss 16.7730598\n",
            "lp_loss 2.86752272\n",
            "dc_loss 24.9603214\n",
            "lp_loss 3.20999837\n",
            "dc_loss 18.3406372\n",
            "lp_loss 2.55619717\n",
            "dc_loss 32.1593933\n",
            "lp_loss 3.34828901\n",
            "dc_loss 41.866\n",
            "lp_loss 2.37546825\n",
            "dc_loss 29.178463\n",
            "lp_loss 2.99823523\n",
            "dc_loss 31.6703796\n",
            "lp_loss 2.98942661\n",
            "dc_loss 13.7654972\n",
            "lp_loss 3.16144848\n",
            "dc_loss 28.7777767\n",
            "lp_loss 3.03318596\n",
            "dc_loss 47.6110764\n",
            "lp_loss 3.05526972\n",
            "dc_loss 59.4639702\n",
            "lp_loss 3.67771387\n",
            "dc_loss 31.602726\n",
            "lp_loss 3.12952805\n",
            "dc_loss 15.2660313\n",
            "lp_loss 2.46462488\n",
            "dc_loss 44.470665\n",
            "lp_loss 2.61247206\n",
            "dc_loss 15.1659718\n",
            "lp_loss 3.47589278\n",
            "dc_loss 39.6466599\n",
            "lp_loss 2.9565115\n",
            "dc_loss 4.08426523\n",
            "lp_loss 3.85339308\n",
            "dc_loss 24.3020687\n",
            "lp_loss 3.72829676\n",
            "dc_loss 23.8190346\n",
            "lp_loss 3.46332121\n",
            "dc_loss 27.532135\n",
            "lp_loss 3.00956511\n",
            "dc_loss 29.0508461\n",
            "lp_loss 2.61471224\n",
            "dc_loss 29.1527519\n",
            "lp_loss 2.48572755\n",
            "dc_loss 33.6648331\n",
            "lp_loss 2.70067787\n",
            "dc_loss 27.3626671\n",
            "lp_loss 3.6507287\n",
            "dc_loss 6.48473\n",
            "lp_loss 3.53774381\n",
            "dc_loss 35.7048874\n",
            "lp_loss 2.78594947\n",
            "dc_loss 33.3008804\n",
            "lp_loss 3.50852156\n",
            "dc_loss 25.2238731\n",
            "lp_loss 2.78330946\n",
            "dc_loss 17.4290142\n",
            "lp_loss 2.51483917\n",
            "dc_loss 47.952404\n",
            "lp_loss 2.74810219\n",
            "dc_loss 20.2177563\n",
            "lp_loss 3.0641706\n",
            "dc_loss 15.7183895\n",
            "lp_loss 2.96198606\n",
            "dc_loss 43.9878044\n",
            "lp_loss 2.37114549\n",
            "dc_loss 33.8130722\n",
            "lp_loss 2.78646469\n",
            "dc_loss 45.2458382\n",
            "lp_loss 2.82961798\n",
            "dc_loss 38.0579224\n",
            "lp_loss 3.02326\n",
            "dc_loss 34.6588173\n",
            "lp_loss 3.30414772\n",
            "dc_loss 29.7762241\n",
            "lp_loss 2.78330803\n",
            "dc_loss 35.33004\n",
            "lp_loss 3.60358024\n",
            "dc_loss 49.8077774\n",
            "lp_loss 3.02490807\n",
            "dc_loss 36.5103531\n",
            "lp_loss 2.51146984\n",
            "dc_loss 31.463232\n",
            "lp_loss 2.37431908\n",
            "dc_loss 32.7194595\n",
            "lp_loss 2.80854559\n",
            "dc_loss 38.1932831\n",
            "lp_loss 3.966887\n",
            "dc_loss 31.6986427\n",
            "lp_loss 3.38975286\n",
            "dc_loss 33.4805\n",
            "lp_loss 2.86062193\n",
            "dc_loss 16.3639717\n",
            "lp_loss 2.68277407\n",
            "dc_loss 30.6326637\n",
            "lp_loss 2.814327\n",
            "dc_loss 43.4190598\n",
            "lp_loss 4.12000847\n",
            "dc_loss 20.637598\n",
            "lp_loss 2.4803133\n",
            "dc_loss 28.1599922\n",
            "lp_loss 2.69365644\n",
            "dc_loss 51.2123184\n",
            "lp_loss 3.10980606\n",
            "dc_loss 11.3314438\n",
            "lp_loss 2.38689494\n",
            "dc_loss 31.7148705\n",
            "lp_loss 3.28934336\n",
            "dc_loss 53.6918449\n",
            "lp_loss 3.72400141\n",
            "dc_loss 38.9653893\n",
            "lp_loss 2.72058129\n",
            "dc_loss 29.9046364\n",
            "lp_loss 3.1803894\n",
            "dc_loss 17.206974\n",
            "lp_loss 2.58145928\n",
            "dc_loss 29.7966461\n",
            "lp_loss 3.08967638\n",
            "dc_loss 67.8416367\n",
            "lp_loss 3.41988897\n",
            "dc_loss 34.832695\n",
            "lp_loss 3.64455867\n",
            "dc_loss 32.771\n",
            "lp_loss 3.61481047\n",
            "dc_loss 27.1088619\n",
            "lp_loss 3.46289277\n",
            "dc_loss 51.6417847\n",
            "lp_loss 3.90312457\n",
            "dc_loss 30.894846\n",
            "lp_loss 3.7086854\n",
            "dc_loss 37.9583511\n",
            "lp_loss 3.06090355\n",
            "dc_loss 27.9002743\n",
            "lp_loss 2.70335531\n",
            "dc_loss 33.9202957\n",
            "lp_loss 3.4310925\n",
            "dc_loss 18.6724358\n",
            "lp_loss 3.37269163\n",
            "dc_loss 22.0535717\n",
            "lp_loss 3.20978451\n",
            "dc_loss 16.9802208\n",
            "lp_loss 2.50632954\n",
            "dc_loss 43.9203911\n",
            "lp_loss 2.6736567\n",
            "dc_loss 46.1329231\n",
            "lp_loss 3.28350282\n",
            "dc_loss 44.0528259\n",
            "lp_loss 3.62442088\n",
            "dc_loss 34.7294197\n",
            "lp_loss 2.55320501\n",
            "dc_loss 27.5617428\n",
            "lp_loss 2.74440265\n",
            "dc_loss 37.4688072\n",
            "lp_loss 3.56272078\n",
            "dc_loss 35.9541397\n",
            "lp_loss 2.87489367\n",
            "dc_loss 42.5390739\n",
            "lp_loss 3.12313843\n",
            "dc_loss 29.2430153\n",
            "lp_loss 4.69823885\n",
            "dc_loss 35.3750343\n",
            "lp_loss 4.17796421\n",
            "dc_loss 26.6769924\n",
            "lp_loss 3.23059034\n",
            "dc_loss 33.0851746\n",
            "lp_loss 3.77505064\n",
            "dc_loss 39.486248\n",
            "lp_loss 2.79188943\n",
            "dc_loss 13.6195421\n",
            "lp_loss 2.51003671\n",
            "dc_loss 33.8446579\n",
            "lp_loss 3.06153822\n",
            "dc_loss 15.8762512\n",
            "lp_loss 2.72084975\n",
            "dc_loss 21.9051456\n",
            "lp_loss 3.00711536\n",
            "dc_loss 25.1196022\n",
            "2020-02-06 18:08:11.377983\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.858901501\n",
            "domain_classification_accuracy: 0.0918560624\n",
            "label_prediction_accuracy - Test: 0.75757575 1748\n",
            "label_prediction_accuracy - Target Test: 0.738636374\n",
            "label_prediction_accuracy - Target : 0.271717161\n",
            "Beginning of epoch: 2\n",
            "lp_loss 3.40079927\n",
            "dc_loss 9.20562172\n",
            "lp_loss 3.00837159\n",
            "dc_loss 46.4247322\n",
            "lp_loss 2.41860199\n",
            "dc_loss 35.2768936\n",
            "lp_loss 2.62641191\n",
            "dc_loss 19.4208336\n",
            "lp_loss 2.5483408\n",
            "dc_loss 15.6960239\n",
            "lp_loss 3.09010553\n",
            "dc_loss 28.2118015\n",
            "lp_loss 2.89213371\n",
            "dc_loss 46.5809097\n",
            "lp_loss 3.00174212\n",
            "dc_loss 45.8483963\n",
            "lp_loss 2.50760889\n",
            "dc_loss 29.6317081\n",
            "lp_loss 3.388942\n",
            "dc_loss 17.7455692\n",
            "lp_loss 2.40956283\n",
            "dc_loss 20.5286598\n",
            "lp_loss 2.95923567\n",
            "dc_loss 41.4099731\n",
            "lp_loss 3.2001605\n",
            "dc_loss 50.8104057\n",
            "lp_loss 2.67275763\n",
            "dc_loss 31.7144814\n",
            "lp_loss 2.82241416\n",
            "dc_loss 45.0290909\n",
            "lp_loss 3.19907069\n",
            "dc_loss 23.7141457\n",
            "lp_loss 3.18771577\n",
            "dc_loss 40.230835\n",
            "lp_loss 3.00853395\n",
            "dc_loss 37.9728889\n",
            "lp_loss 3.08873987\n",
            "dc_loss 27.1454048\n",
            "lp_loss 2.52426147\n",
            "dc_loss 15.6674013\n",
            "lp_loss 2.79818058\n",
            "dc_loss 57.5481262\n",
            "lp_loss 3.28758144\n",
            "dc_loss 53.7512627\n",
            "lp_loss 2.57147217\n",
            "dc_loss 29.5100365\n",
            "lp_loss 3.08559656\n",
            "dc_loss 22.0363541\n",
            "lp_loss 3.31468058\n",
            "dc_loss 36.3477097\n",
            "lp_loss 3.8580637\n",
            "dc_loss 47.9216194\n",
            "lp_loss 3.24188304\n",
            "dc_loss 18.9075661\n",
            "lp_loss 3.27285051\n",
            "dc_loss 20.2263603\n",
            "lp_loss 3.32276869\n",
            "dc_loss 32.3484344\n",
            "lp_loss 3.06605053\n",
            "dc_loss 27.4951534\n",
            "lp_loss 2.49650168\n",
            "dc_loss 38.6646423\n",
            "lp_loss 3.92707849\n",
            "dc_loss 32.234787\n",
            "lp_loss 2.59678984\n",
            "dc_loss 26.8672333\n",
            "lp_loss 3.36525583\n",
            "dc_loss 58.0942154\n",
            "lp_loss 3.26274133\n",
            "dc_loss 19.9148788\n",
            "lp_loss 3.24690199\n",
            "dc_loss 26.4900818\n",
            "lp_loss 3.23394489\n",
            "dc_loss 30.8174629\n",
            "lp_loss 3.51750469\n",
            "dc_loss 49.8090744\n",
            "lp_loss 3.99223375\n",
            "dc_loss 24.363163\n",
            "lp_loss 2.674577\n",
            "dc_loss 41.0470467\n",
            "lp_loss 2.67419863\n",
            "dc_loss 17.6575527\n",
            "lp_loss 2.91196227\n",
            "dc_loss 36.8698387\n",
            "lp_loss 2.5833497\n",
            "dc_loss 57.1645279\n",
            "lp_loss 3.03175831\n",
            "dc_loss 24.1638107\n",
            "lp_loss 2.9443059\n",
            "dc_loss 24.2318687\n",
            "lp_loss 2.72287464\n",
            "dc_loss 23.7782898\n",
            "lp_loss 3.53936291\n",
            "dc_loss 54.3964844\n",
            "lp_loss 2.8603394\n",
            "dc_loss 45.7080688\n",
            "lp_loss 3.59890246\n",
            "dc_loss 49.7864304\n",
            "lp_loss 3.13385057\n",
            "dc_loss 43.2143021\n",
            "lp_loss 3.89847\n",
            "dc_loss 21.9614754\n",
            "lp_loss 3.99689984\n",
            "dc_loss 15.8229189\n",
            "lp_loss 3.08370328\n",
            "dc_loss 30.2998714\n",
            "lp_loss 3.04193258\n",
            "dc_loss 20.7166615\n",
            "lp_loss 3.40557861\n",
            "dc_loss 19.5109863\n",
            "lp_loss 3.60402846\n",
            "dc_loss 43.7307053\n",
            "lp_loss 3.34213161\n",
            "dc_loss 29.1655121\n",
            "lp_loss 2.46345\n",
            "dc_loss 32.0171928\n",
            "lp_loss 3.47918701\n",
            "dc_loss 28.8651161\n",
            "lp_loss 2.78320479\n",
            "dc_loss 36.9428139\n",
            "lp_loss 3.52396369\n",
            "dc_loss 69.8105\n",
            "lp_loss 3.44513869\n",
            "dc_loss 51.8323288\n",
            "lp_loss 3.76781\n",
            "dc_loss 37.7467155\n",
            "lp_loss 2.73000097\n",
            "dc_loss 40.3589096\n",
            "lp_loss 2.82092738\n",
            "dc_loss 7.02040577\n",
            "lp_loss 3.05533552\n",
            "dc_loss 32.684227\n",
            "lp_loss 2.62169409\n",
            "dc_loss 26.774662\n",
            "lp_loss 2.39982224\n",
            "dc_loss 40.0647697\n",
            "lp_loss 3.28740859\n",
            "dc_loss 47.1527\n",
            "lp_loss 3.93917274\n",
            "dc_loss 36.6879387\n",
            "lp_loss 4.35820818\n",
            "dc_loss 14.4959812\n",
            "lp_loss 2.43511724\n",
            "dc_loss 27.2437134\n",
            "lp_loss 2.46705961\n",
            "dc_loss 11.8675051\n",
            "lp_loss 2.82832861\n",
            "dc_loss 31.9727669\n",
            "lp_loss 3.16031599\n",
            "dc_loss 41.6138687\n",
            "lp_loss 2.75305223\n",
            "dc_loss 27.0561314\n",
            "lp_loss 2.46570373\n",
            "dc_loss 33.9946213\n",
            "lp_loss 3.07115412\n",
            "dc_loss 28.6173649\n",
            "lp_loss 3.16181421\n",
            "dc_loss 49.1194839\n",
            "lp_loss 2.98744273\n",
            "dc_loss 30.7817745\n",
            "lp_loss 2.80564713\n",
            "dc_loss 44.6292038\n",
            "lp_loss 2.48595881\n",
            "dc_loss 31.560873\n",
            "lp_loss 3.1667738\n",
            "dc_loss 44.0722771\n",
            "lp_loss 3.52959681\n",
            "dc_loss 41.60952\n",
            "lp_loss 3.4003346\n",
            "dc_loss 23.2427597\n",
            "lp_loss 2.48790455\n",
            "dc_loss 37.4985275\n",
            "lp_loss 2.98252082\n",
            "dc_loss 44.640873\n",
            "lp_loss 3.79851866\n",
            "dc_loss 41.6352119\n",
            "lp_loss 3.36548471\n",
            "dc_loss 35.4455757\n",
            "lp_loss 3.28582549\n",
            "dc_loss 21.2076492\n",
            "lp_loss 3.31258345\n",
            "dc_loss 15.2145338\n",
            "lp_loss 2.66272\n",
            "dc_loss 37.6286888\n",
            "lp_loss 3.20828629\n",
            "dc_loss 34.9143028\n",
            "lp_loss 3.60419559\n",
            "dc_loss 35.5954514\n",
            "lp_loss 2.7833\n",
            "dc_loss 39.307148\n",
            "lp_loss 3.22601986\n",
            "dc_loss 38.1410751\n",
            "lp_loss 2.71929884\n",
            "dc_loss 43.3009911\n",
            "lp_loss 2.52550268\n",
            "dc_loss 46.283535\n",
            "lp_loss 3.10925078\n",
            "dc_loss 55.7659225\n",
            "lp_loss 3.33260465\n",
            "dc_loss 32.899292\n",
            "lp_loss 3.16172385\n",
            "dc_loss 20.0207767\n",
            "lp_loss 2.67129135\n",
            "dc_loss 19.3854561\n",
            "lp_loss 2.91684294\n",
            "dc_loss 34.4958191\n",
            "lp_loss 3.05337739\n",
            "dc_loss 26.1825657\n",
            "lp_loss 2.46772432\n",
            "dc_loss 48.0501328\n",
            "lp_loss 3.07241297\n",
            "dc_loss 36.5503\n",
            "lp_loss 3.40318632\n",
            "dc_loss 32.981041\n",
            "lp_loss 3.73115659\n",
            "dc_loss 51.3448677\n",
            "lp_loss 3.24726057\n",
            "dc_loss 33.5795517\n",
            "lp_loss 2.92807579\n",
            "dc_loss 24.9545593\n",
            "lp_loss 2.58114243\n",
            "dc_loss 40.6189842\n",
            "lp_loss 3.85245037\n",
            "dc_loss 39.0078354\n",
            "lp_loss 2.95759082\n",
            "dc_loss 34.0527725\n",
            "lp_loss 3.32691646\n",
            "dc_loss 67.7840424\n",
            "lp_loss 3.08256626\n",
            "dc_loss 33.0695686\n",
            "lp_loss 4.41684818\n",
            "dc_loss 49.1254234\n",
            "lp_loss 3.07064986\n",
            "dc_loss 58.2477341\n",
            "lp_loss 2.74379206\n",
            "dc_loss 29.6910152\n",
            "lp_loss 2.56462049\n",
            "dc_loss 30.3358765\n",
            "lp_loss 3.99679255\n",
            "dc_loss 51.1346779\n",
            "lp_loss 3.82854557\n",
            "dc_loss 30.824564\n",
            "lp_loss 3.45094681\n",
            "dc_loss 57.9483643\n",
            "lp_loss 3.42483068\n",
            "dc_loss 41.9577522\n",
            "lp_loss 2.63757133\n",
            "dc_loss 21.3628502\n",
            "lp_loss 3.42866755\n",
            "dc_loss 34.2064934\n",
            "lp_loss 3.93369603\n",
            "dc_loss 26.2272949\n",
            "lp_loss 2.48772979\n",
            "dc_loss 44.1632919\n",
            "lp_loss 2.67951345\n",
            "dc_loss 44.6630898\n",
            "lp_loss 2.86397314\n",
            "dc_loss 35.5405922\n",
            "lp_loss 3.13570452\n",
            "dc_loss 46.1245651\n",
            "lp_loss 3.84337664\n",
            "dc_loss 25.7725487\n",
            "lp_loss 2.62222862\n",
            "dc_loss 24.4581451\n",
            "lp_loss 3.84540701\n",
            "dc_loss 39.4670906\n",
            "lp_loss 3.5000844\n",
            "dc_loss 18.0341511\n",
            "lp_loss 2.74725246\n",
            "dc_loss 28.3686218\n",
            "lp_loss 3.79651165\n",
            "dc_loss 25.8178158\n",
            "lp_loss 2.4580822\n",
            "dc_loss 24.4383602\n",
            "lp_loss 3.31027675\n",
            "dc_loss 46.9532089\n",
            "lp_loss 3.75962257\n",
            "dc_loss 21.2930374\n",
            "lp_loss 3.76498938\n",
            "dc_loss 30.9740639\n",
            "lp_loss 2.86463261\n",
            "dc_loss 15.0066862\n",
            "lp_loss 2.55867553\n",
            "dc_loss 29.2084961\n",
            "lp_loss 2.9040947\n",
            "dc_loss 27.8696899\n",
            "lp_loss 2.60020828\n",
            "dc_loss 49.6981392\n",
            "lp_loss 3.09913111\n",
            "dc_loss 22.8824291\n",
            "lp_loss 2.52681136\n",
            "dc_loss 40.8360291\n",
            "lp_loss 3.04876423\n",
            "dc_loss 25.2803688\n",
            "lp_loss 2.9467783\n",
            "dc_loss 29.9476318\n",
            "lp_loss 3.18586946\n",
            "dc_loss 40.3693657\n",
            "lp_loss 2.66195631\n",
            "dc_loss 19.3907471\n",
            "lp_loss 2.46169066\n",
            "dc_loss 52.7485771\n",
            "lp_loss 2.59064889\n",
            "dc_loss 29.8636169\n",
            "lp_loss 3.71789956\n",
            "dc_loss 57.9378052\n",
            "lp_loss 2.6670835\n",
            "dc_loss 57.9240112\n",
            "lp_loss 2.6085043\n",
            "dc_loss 18.9286232\n",
            "lp_loss 2.706249\n",
            "dc_loss 54.6865959\n",
            "lp_loss 3.23799968\n",
            "dc_loss 41.1234093\n",
            "lp_loss 2.82768154\n",
            "dc_loss 17.1341381\n",
            "lp_loss 3.10337281\n",
            "dc_loss 23.9622459\n",
            "lp_loss 3.48242283\n",
            "dc_loss 34.6723938\n",
            "lp_loss 2.89872551\n",
            "dc_loss 21.017395\n",
            "lp_loss 3.18765426\n",
            "dc_loss 38.8617935\n",
            "lp_loss 3.22888017\n",
            "dc_loss 27.2850494\n",
            "lp_loss 3.35506678\n",
            "dc_loss 74.9583359\n",
            "lp_loss 2.79213572\n",
            "dc_loss 28.7139015\n",
            "lp_loss 3.2999227\n",
            "dc_loss 44.5215073\n",
            "lp_loss 4.28614044\n",
            "dc_loss 23.6656837\n",
            "lp_loss 3.97873783\n",
            "dc_loss 38.7177353\n",
            "lp_loss 3.64736295\n",
            "dc_loss 40.2155952\n",
            "lp_loss 3.0351429\n",
            "dc_loss 36.9567642\n",
            "lp_loss 2.8701067\n",
            "dc_loss 17.5634727\n",
            "lp_loss 2.45645881\n",
            "dc_loss 26.0867615\n",
            "lp_loss 2.47536206\n",
            "dc_loss 40.3015976\n",
            "lp_loss 3.29932451\n",
            "dc_loss 17.7042198\n",
            "lp_loss 2.49144793\n",
            "dc_loss 32.7481651\n",
            "lp_loss 3.59977484\n",
            "dc_loss 44.2302971\n",
            "lp_loss 2.65376234\n",
            "dc_loss 49.8701897\n",
            "lp_loss 3.27021503\n",
            "dc_loss 27.4226074\n",
            "lp_loss 3.4665482\n",
            "dc_loss 48.2738953\n",
            "lp_loss 3.31146717\n",
            "dc_loss 41.3573914\n",
            "lp_loss 3.30247355\n",
            "dc_loss 21.0491276\n",
            "lp_loss 4.33752441\n",
            "dc_loss 40.1867142\n",
            "lp_loss 2.87231541\n",
            "dc_loss 48.8781662\n",
            "lp_loss 2.83252096\n",
            "dc_loss 19.8146019\n",
            "lp_loss 3.49303532\n",
            "dc_loss 32.5451889\n",
            "lp_loss 2.56619978\n",
            "dc_loss 56.8294258\n",
            "lp_loss 2.93255949\n",
            "dc_loss 54.4494629\n",
            "lp_loss 2.91010332\n",
            "dc_loss 22.6975212\n",
            "lp_loss 2.45714545\n",
            "dc_loss 52.4582214\n",
            "lp_loss 2.48269248\n",
            "dc_loss 25.6036835\n",
            "lp_loss 2.58856988\n",
            "dc_loss 6.15001297\n",
            "lp_loss 3.66055059\n",
            "dc_loss 24.9559937\n",
            "lp_loss 4.27403355\n",
            "dc_loss 25.5481567\n",
            "lp_loss 4.17224407\n",
            "dc_loss 50.2480583\n",
            "lp_loss 3.12363982\n",
            "dc_loss 27.1867981\n",
            "lp_loss 3.09185648\n",
            "dc_loss 28.7558956\n",
            "lp_loss 3.16946745\n",
            "dc_loss 36.6865768\n",
            "lp_loss 2.64494944\n",
            "dc_loss 40.5732\n",
            "lp_loss 3.26996064\n",
            "dc_loss 57.4560127\n",
            "lp_loss 3.27700806\n",
            "dc_loss 43.0056877\n",
            "lp_loss 3.0342145\n",
            "dc_loss 22.3984871\n",
            "lp_loss 2.65518522\n",
            "dc_loss 1.84882355\n",
            "lp_loss 3.07387567\n",
            "dc_loss 37.4297104\n",
            "lp_loss 2.87366\n",
            "dc_loss 53.9722481\n",
            "lp_loss 3.38340759\n",
            "dc_loss 36.2857666\n",
            "lp_loss 2.79956222\n",
            "dc_loss 53.6353569\n",
            "lp_loss 3.36349535\n",
            "dc_loss 26.3906593\n",
            "lp_loss 4.42941809\n",
            "dc_loss 30.2072487\n",
            "lp_loss 2.84642315\n",
            "dc_loss 8.74885273\n",
            "lp_loss 3.29662\n",
            "dc_loss 47.7397881\n",
            "lp_loss 3.19404602\n",
            "dc_loss 16.6904049\n",
            "lp_loss 3.16681957\n",
            "dc_loss 14.886096\n",
            "lp_loss 3.02114\n",
            "dc_loss 43.6744156\n",
            "lp_loss 2.80070186\n",
            "dc_loss 40.4662552\n",
            "lp_loss 2.98294544\n",
            "dc_loss 34.4974785\n",
            "lp_loss 2.95611572\n",
            "dc_loss 46.942791\n",
            "lp_loss 2.42843771\n",
            "dc_loss 44.1379776\n",
            "lp_loss 2.57263541\n",
            "dc_loss 41.3952866\n",
            "lp_loss 3.09426975\n",
            "dc_loss 38.4637146\n",
            "lp_loss 3.05953479\n",
            "dc_loss 25.9136505\n",
            "lp_loss 4.02470732\n",
            "dc_loss 11.1488848\n",
            "lp_loss 3.30652905\n",
            "dc_loss 9.88898373\n",
            "lp_loss 2.82591152\n",
            "dc_loss 33.1417542\n",
            "lp_loss 2.73172045\n",
            "dc_loss 49.894165\n",
            "lp_loss 2.92744446\n",
            "dc_loss 30.2558441\n",
            "lp_loss 3.84598279\n",
            "dc_loss 22.5913486\n",
            "lp_loss 2.57725978\n",
            "dc_loss 20.7890453\n",
            "lp_loss 3.18807364\n",
            "dc_loss 30.0788078\n",
            "lp_loss 3.34974861\n",
            "dc_loss 32.4097366\n",
            "lp_loss 3.4756422\n",
            "dc_loss 30.0146732\n",
            "lp_loss 3.05541635\n",
            "dc_loss 43.7713242\n",
            "lp_loss 3.0496068\n",
            "dc_loss 58.5768433\n",
            "lp_loss 2.66499901\n",
            "dc_loss 38.2510757\n",
            "lp_loss 2.99662542\n",
            "dc_loss 40.6163292\n",
            "lp_loss 3.23863602\n",
            "dc_loss 31.1136665\n",
            "lp_loss 2.81874275\n",
            "dc_loss 11.9722691\n",
            "lp_loss 3.33157635\n",
            "dc_loss 53.5349\n",
            "lp_loss 3.12956285\n",
            "dc_loss 26.4279747\n",
            "lp_loss 3.06471896\n",
            "dc_loss 38.6357155\n",
            "lp_loss 3.17879\n",
            "dc_loss 52.3227348\n",
            "lp_loss 2.71671581\n",
            "dc_loss 22.8629417\n",
            "lp_loss 3.11307549\n",
            "dc_loss 30.0169258\n",
            "lp_loss 3.24026871\n",
            "dc_loss 40.0829\n",
            "lp_loss 2.40355349\n",
            "dc_loss 24.3541832\n",
            "lp_loss 4.07373571\n",
            "dc_loss 47.5339241\n",
            "lp_loss 3.02132535\n",
            "dc_loss 25.0522976\n",
            "lp_loss 2.58486319\n",
            "dc_loss 45.9275436\n",
            "lp_loss 3.25165749\n",
            "dc_loss 58.382618\n",
            "lp_loss 2.47457743\n",
            "dc_loss 34.155365\n",
            "lp_loss 3.24686956\n",
            "dc_loss 40.4533577\n",
            "lp_loss 3.07923102\n",
            "dc_loss 45.0203667\n",
            "lp_loss 3.12273836\n",
            "dc_loss 29.0793858\n",
            "lp_loss 3.35531855\n",
            "dc_loss 13.8915482\n",
            "lp_loss 2.69305825\n",
            "dc_loss 11.7361946\n",
            "lp_loss 2.72415709\n",
            "dc_loss 50.620533\n",
            "lp_loss 2.90153837\n",
            "dc_loss 26.1558437\n",
            "lp_loss 4.04318905\n",
            "dc_loss 24.2703667\n",
            "lp_loss 2.65606403\n",
            "dc_loss 28.061657\n",
            "lp_loss 3.07344866\n",
            "dc_loss 43.0743752\n",
            "lp_loss 3.14787912\n",
            "dc_loss 44.6601105\n",
            "lp_loss 3.10477304\n",
            "dc_loss 37.7305832\n",
            "lp_loss 3.68893242\n",
            "dc_loss 48.857048\n",
            "lp_loss 3.73690224\n",
            "dc_loss 33.2121582\n",
            "lp_loss 3.03125858\n",
            "dc_loss 27.7580929\n",
            "2020-02-06 18:08:16.906164\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.902462125\n",
            "domain_classification_accuracy: 0.0151515156\n",
            "label_prediction_accuracy - Test: 0.829545438 2012\n",
            "label_prediction_accuracy - Target Test: 0.825757563\n",
            "label_prediction_accuracy - Target : 0.277922064\n",
            "Beginning of epoch: 3\n",
            "lp_loss 2.86181188\n",
            "dc_loss 39.4176216\n",
            "lp_loss 3.48230457\n",
            "dc_loss 57.0282707\n",
            "lp_loss 3.55175638\n",
            "dc_loss 27.9802399\n",
            "lp_loss 2.49696779\n",
            "dc_loss 25.1244164\n",
            "lp_loss 2.54352713\n",
            "dc_loss 49.1696243\n",
            "lp_loss 3.90709496\n",
            "dc_loss 53.3080978\n",
            "lp_loss 2.38307834\n",
            "dc_loss 27.5806885\n",
            "lp_loss 2.66657543\n",
            "dc_loss 34.3844452\n",
            "lp_loss 3.626019\n",
            "dc_loss 32.3037453\n",
            "lp_loss 3.76369143\n",
            "dc_loss 32.1695633\n",
            "lp_loss 2.90362239\n",
            "dc_loss 31.0299988\n",
            "lp_loss 2.75366926\n",
            "dc_loss 12.4022112\n",
            "lp_loss 2.99156499\n",
            "dc_loss 37.2806511\n",
            "lp_loss 2.68761206\n",
            "dc_loss 19.0061226\n",
            "lp_loss 3.14842963\n",
            "dc_loss 40.3372498\n",
            "lp_loss 2.54229569\n",
            "dc_loss 26.2429752\n",
            "lp_loss 2.46876574\n",
            "dc_loss 12.8317366\n",
            "lp_loss 2.58820629\n",
            "dc_loss 22.1440048\n",
            "lp_loss 2.80980587\n",
            "dc_loss 38.9890785\n",
            "lp_loss 2.55385542\n",
            "dc_loss 42.4381332\n",
            "lp_loss 2.44649601\n",
            "dc_loss 40.3521461\n",
            "lp_loss 3.32175732\n",
            "dc_loss 9.53539085\n",
            "lp_loss 3.07940507\n",
            "dc_loss 44.557518\n",
            "lp_loss 2.75270367\n",
            "dc_loss 44.1913071\n",
            "lp_loss 2.51938963\n",
            "dc_loss 23.6787739\n",
            "lp_loss 2.79876828\n",
            "dc_loss 13.9405422\n",
            "lp_loss 3.09479618\n",
            "dc_loss 33.5921707\n",
            "lp_loss 2.60370207\n",
            "dc_loss 32.7085342\n",
            "lp_loss 2.70921803\n",
            "dc_loss 40.8704605\n",
            "lp_loss 3.01893973\n",
            "dc_loss 28.6381798\n",
            "lp_loss 3.40175033\n",
            "dc_loss 20.1497612\n",
            "lp_loss 2.92946243\n",
            "dc_loss 21.9294624\n",
            "lp_loss 2.79363203\n",
            "dc_loss 41.6720924\n",
            "lp_loss 2.62804365\n",
            "dc_loss 30.4814758\n",
            "lp_loss 2.6837244\n",
            "dc_loss 36.3333168\n",
            "lp_loss 3.05107784\n",
            "dc_loss 21.4591122\n",
            "lp_loss 3.37854075\n",
            "dc_loss 24.0052\n",
            "lp_loss 3.89549756\n",
            "dc_loss 29.8145752\n",
            "lp_loss 2.54507494\n",
            "dc_loss 7.40426636\n",
            "lp_loss 3.28978777\n",
            "dc_loss 34.9471512\n",
            "lp_loss 2.78264785\n",
            "dc_loss 42.0955849\n",
            "lp_loss 3.15793109\n",
            "dc_loss 42.3196716\n",
            "lp_loss 2.43184829\n",
            "dc_loss 34.9915237\n",
            "lp_loss 2.91786599\n",
            "dc_loss 20.003994\n",
            "lp_loss 2.56143618\n",
            "dc_loss 42.6887589\n",
            "lp_loss 4.01237822\n",
            "dc_loss 35.7141953\n",
            "lp_loss 3.13773489\n",
            "dc_loss 22.5958366\n",
            "lp_loss 2.83550596\n",
            "dc_loss 15.7258635\n",
            "lp_loss 2.50015283\n",
            "dc_loss 16.0209179\n",
            "lp_loss 3.19362879\n",
            "dc_loss 17.6708984\n",
            "lp_loss 3.21913\n",
            "dc_loss 25.8825684\n",
            "lp_loss 3.18518233\n",
            "dc_loss 35.6096115\n",
            "lp_loss 3.18394017\n",
            "dc_loss 21.7319489\n",
            "lp_loss 2.84507298\n",
            "dc_loss 26.4840641\n",
            "lp_loss 3.07217073\n",
            "dc_loss 29.8590755\n",
            "lp_loss 3.00036907\n",
            "dc_loss 31.793539\n",
            "lp_loss 2.91498232\n",
            "dc_loss 30.7647896\n",
            "lp_loss 2.40712976\n",
            "dc_loss 26.2331543\n",
            "lp_loss 3.23178816\n",
            "dc_loss 31.2302551\n",
            "lp_loss 3.17758894\n",
            "dc_loss 20.1888599\n",
            "lp_loss 2.69096\n",
            "dc_loss 30.2101326\n",
            "lp_loss 4.34066677\n",
            "dc_loss 22.1392956\n",
            "lp_loss 2.58413768\n",
            "dc_loss 17.4226112\n",
            "lp_loss 4.162817\n",
            "dc_loss 19.5034256\n",
            "lp_loss 3.33826923\n",
            "dc_loss 37.7234383\n",
            "lp_loss 2.89239836\n",
            "dc_loss 17.8407822\n",
            "lp_loss 3.36816359\n",
            "dc_loss 31.3368416\n",
            "lp_loss 2.57537651\n",
            "dc_loss 27.7015533\n",
            "lp_loss 3.74512434\n",
            "dc_loss 33.5695114\n",
            "lp_loss 2.750736\n",
            "dc_loss 37.8094177\n",
            "lp_loss 2.92419815\n",
            "dc_loss 52.4215202\n",
            "lp_loss 3.12872219\n",
            "dc_loss 28.5644569\n",
            "lp_loss 2.57781577\n",
            "dc_loss 32.947\n",
            "lp_loss 2.87650156\n",
            "dc_loss 15.7269058\n",
            "lp_loss 3.0226841\n",
            "dc_loss 45.9432793\n",
            "lp_loss 2.92851472\n",
            "dc_loss 39.3287239\n",
            "lp_loss 2.28067875\n",
            "dc_loss 39.6491661\n",
            "lp_loss 3.55736113\n",
            "dc_loss 38.7758484\n",
            "lp_loss 2.38852096\n",
            "dc_loss 34.9329796\n",
            "lp_loss 2.5769949\n",
            "dc_loss 31.8535652\n",
            "lp_loss 3.98428869\n",
            "dc_loss 32.481987\n",
            "lp_loss 3.09826612\n",
            "dc_loss 40.5439377\n",
            "lp_loss 2.5586\n",
            "dc_loss 33.2982674\n",
            "lp_loss 2.87563896\n",
            "dc_loss 45.7017975\n",
            "lp_loss 2.75641465\n",
            "dc_loss 32.0442886\n",
            "lp_loss 3.14070845\n",
            "dc_loss 33.3999481\n",
            "lp_loss 3.0791533\n",
            "dc_loss 29.1022682\n",
            "lp_loss 2.67709184\n",
            "dc_loss 45.3584595\n",
            "lp_loss 3.17654705\n",
            "dc_loss 28.8604031\n",
            "lp_loss 2.81864548\n",
            "dc_loss 65.8221359\n",
            "lp_loss 3.1020937\n",
            "dc_loss 24.3118134\n",
            "lp_loss 2.40152955\n",
            "dc_loss 54.3426514\n",
            "lp_loss 4.26401663\n",
            "dc_loss 6.29192495\n",
            "lp_loss 3.70331526\n",
            "dc_loss 14.8505507\n",
            "lp_loss 3.07734513\n",
            "dc_loss 16.9061\n",
            "lp_loss 3.42815328\n",
            "dc_loss 28.998642\n",
            "lp_loss 3.39896441\n",
            "dc_loss 23.6417503\n",
            "lp_loss 3.08419228\n",
            "dc_loss 20.6884232\n",
            "lp_loss 3.28115749\n",
            "dc_loss 38.2202606\n",
            "lp_loss 3.55193758\n",
            "dc_loss 33.9845963\n",
            "lp_loss 3.87688923\n",
            "dc_loss 14.2980223\n",
            "lp_loss 3.87481928\n",
            "dc_loss 12.086359\n",
            "lp_loss 3.03897095\n",
            "dc_loss 32.7520752\n",
            "lp_loss 2.50650167\n",
            "dc_loss 46.3829422\n",
            "lp_loss 3.65448356\n",
            "dc_loss 26.6365871\n",
            "lp_loss 3.24774933\n",
            "dc_loss 36.2635841\n",
            "lp_loss 3.05356741\n",
            "dc_loss 36.3725967\n",
            "lp_loss 3.1810782\n",
            "dc_loss 35.7137489\n",
            "lp_loss 3.30008268\n",
            "dc_loss 22.5215454\n",
            "lp_loss 2.90988874\n",
            "dc_loss 38.2641602\n",
            "lp_loss 3.20957851\n",
            "dc_loss 26.5234337\n",
            "lp_loss 2.67859793\n",
            "dc_loss 36.6583023\n",
            "lp_loss 3.06689429\n",
            "dc_loss 42.4328079\n",
            "lp_loss 2.64484477\n",
            "dc_loss 24.8355923\n",
            "lp_loss 2.76212311\n",
            "dc_loss 37.3229942\n",
            "lp_loss 2.4158535\n",
            "dc_loss 44.2458191\n",
            "lp_loss 3.34189463\n",
            "dc_loss 7.9418745\n",
            "lp_loss 3.72295\n",
            "dc_loss 41.3304977\n",
            "lp_loss 2.50429249\n",
            "dc_loss 36.2174606\n",
            "lp_loss 2.46533537\n",
            "dc_loss 27.7003784\n",
            "lp_loss 3.05766\n",
            "dc_loss 34.7977142\n",
            "lp_loss 3.07548499\n",
            "dc_loss 53.6570663\n",
            "lp_loss 3.06726408\n",
            "dc_loss 8.74018669\n",
            "lp_loss 2.86521244\n",
            "dc_loss 26.295536\n",
            "lp_loss 3.57779336\n",
            "dc_loss 24.361208\n",
            "lp_loss 2.94169664\n",
            "dc_loss 35.8836784\n",
            "lp_loss 2.93312836\n",
            "dc_loss 28.4637508\n",
            "lp_loss 2.82346964\n",
            "dc_loss 14.5017223\n",
            "lp_loss 2.6742363\n",
            "dc_loss 10.857605\n",
            "lp_loss 2.7973125\n",
            "dc_loss 36.5041771\n",
            "lp_loss 2.49217033\n",
            "dc_loss 34.8384323\n",
            "lp_loss 2.78349638\n",
            "dc_loss 18.2892647\n",
            "lp_loss 2.6227951\n",
            "dc_loss 32.5341301\n",
            "lp_loss 3.01398873\n",
            "dc_loss 71.3717499\n",
            "lp_loss 2.58646202\n",
            "dc_loss 39.9264336\n",
            "lp_loss 3.90100217\n",
            "dc_loss 54.5890427\n",
            "lp_loss 2.78743601\n",
            "dc_loss 7.14543772\n",
            "lp_loss 2.66821575\n",
            "dc_loss 36.813343\n",
            "lp_loss 2.91379142\n",
            "dc_loss 34.8653412\n",
            "lp_loss 3.23412585\n",
            "dc_loss 32.129612\n",
            "lp_loss 4.24666071\n",
            "dc_loss 26.0832863\n",
            "lp_loss 2.72942162\n",
            "dc_loss 40.5008926\n",
            "lp_loss 2.46498299\n",
            "dc_loss 44.9602509\n",
            "lp_loss 2.60061145\n",
            "dc_loss 38.397686\n",
            "lp_loss 3.0055747\n",
            "dc_loss 45.147377\n",
            "lp_loss 2.47407961\n",
            "dc_loss 14.1733456\n",
            "lp_loss 3.43305349\n",
            "dc_loss 55.0157242\n",
            "lp_loss 2.81930041\n",
            "dc_loss 12.2388363\n",
            "lp_loss 2.43181229\n",
            "dc_loss 10.684804\n",
            "lp_loss 3.84380865\n",
            "dc_loss 20.7451458\n",
            "lp_loss 2.82131672\n",
            "dc_loss 37.3216553\n",
            "lp_loss 2.42114449\n",
            "dc_loss 18.1628685\n",
            "lp_loss 3.14976454\n",
            "dc_loss 17.5879631\n",
            "lp_loss 2.45075083\n",
            "dc_loss 28.7000828\n",
            "lp_loss 2.63576269\n",
            "dc_loss 49.9830322\n",
            "lp_loss 2.9666419\n",
            "dc_loss 42.2945671\n",
            "lp_loss 3.40032792\n",
            "dc_loss 13.2313585\n",
            "lp_loss 2.95774698\n",
            "dc_loss 36.920105\n",
            "lp_loss 3.1178484\n",
            "dc_loss 25.8356323\n",
            "lp_loss 2.64004183\n",
            "dc_loss 33.451519\n",
            "lp_loss 2.72682071\n",
            "dc_loss 27.8559875\n",
            "lp_loss 3.76364803\n",
            "dc_loss 18.5943871\n",
            "lp_loss 3.23441052\n",
            "dc_loss 10.2737226\n",
            "lp_loss 3.15614915\n",
            "dc_loss 30.2274284\n",
            "lp_loss 3.08066416\n",
            "dc_loss 37.8932381\n",
            "lp_loss 2.71796679\n",
            "dc_loss 22.6471519\n",
            "lp_loss 2.71097374\n",
            "dc_loss 41.1749496\n",
            "lp_loss 3.92634797\n",
            "dc_loss 32.8847961\n",
            "lp_loss 3.07885265\n",
            "dc_loss 31.7820644\n",
            "lp_loss 2.51786184\n",
            "dc_loss 44.8168831\n",
            "lp_loss 2.43930101\n",
            "dc_loss 35.0994072\n",
            "lp_loss 3.64016199\n",
            "dc_loss 32.7323112\n",
            "lp_loss 2.74652672\n",
            "dc_loss 42.1970291\n",
            "lp_loss 2.76664543\n",
            "dc_loss 27.3599911\n",
            "lp_loss 2.53014231\n",
            "dc_loss 27.305584\n",
            "lp_loss 2.74365306\n",
            "dc_loss 54.3530655\n",
            "lp_loss 3.34548616\n",
            "dc_loss 32.2377129\n",
            "lp_loss 2.76407146\n",
            "dc_loss 34.35429\n",
            "lp_loss 2.42593741\n",
            "dc_loss 47.7458305\n",
            "lp_loss 2.73473477\n",
            "dc_loss 5.22435188\n",
            "lp_loss 2.60226822\n",
            "dc_loss 29.7385368\n",
            "lp_loss 3.08401918\n",
            "dc_loss 55.7823181\n",
            "lp_loss 2.72802854\n",
            "dc_loss 42.6798782\n",
            "lp_loss 3.69672298\n",
            "dc_loss 17.3291512\n",
            "lp_loss 3.60078502\n",
            "dc_loss 43.5788116\n",
            "lp_loss 4.86651421\n",
            "dc_loss 26.1396675\n",
            "lp_loss 3.10546446\n",
            "dc_loss 22.150034\n",
            "lp_loss 2.46221685\n",
            "dc_loss 18.118845\n",
            "lp_loss 3.20431495\n",
            "dc_loss 14.9179182\n",
            "lp_loss 3.22498274\n",
            "dc_loss 17.6521072\n",
            "lp_loss 2.73061728\n",
            "dc_loss 20.8269844\n",
            "lp_loss 3.04619837\n",
            "dc_loss 23.6990738\n",
            "lp_loss 3.40753889\n",
            "dc_loss 30.9278145\n",
            "lp_loss 2.89298058\n",
            "dc_loss 41.0724792\n",
            "lp_loss 3.1983819\n",
            "dc_loss 21.5101013\n",
            "lp_loss 3.09498787\n",
            "dc_loss 48.3297577\n",
            "lp_loss 2.65359592\n",
            "dc_loss 41.4271469\n",
            "lp_loss 2.59786034\n",
            "dc_loss 36.6379204\n",
            "lp_loss 3.28230953\n",
            "dc_loss 22.3963203\n",
            "lp_loss 3.08653545\n",
            "dc_loss 21.3769474\n",
            "lp_loss 3.3353796\n",
            "dc_loss 35.8335609\n",
            "lp_loss 2.98964119\n",
            "dc_loss 24.338892\n",
            "lp_loss 3.20466638\n",
            "dc_loss 34.0246506\n",
            "lp_loss 2.55278707\n",
            "dc_loss 31.1923523\n",
            "lp_loss 3.70062971\n",
            "dc_loss 30.7445736\n",
            "lp_loss 3.28335047\n",
            "dc_loss 47.7987\n",
            "lp_loss 3.87452197\n",
            "dc_loss 16.6469269\n",
            "lp_loss 2.78656077\n",
            "dc_loss 19.4592266\n",
            "lp_loss 2.71057272\n",
            "dc_loss 18.2674446\n",
            "lp_loss 2.48128557\n",
            "dc_loss 35.4283142\n",
            "lp_loss 2.89033699\n",
            "dc_loss 30.954998\n",
            "lp_loss 3.27484465\n",
            "dc_loss 36.2791\n",
            "lp_loss 3.27060437\n",
            "dc_loss 46.5564\n",
            "lp_loss 3.72697926\n",
            "dc_loss 43.4405632\n",
            "lp_loss 2.40077424\n",
            "dc_loss 23.090744\n",
            "lp_loss 3.23206663\n",
            "dc_loss 20.8201904\n",
            "lp_loss 2.5134728\n",
            "dc_loss 47.6289558\n",
            "lp_loss 2.85837412\n",
            "dc_loss 29.4225254\n",
            "lp_loss 2.91605306\n",
            "dc_loss 22.242197\n",
            "lp_loss 2.60950494\n",
            "dc_loss 27.691925\n",
            "lp_loss 3.01103973\n",
            "dc_loss 42.5380592\n",
            "lp_loss 3.1444869\n",
            "dc_loss 32.5631752\n",
            "lp_loss 4.00159311\n",
            "dc_loss 21.7586918\n",
            "lp_loss 4.23108578\n",
            "dc_loss 31.7153873\n",
            "lp_loss 3.21819639\n",
            "dc_loss 26.4604\n",
            "lp_loss 2.51079655\n",
            "dc_loss 44.270874\n",
            "lp_loss 3.6225183\n",
            "dc_loss 19.7009716\n",
            "lp_loss 2.60506535\n",
            "dc_loss 40.1159134\n",
            "lp_loss 2.52633429\n",
            "dc_loss 37.8686066\n",
            "lp_loss 2.82964182\n",
            "dc_loss 48.8000565\n",
            "lp_loss 2.42958212\n",
            "dc_loss 48.4796524\n",
            "lp_loss 2.89789057\n",
            "dc_loss 41.2385178\n",
            "lp_loss 3.15797687\n",
            "dc_loss 12.617878\n",
            "lp_loss 3.31386\n",
            "dc_loss 11.7175188\n",
            "lp_loss 3.01857805\n",
            "dc_loss 31.0562286\n",
            "lp_loss 2.82492924\n",
            "dc_loss 18.5210228\n",
            "lp_loss 3.27613711\n",
            "dc_loss 22.0465908\n",
            "lp_loss 2.88175654\n",
            "dc_loss 37.5022926\n",
            "lp_loss 3.40033293\n",
            "dc_loss 27.6894684\n",
            "lp_loss 2.33362103\n",
            "dc_loss 28.9180107\n",
            "lp_loss 3.29845572\n",
            "dc_loss 42.78228\n",
            "lp_loss 2.53338265\n",
            "dc_loss 40.2809067\n",
            "lp_loss 3.71882343\n",
            "dc_loss 48.501236\n",
            "lp_loss 3.22677159\n",
            "dc_loss 40.9372025\n",
            "lp_loss 3.07230425\n",
            "dc_loss 41.7792435\n",
            "lp_loss 2.63992453\n",
            "dc_loss 31.1354485\n",
            "lp_loss 2.6089282\n",
            "dc_loss 48.6649208\n",
            "lp_loss 2.60938835\n",
            "dc_loss 9.60149193\n",
            "lp_loss 3.09840584\n",
            "dc_loss 31.6986389\n",
            "lp_loss 2.47436714\n",
            "dc_loss 24.0827847\n",
            "lp_loss 2.83507657\n",
            "dc_loss 27.1263618\n",
            "lp_loss 2.90633535\n",
            "dc_loss 7.39129734\n",
            "lp_loss 2.58868265\n",
            "dc_loss 21.3250675\n",
            "lp_loss 3.84470987\n",
            "dc_loss 44.3954468\n",
            "lp_loss 2.79823399\n",
            "dc_loss 32.1754\n",
            "lp_loss 3.1747396\n",
            "dc_loss 35.3855934\n",
            "lp_loss 3.07495284\n",
            "dc_loss 38.3695221\n",
            "lp_loss 2.56252813\n",
            "dc_loss 29.9691658\n",
            "lp_loss 3.19681668\n",
            "dc_loss 46.8680496\n",
            "lp_loss 2.54583049\n",
            "dc_loss 41.0470581\n",
            "lp_loss 2.48487473\n",
            "dc_loss 17.0806751\n",
            "lp_loss 2.62166262\n",
            "dc_loss 18.7066231\n",
            "lp_loss 3.1884234\n",
            "dc_loss 25.6736851\n",
            "lp_loss 3.13085032\n",
            "dc_loss 39.7730141\n",
            "2020-02-06 18:08:22.428389\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.931818187\n",
            "domain_classification_accuracy: 0.216856062\n",
            "label_prediction_accuracy - Test: 0.821969688 2276\n",
            "label_prediction_accuracy - Target Test: 0.814393938\n",
            "label_prediction_accuracy - Target : 0.278787881\n",
            "Beginning of epoch: 4\n",
            "lp_loss 3.55114746\n",
            "dc_loss 50.9580536\n",
            "lp_loss 3.25740266\n",
            "dc_loss 20.4986935\n",
            "lp_loss 2.33963251\n",
            "dc_loss 42.6068115\n",
            "lp_loss 2.49448729\n",
            "dc_loss 14.0878696\n",
            "lp_loss 2.78655434\n",
            "dc_loss 16.5634804\n",
            "lp_loss 3.0357554\n",
            "dc_loss 87.543129\n",
            "lp_loss 3.15366387\n",
            "dc_loss 68.2580719\n",
            "lp_loss 3.2157352\n",
            "dc_loss 11.4144545\n",
            "lp_loss 2.2716186\n",
            "dc_loss 29.6729736\n",
            "lp_loss 2.52783203\n",
            "dc_loss 35.9898605\n",
            "lp_loss 2.56248784\n",
            "dc_loss 31.0359497\n",
            "lp_loss 3.3061502\n",
            "dc_loss 54.9996834\n",
            "lp_loss 2.39706421\n",
            "dc_loss 22.1390553\n",
            "lp_loss 4.40203142\n",
            "dc_loss 32.3972778\n",
            "lp_loss 3.07306504\n",
            "dc_loss 49.0719757\n",
            "lp_loss 2.51391745\n",
            "dc_loss 53.8087883\n",
            "lp_loss 3.50483942\n",
            "dc_loss 32.7297668\n",
            "lp_loss 2.52545118\n",
            "dc_loss 33.1425323\n",
            "lp_loss 3.13318515\n",
            "dc_loss 23.5964966\n",
            "lp_loss 2.99907327\n",
            "dc_loss 31.3623753\n",
            "lp_loss 3.51700783\n",
            "dc_loss 38.8325348\n",
            "lp_loss 2.70002508\n",
            "dc_loss 40.9780807\n",
            "lp_loss 3.35344553\n",
            "dc_loss 29.8482971\n",
            "lp_loss 2.86712289\n",
            "dc_loss 25.1441765\n",
            "lp_loss 2.68422127\n",
            "dc_loss 24.3056068\n",
            "lp_loss 3.1134603\n",
            "dc_loss 48.0169258\n",
            "lp_loss 2.79154158\n",
            "dc_loss 52.7036438\n",
            "lp_loss 2.86215019\n",
            "dc_loss 35.5010071\n",
            "lp_loss 2.42269945\n",
            "dc_loss 34.7563934\n",
            "lp_loss 3.87296176\n",
            "dc_loss 43.1276169\n",
            "lp_loss 3.37344\n",
            "dc_loss 50.3983803\n",
            "lp_loss 2.38442707\n",
            "dc_loss 32.5454788\n",
            "lp_loss 2.36388516\n",
            "dc_loss 24.5833492\n",
            "lp_loss 2.782408\n",
            "dc_loss 31.8577824\n",
            "lp_loss 3.40518761\n",
            "dc_loss 55.7468147\n",
            "lp_loss 3.24634266\n",
            "dc_loss 51.4651489\n",
            "lp_loss 2.75905895\n",
            "dc_loss 15.1484833\n",
            "lp_loss 2.73938799\n",
            "dc_loss 73.1102753\n",
            "lp_loss 2.35184288\n",
            "dc_loss 32.3281364\n",
            "lp_loss 3.12094426\n",
            "dc_loss 33.6303406\n",
            "lp_loss 2.69697332\n",
            "dc_loss 33.0955238\n",
            "lp_loss 3.18539166\n",
            "dc_loss 35.3026161\n",
            "lp_loss 2.66253853\n",
            "dc_loss 30.1908455\n",
            "lp_loss 3.26914144\n",
            "dc_loss 28.0883598\n",
            "lp_loss 3.3259635\n",
            "dc_loss 55.1318855\n",
            "lp_loss 2.53856397\n",
            "dc_loss 64.9712143\n",
            "lp_loss 2.38432336\n",
            "dc_loss 6.49136591\n",
            "lp_loss 3.25959682\n",
            "dc_loss 34.2784538\n",
            "lp_loss 2.70599556\n",
            "dc_loss 18.7090054\n",
            "lp_loss 2.58070898\n",
            "dc_loss 28.7525902\n",
            "lp_loss 3.08310747\n",
            "dc_loss 58.0062141\n",
            "lp_loss 2.32523203\n",
            "dc_loss 34.2122459\n",
            "lp_loss 2.88741255\n",
            "dc_loss 44.2064171\n",
            "lp_loss 3.39547586\n",
            "dc_loss 51.6447449\n",
            "lp_loss 4.18880653\n",
            "dc_loss 59.4386063\n",
            "lp_loss 3.61995387\n",
            "dc_loss 25.4277477\n",
            "lp_loss 2.42462397\n",
            "dc_loss 84.5702\n",
            "lp_loss 3.52243614\n",
            "dc_loss 50.1535301\n",
            "lp_loss 2.44690418\n",
            "dc_loss 55.7597542\n",
            "lp_loss 3.39809585\n",
            "dc_loss 43.5179672\n",
            "lp_loss 3.34619665\n",
            "dc_loss 36.5715714\n",
            "lp_loss 2.81889296\n",
            "dc_loss 32.7702675\n",
            "lp_loss 3.26701069\n",
            "dc_loss 27.0849972\n",
            "lp_loss 3.65928507\n",
            "dc_loss 41.5662766\n",
            "lp_loss 3.2349503\n",
            "dc_loss 22.9314098\n",
            "lp_loss 2.78824329\n",
            "dc_loss 42.8567429\n",
            "lp_loss 2.40561295\n",
            "dc_loss 52.3161545\n",
            "lp_loss 3.30537939\n",
            "dc_loss 21.2471523\n",
            "lp_loss 2.35105038\n",
            "dc_loss 62.6341324\n",
            "lp_loss 3.17670393\n",
            "dc_loss 36.5959244\n",
            "lp_loss 2.73725748\n",
            "dc_loss 13.6685839\n",
            "lp_loss 2.98662043\n",
            "dc_loss 60.3337\n",
            "lp_loss 3.45268\n",
            "dc_loss 67.7696686\n",
            "lp_loss 2.66139746\n",
            "dc_loss 39.8894958\n",
            "lp_loss 2.99077368\n",
            "dc_loss 41.0745926\n",
            "lp_loss 3.22108412\n",
            "dc_loss 54.0992\n",
            "lp_loss 2.47589684\n",
            "dc_loss 54.1702499\n",
            "lp_loss 3.57793808\n",
            "dc_loss 37.8278122\n",
            "lp_loss 4.44957447\n",
            "dc_loss 20.2515259\n",
            "lp_loss 3.24187946\n",
            "dc_loss 57.3484116\n",
            "lp_loss 3.44780612\n",
            "dc_loss 72.1251\n",
            "lp_loss 3.0418725\n",
            "dc_loss 46.0611076\n",
            "lp_loss 2.42795372\n",
            "dc_loss 28.6005459\n",
            "lp_loss 2.66491461\n",
            "dc_loss 41.0642052\n",
            "lp_loss 2.67209101\n",
            "dc_loss 41.1000214\n",
            "lp_loss 3.24058223\n",
            "dc_loss 24.742075\n",
            "lp_loss 3.12643218\n",
            "dc_loss 44.721447\n",
            "lp_loss 3.05218935\n",
            "dc_loss 36.2538185\n",
            "lp_loss 2.9317503\n",
            "dc_loss 58.8942642\n",
            "lp_loss 2.4504993\n",
            "dc_loss 34.5282631\n",
            "lp_loss 3.75075865\n",
            "dc_loss 26.3563652\n",
            "lp_loss 2.30136347\n",
            "dc_loss 44.3570557\n",
            "lp_loss 3.08730793\n",
            "dc_loss 52.5732231\n",
            "lp_loss 2.8333776\n",
            "dc_loss 64.3510284\n",
            "lp_loss 2.60557556\n",
            "dc_loss 22.8616104\n",
            "lp_loss 3.61114\n",
            "dc_loss 25.7315826\n",
            "lp_loss 3.12338924\n",
            "dc_loss 30.39\n",
            "lp_loss 3.2921772\n",
            "dc_loss 7.33655787\n",
            "lp_loss 3.16402555\n",
            "dc_loss 36.3519\n",
            "lp_loss 2.56515598\n",
            "dc_loss 53.6215401\n",
            "lp_loss 3.20395303\n",
            "dc_loss 44.0152\n",
            "lp_loss 2.56100154\n",
            "dc_loss 52.6296577\n",
            "lp_loss 2.66993737\n",
            "dc_loss 42.6495972\n",
            "lp_loss 2.5350554\n",
            "dc_loss 22.6593418\n",
            "lp_loss 3.15147543\n",
            "dc_loss 50.1617889\n",
            "lp_loss 3.20866156\n",
            "dc_loss 40.5044937\n",
            "lp_loss 3.2214992\n",
            "dc_loss 76.1844\n",
            "lp_loss 3.17529273\n",
            "dc_loss 22.3771019\n",
            "lp_loss 4.0637722\n",
            "dc_loss 54.4821281\n",
            "lp_loss 2.41644597\n",
            "dc_loss 43.8895454\n",
            "lp_loss 2.47382307\n",
            "dc_loss 53.4912605\n",
            "lp_loss 2.3854723\n",
            "dc_loss 62.6136246\n",
            "lp_loss 2.66393375\n",
            "dc_loss 20.645319\n",
            "lp_loss 2.78392172\n",
            "dc_loss 68.5119247\n",
            "lp_loss 2.36422348\n",
            "dc_loss 40.1117439\n",
            "lp_loss 3.07325649\n",
            "dc_loss 65.1918716\n",
            "lp_loss 2.67430162\n",
            "dc_loss 6.92346573\n",
            "lp_loss 3.24251556\n",
            "dc_loss 61.0944443\n",
            "lp_loss 2.44749451\n",
            "dc_loss 36.0052261\n",
            "lp_loss 2.40838957\n",
            "dc_loss 56.4175911\n",
            "lp_loss 2.80701017\n",
            "dc_loss 25.1382694\n",
            "lp_loss 3.28556919\n",
            "dc_loss 23.9312153\n",
            "lp_loss 2.99422503\n",
            "dc_loss 21.7407417\n",
            "lp_loss 3.15461826\n",
            "dc_loss 32.8720665\n",
            "lp_loss 4.22487879\n",
            "dc_loss 24.7125225\n",
            "lp_loss 2.54543924\n",
            "dc_loss 30.7523251\n",
            "lp_loss 2.66981316\n",
            "dc_loss 30.763752\n",
            "lp_loss 3.41631699\n",
            "dc_loss 32.6094589\n",
            "lp_loss 2.73915839\n",
            "dc_loss 71.261673\n",
            "lp_loss 2.77951956\n",
            "dc_loss 22.8601589\n",
            "lp_loss 2.57614565\n",
            "dc_loss 23.6471844\n",
            "lp_loss 2.47171831\n",
            "dc_loss 29.863699\n",
            "lp_loss 2.47610617\n",
            "dc_loss 10.5593395\n",
            "lp_loss 2.37074137\n",
            "dc_loss 51.74757\n",
            "lp_loss 4.07909966\n",
            "dc_loss 48.4412918\n",
            "lp_loss 2.56070566\n",
            "dc_loss 58.8890915\n",
            "lp_loss 2.5991466\n",
            "dc_loss 46.1749954\n",
            "lp_loss 3.3695972\n",
            "dc_loss 64.2055511\n",
            "lp_loss 2.59275293\n",
            "dc_loss 62.7738647\n",
            "lp_loss 3.34199739\n",
            "dc_loss 41.9821091\n",
            "lp_loss 2.71379972\n",
            "dc_loss 59.774231\n",
            "lp_loss 2.76563406\n",
            "dc_loss 51.8955803\n",
            "lp_loss 2.50404787\n",
            "dc_loss 35.5995445\n",
            "lp_loss 3.59207058\n",
            "dc_loss 56.9396477\n",
            "lp_loss 3.12905121\n",
            "dc_loss 31.6957397\n",
            "lp_loss 4.15757513\n",
            "dc_loss 58.4031067\n",
            "lp_loss 2.53289533\n",
            "dc_loss 62.8229599\n",
            "lp_loss 4.15974712\n",
            "dc_loss 44.8433113\n",
            "lp_loss 2.53149319\n",
            "dc_loss 16.516552\n",
            "lp_loss 2.4473784\n",
            "dc_loss 58.1990738\n",
            "lp_loss 2.5407927\n",
            "dc_loss 15.5002317\n",
            "lp_loss 2.38315368\n",
            "dc_loss 82.5230331\n",
            "lp_loss 2.54512119\n",
            "dc_loss 46.409256\n",
            "lp_loss 3.2066741\n",
            "dc_loss 63.9490471\n",
            "lp_loss 2.51949835\n",
            "dc_loss 20.1421471\n",
            "lp_loss 2.71873116\n",
            "dc_loss 41.3446884\n",
            "lp_loss 3.07446623\n",
            "dc_loss 54.8408203\n",
            "lp_loss 2.6658287\n",
            "dc_loss 62.8248901\n",
            "lp_loss 2.99240851\n",
            "dc_loss 31.0190029\n",
            "lp_loss 3.08267403\n",
            "dc_loss 49.122509\n",
            "lp_loss 2.89001608\n",
            "dc_loss 67.2481689\n",
            "lp_loss 2.39773083\n",
            "dc_loss 23.7318821\n",
            "lp_loss 2.53046322\n",
            "dc_loss 81.6374207\n",
            "lp_loss 2.77125669\n",
            "dc_loss 54.6973381\n",
            "lp_loss 4.70779371\n",
            "dc_loss 45.9539\n",
            "lp_loss 3.23084\n",
            "dc_loss 46.8107605\n",
            "lp_loss 3.10406017\n",
            "dc_loss 68.2937622\n",
            "lp_loss 2.69853044\n",
            "dc_loss 82.3570404\n",
            "lp_loss 2.84030581\n",
            "dc_loss 59.3955917\n",
            "lp_loss 2.94385719\n",
            "dc_loss 75.9095154\n",
            "lp_loss 2.54288769\n",
            "dc_loss 33.5143814\n",
            "lp_loss 3.20910788\n",
            "dc_loss 38.7307243\n",
            "lp_loss 3.16716051\n",
            "dc_loss 64.8862915\n",
            "lp_loss 3.07480955\n",
            "dc_loss 50.7013321\n",
            "lp_loss 2.57257318\n",
            "dc_loss 10.0882769\n",
            "lp_loss 2.36507607\n",
            "dc_loss 55.3717422\n",
            "lp_loss 2.98538661\n",
            "dc_loss 20.9187374\n",
            "lp_loss 2.92256498\n",
            "dc_loss 62.0112076\n",
            "lp_loss 2.9383831\n",
            "dc_loss 90.3546\n",
            "lp_loss 2.65571094\n",
            "dc_loss 21.4061489\n",
            "lp_loss 3.31674337\n",
            "dc_loss 39.5662\n",
            "lp_loss 3.00593543\n",
            "dc_loss 22.1486702\n",
            "lp_loss 3.213902\n",
            "dc_loss 10.7816296\n",
            "lp_loss 2.92809796\n",
            "dc_loss 36.8856812\n",
            "lp_loss 3.72658372\n",
            "dc_loss 56.2554207\n",
            "lp_loss 3.30423236\n",
            "dc_loss 66.4207535\n",
            "lp_loss 3.33866382\n",
            "dc_loss 71.4942932\n",
            "lp_loss 4.09295654\n",
            "dc_loss 51.7663269\n",
            "lp_loss 3.25493574\n",
            "dc_loss 49.9104042\n",
            "lp_loss 3.04807162\n",
            "dc_loss 75.8819\n",
            "lp_loss 2.8116498\n",
            "dc_loss 69.8183\n",
            "lp_loss 2.61361122\n",
            "dc_loss 24.3920174\n",
            "lp_loss 2.42916751\n",
            "dc_loss 31.977972\n",
            "lp_loss 3.11867261\n",
            "dc_loss 53.352356\n",
            "lp_loss 2.72184753\n",
            "dc_loss 28.8446693\n",
            "lp_loss 5.30130816\n",
            "dc_loss 31.3041286\n",
            "lp_loss 3.38087034\n",
            "dc_loss 37.6648827\n",
            "lp_loss 3.19426489\n",
            "dc_loss 66.6272354\n",
            "lp_loss 3.03220177\n",
            "dc_loss 57.8117599\n",
            "lp_loss 2.70015574\n",
            "dc_loss 59.5649338\n",
            "lp_loss 3.56290865\n",
            "dc_loss 50.4074326\n",
            "lp_loss 2.98734426\n",
            "dc_loss 47.1294174\n",
            "lp_loss 3.28854275\n",
            "dc_loss 10.9698715\n",
            "lp_loss 2.83644676\n",
            "dc_loss 43.9558334\n",
            "lp_loss 3.11531234\n",
            "dc_loss 96.274025\n",
            "lp_loss 3.21217203\n",
            "dc_loss 49.2560349\n",
            "lp_loss 3.39693642\n",
            "dc_loss 22.4557705\n",
            "lp_loss 2.65033484\n",
            "dc_loss 57.5237503\n",
            "lp_loss 3.05958128\n",
            "dc_loss 42.5966759\n",
            "lp_loss 3.84422278\n",
            "dc_loss 27.9287968\n",
            "lp_loss 2.70331883\n",
            "dc_loss 24.1497879\n",
            "lp_loss 2.65184402\n",
            "dc_loss 38.1823387\n",
            "lp_loss 2.85526514\n",
            "dc_loss 32.2246323\n",
            "lp_loss 2.69735765\n",
            "dc_loss 43.8769913\n",
            "lp_loss 3.24940419\n",
            "dc_loss 35.2487144\n",
            "lp_loss 2.6466651\n",
            "dc_loss 44.3193283\n",
            "lp_loss 3.26595306\n",
            "dc_loss 5.40024233\n",
            "lp_loss 2.45962381\n",
            "dc_loss 28.4237671\n",
            "lp_loss 3.03252792\n",
            "dc_loss 86.4525833\n",
            "lp_loss 3.75755262\n",
            "dc_loss 15.3214188\n",
            "lp_loss 3.12879324\n",
            "dc_loss 43.6089973\n",
            "lp_loss 2.91450763\n",
            "dc_loss 41.2710953\n",
            "lp_loss 2.86001897\n",
            "dc_loss 53.5009651\n",
            "lp_loss 2.49089909\n",
            "dc_loss 24.5251293\n",
            "lp_loss 3.78885794\n",
            "dc_loss 22.4312191\n",
            "lp_loss 3.45043731\n",
            "dc_loss 75.3791122\n",
            "lp_loss 3.2068603\n",
            "dc_loss 62.0646858\n",
            "lp_loss 3.17355347\n",
            "dc_loss 35.5576286\n",
            "lp_loss 2.44138432\n",
            "dc_loss 45.2502975\n",
            "lp_loss 2.5718658\n",
            "dc_loss 39.4428215\n",
            "lp_loss 2.35557032\n",
            "dc_loss 74.7303619\n",
            "lp_loss 3.17021132\n",
            "dc_loss 101.333847\n",
            "lp_loss 2.5194428\n",
            "dc_loss 54.3085327\n",
            "lp_loss 3.05224562\n",
            "dc_loss 74.3154068\n",
            "lp_loss 3.02269697\n",
            "dc_loss 63.8098564\n",
            "lp_loss 2.64313793\n",
            "dc_loss 15.5793\n",
            "lp_loss 3.17104983\n",
            "dc_loss 54.6297722\n",
            "lp_loss 2.70991087\n",
            "dc_loss 97.6165543\n",
            "lp_loss 3.10328317\n",
            "dc_loss 23.1385345\n",
            "lp_loss 3.29653025\n",
            "dc_loss 29.6765079\n",
            "lp_loss 2.59545708\n",
            "dc_loss 44.990181\n",
            "lp_loss 3.03335762\n",
            "dc_loss 25.6874905\n",
            "lp_loss 2.88844466\n",
            "dc_loss 54.1801376\n",
            "lp_loss 2.59243345\n",
            "dc_loss 56.8496094\n",
            "lp_loss 2.94597459\n",
            "dc_loss 52.5908928\n",
            "lp_loss 3.21742058\n",
            "dc_loss 47.4483299\n",
            "lp_loss 3.43537903\n",
            "dc_loss 83.2205658\n",
            "lp_loss 3.06293464\n",
            "dc_loss 42.7968483\n",
            "lp_loss 3.02406669\n",
            "dc_loss 69.9146\n",
            "lp_loss 2.49097872\n",
            "dc_loss 30.7457161\n",
            "lp_loss 3.10520124\n",
            "dc_loss 25.543047\n",
            "lp_loss 3.26723599\n",
            "dc_loss 61.0374374\n",
            "lp_loss 2.73645449\n",
            "dc_loss 26.2662754\n",
            "lp_loss 2.46081591\n",
            "dc_loss 44.6358643\n",
            "lp_loss 2.48815799\n",
            "dc_loss 46.6028328\n",
            "lp_loss 3.04016018\n",
            "dc_loss 50.0623894\n",
            "lp_loss 2.36593819\n",
            "dc_loss 52.4708786\n",
            "lp_loss 2.64784741\n",
            "dc_loss 66.8660736\n",
            "lp_loss 3.19564486\n",
            "dc_loss 37.0766792\n",
            "lp_loss 2.63784\n",
            "dc_loss 71.7489\n",
            "lp_loss 3.13010335\n",
            "dc_loss 28.9998817\n",
            "lp_loss 3.31134462\n",
            "dc_loss 4.99939489\n",
            "lp_loss 3.42730093\n",
            "dc_loss 64.0538635\n",
            "lp_loss 3.08153629\n",
            "dc_loss 52.7155647\n",
            "2020-02-06 18:08:27.935254\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.917613626\n",
            "domain_classification_accuracy: 0.181818187\n",
            "label_prediction_accuracy - Test: 0.829545438 2540\n",
            "label_prediction_accuracy - Target Test: 0.818181813\n",
            "label_prediction_accuracy - Target : 0.281481475\n",
            "Beginning of epoch: 5\n",
            "lp_loss 3.26085901\n",
            "dc_loss 40.3947144\n",
            "lp_loss 2.72556496\n",
            "dc_loss 85.5701675\n",
            "lp_loss 4.65117073\n",
            "dc_loss 54.7354546\n",
            "lp_loss 2.91507101\n",
            "dc_loss 49.8801956\n",
            "lp_loss 4.06746769\n",
            "dc_loss 36.0698471\n",
            "lp_loss 3.03213501\n",
            "dc_loss 63.0073624\n",
            "lp_loss 2.85327125\n",
            "dc_loss 38.1964\n",
            "lp_loss 3.143718\n",
            "dc_loss 27.9879417\n",
            "lp_loss 3.80483031\n",
            "dc_loss 33.9737282\n",
            "lp_loss 2.69574165\n",
            "dc_loss 44.0116196\n",
            "lp_loss 3.62463379\n",
            "dc_loss 22.1521416\n",
            "lp_loss 3.2419467\n",
            "dc_loss 48.711319\n",
            "lp_loss 2.98433733\n",
            "dc_loss 40.3968697\n",
            "lp_loss 2.63971376\n",
            "dc_loss 59.9359665\n",
            "lp_loss 2.56469107\n",
            "dc_loss 80.3282394\n",
            "lp_loss 3.18326139\n",
            "dc_loss 38.1636429\n",
            "lp_loss 3.03961325\n",
            "dc_loss 41.6827278\n",
            "lp_loss 2.49639821\n",
            "dc_loss 31.3501778\n",
            "lp_loss 3.19568872\n",
            "dc_loss 118.573608\n",
            "lp_loss 2.45564604\n",
            "dc_loss 51.2605972\n",
            "lp_loss 2.66630507\n",
            "dc_loss 37.9317398\n",
            "lp_loss 3.50581217\n",
            "dc_loss 87.5854187\n",
            "lp_loss 2.58435345\n",
            "dc_loss 78.788826\n",
            "lp_loss 2.49970531\n",
            "dc_loss 39.6120911\n",
            "lp_loss 2.3987174\n",
            "dc_loss 90.4980316\n",
            "lp_loss 3.66344619\n",
            "dc_loss 44.9237823\n",
            "lp_loss 3.05742741\n",
            "dc_loss 47.02388\n",
            "lp_loss 2.98540902\n",
            "dc_loss 51.1963196\n",
            "lp_loss 2.4090786\n",
            "dc_loss 36.533596\n",
            "lp_loss 3.03064895\n",
            "dc_loss 65.1520386\n",
            "lp_loss 2.48894644\n",
            "dc_loss 30.1798496\n",
            "lp_loss 2.99181342\n",
            "dc_loss 55.951149\n",
            "lp_loss 2.66551638\n",
            "dc_loss 66.0653381\n",
            "lp_loss 3.01811552\n",
            "dc_loss 57.2208176\n",
            "lp_loss 2.35453081\n",
            "dc_loss 21.8074493\n",
            "lp_loss 2.36455321\n",
            "dc_loss 82.3480225\n",
            "lp_loss 2.47481155\n",
            "dc_loss 30.8235588\n",
            "lp_loss 2.97550797\n",
            "dc_loss 23.0644035\n",
            "lp_loss 2.55012226\n",
            "dc_loss 63.7824211\n",
            "lp_loss 2.99572515\n",
            "dc_loss 84.1882935\n",
            "lp_loss 2.85701466\n",
            "dc_loss 36.749115\n",
            "lp_loss 2.54409194\n",
            "dc_loss 36.6541138\n",
            "lp_loss 2.95735741\n",
            "dc_loss 109.902199\n",
            "lp_loss 3.29493642\n",
            "dc_loss 80.7228241\n",
            "lp_loss 3.33717275\n",
            "dc_loss 53.8556442\n",
            "lp_loss 2.78390479\n",
            "dc_loss 89.3701477\n",
            "lp_loss 2.38608766\n",
            "dc_loss 68.3004913\n",
            "lp_loss 2.67604923\n",
            "dc_loss 56.366127\n",
            "lp_loss 2.48209453\n",
            "dc_loss 64.1192932\n",
            "lp_loss 3.05540085\n",
            "dc_loss 61.4055901\n",
            "lp_loss 3.27227974\n",
            "dc_loss 60.7818909\n",
            "lp_loss 3.52332854\n",
            "dc_loss 34.7192497\n",
            "lp_loss 3.08958054\n",
            "dc_loss 50.3377762\n",
            "lp_loss 2.61240768\n",
            "dc_loss 19.8364601\n",
            "lp_loss 3.35457182\n",
            "dc_loss 31.8037987\n",
            "lp_loss 3.4915638\n",
            "dc_loss 45.0585022\n",
            "lp_loss 3.97166395\n",
            "dc_loss 35.95121\n",
            "lp_loss 3.94717836\n",
            "dc_loss 79.3111191\n",
            "lp_loss 3.56895852\n",
            "dc_loss 25.5083065\n",
            "lp_loss 2.64313507\n",
            "dc_loss 60.064537\n",
            "lp_loss 2.67153978\n",
            "dc_loss 81.403183\n",
            "lp_loss 3.51125526\n",
            "dc_loss 125.864647\n",
            "lp_loss 2.64400053\n",
            "dc_loss 18.3915024\n",
            "lp_loss 2.81521368\n",
            "dc_loss 50.5449028\n",
            "lp_loss 3.10286689\n",
            "dc_loss 41.7333603\n",
            "lp_loss 3.16360283\n",
            "dc_loss 90.576355\n",
            "lp_loss 2.74847937\n",
            "dc_loss 88.4655075\n",
            "lp_loss 2.62207246\n",
            "dc_loss 42.1634331\n",
            "lp_loss 2.54034472\n",
            "dc_loss 27.8755894\n",
            "lp_loss 2.92786479\n",
            "dc_loss 37.5154\n",
            "lp_loss 2.6483283\n",
            "dc_loss 52.8386955\n",
            "lp_loss 2.58019257\n",
            "dc_loss 67.812851\n",
            "lp_loss 2.44270635\n",
            "dc_loss 48.3277931\n",
            "lp_loss 3.29804182\n",
            "dc_loss 73.2994919\n",
            "lp_loss 2.4239943\n",
            "dc_loss 38.4786682\n",
            "lp_loss 2.79603\n",
            "dc_loss 45.7781754\n",
            "lp_loss 3.1891675\n",
            "dc_loss 53.5491219\n",
            "lp_loss 2.96220875\n",
            "dc_loss 52.8809586\n",
            "lp_loss 2.76505804\n",
            "dc_loss 92.4632721\n",
            "lp_loss 2.48371553\n",
            "dc_loss 69.9174957\n",
            "lp_loss 2.32149029\n",
            "dc_loss 25.2384491\n",
            "lp_loss 3.73046136\n",
            "dc_loss 39.4541893\n",
            "lp_loss 2.69556451\n",
            "dc_loss 56.7427864\n",
            "lp_loss 2.33835149\n",
            "dc_loss 91.9975128\n",
            "lp_loss 2.70460987\n",
            "dc_loss 66.3525772\n",
            "lp_loss 2.61252451\n",
            "dc_loss 51.7485657\n",
            "lp_loss 3.41770506\n",
            "dc_loss 24.8356667\n",
            "lp_loss 2.73118496\n",
            "dc_loss 47.7882957\n",
            "lp_loss 3.2834549\n",
            "dc_loss 102.371346\n",
            "lp_loss 2.63077593\n",
            "dc_loss 45.3417053\n",
            "lp_loss 3.43543363\n",
            "dc_loss 59.1121712\n",
            "lp_loss 2.59722376\n",
            "dc_loss 60.5566101\n",
            "lp_loss 2.54149103\n",
            "dc_loss 21.7973843\n",
            "lp_loss 2.97377539\n",
            "dc_loss 37.8360176\n",
            "lp_loss 2.4324441\n",
            "dc_loss 42.311409\n",
            "lp_loss 2.55011463\n",
            "dc_loss 70.5891266\n",
            "lp_loss 3.00033665\n",
            "dc_loss 52.2434082\n",
            "lp_loss 3.13646078\n",
            "dc_loss 71.9479\n",
            "lp_loss 2.5908165\n",
            "dc_loss 79.5035\n",
            "lp_loss 2.92388391\n",
            "dc_loss 126.660706\n",
            "lp_loss 3.26073956\n",
            "dc_loss 84.9662933\n",
            "lp_loss 2.54176378\n",
            "dc_loss 84.4275818\n",
            "lp_loss 2.64825296\n",
            "dc_loss 50.0710258\n",
            "lp_loss 2.47881126\n",
            "dc_loss 72.4498291\n",
            "lp_loss 3.28119326\n",
            "dc_loss 71.654007\n",
            "lp_loss 2.88707638\n",
            "dc_loss 96.3181\n",
            "lp_loss 2.53445053\n",
            "dc_loss 48.2802544\n",
            "lp_loss 3.0176053\n",
            "dc_loss 38.1852493\n",
            "lp_loss 2.57335758\n",
            "dc_loss 30.6151695\n",
            "lp_loss 2.44045687\n",
            "dc_loss 40.901123\n",
            "lp_loss 3.61515331\n",
            "dc_loss 91.495491\n",
            "lp_loss 2.50468326\n",
            "dc_loss 61.360424\n",
            "lp_loss 3.32811427\n",
            "dc_loss 23.4210701\n",
            "lp_loss 2.54915524\n",
            "dc_loss 62.8270264\n",
            "lp_loss 2.41773272\n",
            "dc_loss 104.612717\n",
            "lp_loss 2.4603641\n",
            "dc_loss 81.2624283\n",
            "lp_loss 3.05020618\n",
            "dc_loss 71.7731476\n",
            "lp_loss 3.18958139\n",
            "dc_loss 59.2197189\n",
            "lp_loss 2.46792674\n",
            "dc_loss 73.8987503\n",
            "lp_loss 2.9459188\n",
            "dc_loss 64.4209747\n",
            "lp_loss 3.26943016\n",
            "dc_loss 79.4258041\n",
            "lp_loss 3.44617176\n",
            "dc_loss 43.1164322\n",
            "lp_loss 2.47144222\n",
            "dc_loss 61.66465\n",
            "lp_loss 2.82567835\n",
            "dc_loss 85.6994095\n",
            "lp_loss 2.58517075\n",
            "dc_loss 59.8803711\n",
            "lp_loss 3.46202898\n",
            "dc_loss 60.4128304\n",
            "lp_loss 2.83027959\n",
            "dc_loss 80.7351685\n",
            "lp_loss 3.89638305\n",
            "dc_loss 75.295\n",
            "lp_loss 4.39914274\n",
            "dc_loss 76.2251129\n",
            "lp_loss 3.5600183\n",
            "dc_loss 76.947\n",
            "lp_loss 3.05935931\n",
            "dc_loss 30.6997032\n",
            "lp_loss 3.14970493\n",
            "dc_loss 71.3599701\n",
            "lp_loss 2.69269371\n",
            "dc_loss 53.7101974\n",
            "lp_loss 3.10217047\n",
            "dc_loss 63.9447823\n",
            "lp_loss 2.5096488\n",
            "dc_loss 52.6175156\n",
            "lp_loss 4.11288071\n",
            "dc_loss 28.4690361\n",
            "lp_loss 3.86818123\n",
            "dc_loss 50.3089676\n",
            "lp_loss 3.08608365\n",
            "dc_loss 74.8236389\n",
            "lp_loss 2.45852661\n",
            "dc_loss 62.1689835\n",
            "lp_loss 2.40132093\n",
            "dc_loss 80.7607193\n",
            "lp_loss 3.20211363\n",
            "dc_loss 32.1772575\n",
            "lp_loss 3.27472663\n",
            "dc_loss 60.0156746\n",
            "lp_loss 2.4218564\n",
            "dc_loss 83.663147\n",
            "lp_loss 2.46084976\n",
            "dc_loss 30.0553703\n",
            "lp_loss 3.12613201\n",
            "dc_loss 68.8872757\n",
            "lp_loss 2.63078737\n",
            "dc_loss 43.1567039\n",
            "lp_loss 2.39993978\n",
            "dc_loss 40.7513618\n",
            "lp_loss 2.81211948\n",
            "dc_loss 33.4220352\n",
            "lp_loss 2.63350987\n",
            "dc_loss 71.0793\n",
            "lp_loss 3.19176579\n",
            "dc_loss 108.474342\n",
            "lp_loss 2.60520887\n",
            "dc_loss 67.8251953\n",
            "lp_loss 2.5289135\n",
            "dc_loss 66.4752\n",
            "lp_loss 3.87145877\n",
            "dc_loss 73.6758652\n",
            "lp_loss 2.25673723\n",
            "dc_loss 66.9552\n",
            "lp_loss 2.42492485\n",
            "dc_loss 57.6851807\n",
            "lp_loss 3.09987354\n",
            "dc_loss 35.0493469\n",
            "lp_loss 3.1961441\n",
            "dc_loss 54.6008224\n",
            "lp_loss 3.82360482\n",
            "dc_loss 54.9665337\n",
            "lp_loss 2.44766259\n",
            "dc_loss 69.5549469\n",
            "lp_loss 2.60644984\n",
            "dc_loss 105.115067\n",
            "lp_loss 3.02861023\n",
            "dc_loss 76.5918274\n",
            "lp_loss 2.62396717\n",
            "dc_loss 81.0373535\n",
            "lp_loss 2.58240104\n",
            "dc_loss 73.1394272\n",
            "lp_loss 3.18965173\n",
            "dc_loss 59.4131165\n",
            "lp_loss 3.16671371\n",
            "dc_loss 55.7107925\n",
            "lp_loss 3.69672227\n",
            "dc_loss 93.1574402\n",
            "lp_loss 2.70947075\n",
            "dc_loss 54.2508316\n",
            "lp_loss 2.94984794\n",
            "dc_loss 106.735985\n",
            "lp_loss 2.49066639\n",
            "dc_loss 111.293762\n",
            "lp_loss 3.25806713\n",
            "dc_loss 59.9219856\n",
            "lp_loss 2.59485579\n",
            "dc_loss 81.2224\n",
            "lp_loss 2.89692187\n",
            "dc_loss 72.0194321\n",
            "lp_loss 3.16909218\n",
            "dc_loss 44.9756432\n",
            "lp_loss 3.09718847\n",
            "dc_loss 65.2202148\n",
            "lp_loss 2.42880821\n",
            "dc_loss 67.0774307\n",
            "lp_loss 3.19004107\n",
            "dc_loss 52.5882339\n",
            "lp_loss 3.16089749\n",
            "dc_loss 40.2446594\n",
            "lp_loss 3.62915373\n",
            "dc_loss 61.3791504\n",
            "lp_loss 2.42587137\n",
            "dc_loss 40.6654854\n",
            "lp_loss 2.86463308\n",
            "dc_loss 13.3922195\n",
            "lp_loss 3.32925749\n",
            "dc_loss 54.1045761\n",
            "lp_loss 2.38298464\n",
            "dc_loss 81.8325348\n",
            "lp_loss 3.16186285\n",
            "dc_loss 42.011013\n",
            "lp_loss 3.01135206\n",
            "dc_loss 76.2580948\n",
            "lp_loss 3.47157812\n",
            "dc_loss 65.0423889\n",
            "lp_loss 2.47896576\n",
            "dc_loss 86.2465668\n",
            "lp_loss 2.71743894\n",
            "dc_loss 55.3968391\n",
            "lp_loss 2.7687645\n",
            "dc_loss 102.710892\n",
            "lp_loss 4.22064209\n",
            "dc_loss 103.052734\n",
            "lp_loss 2.53743863\n",
            "dc_loss 44.5812263\n",
            "lp_loss 2.67021322\n",
            "dc_loss 57.9207344\n",
            "lp_loss 2.97008944\n",
            "dc_loss 79.2190857\n",
            "lp_loss 3.21846437\n",
            "dc_loss 97.6592865\n",
            "lp_loss 3.10648584\n",
            "dc_loss 48.1241226\n",
            "lp_loss 4.11755753\n",
            "dc_loss 110.85659\n",
            "lp_loss 3.91213465\n",
            "dc_loss 29.2950401\n",
            "lp_loss 2.64393497\n",
            "dc_loss 50.291687\n",
            "lp_loss 2.71555543\n",
            "dc_loss 42.706974\n",
            "lp_loss 2.78304791\n",
            "dc_loss 69.4366913\n",
            "lp_loss 2.71866775\n",
            "dc_loss 49.3996582\n",
            "lp_loss 2.46952271\n",
            "dc_loss 81.4544067\n",
            "lp_loss 2.6189\n",
            "dc_loss 90.0633087\n",
            "lp_loss 3.30681705\n",
            "dc_loss 64.2591553\n",
            "lp_loss 2.91414046\n",
            "dc_loss 69.8707123\n",
            "lp_loss 3.21709299\n",
            "dc_loss 85.6286926\n",
            "lp_loss 2.50100613\n",
            "dc_loss 134.80748\n",
            "lp_loss 3.07226562\n",
            "dc_loss 17.6000042\n",
            "lp_loss 2.58849645\n",
            "dc_loss 63.5925407\n",
            "lp_loss 3.72796059\n",
            "dc_loss 93.6618\n",
            "lp_loss 2.94109297\n",
            "dc_loss 17.6466255\n",
            "lp_loss 2.65326595\n",
            "dc_loss 79.1103\n",
            "lp_loss 2.60542679\n",
            "dc_loss 65.6047516\n",
            "lp_loss 2.95805311\n",
            "dc_loss 96.4797668\n",
            "lp_loss 2.54202223\n",
            "dc_loss 97.2706757\n",
            "lp_loss 3.12543678\n",
            "dc_loss 43.0276108\n",
            "lp_loss 3.20193\n",
            "dc_loss 61.5647774\n",
            "lp_loss 2.52138186\n",
            "dc_loss 48.0402374\n",
            "lp_loss 2.45606375\n",
            "dc_loss 40.8557243\n",
            "lp_loss 3.5299716\n",
            "dc_loss 92.6140823\n",
            "lp_loss 2.92538595\n",
            "dc_loss 46.3444595\n",
            "lp_loss 2.43369102\n",
            "dc_loss 104.88591\n",
            "lp_loss 2.64776278\n",
            "dc_loss 54.6290779\n",
            "lp_loss 3.04737115\n",
            "dc_loss 71.2730255\n",
            "lp_loss 2.58239532\n",
            "dc_loss 91.4370346\n",
            "lp_loss 3.12837863\n",
            "dc_loss 38.1186142\n",
            "lp_loss 2.7556417\n",
            "dc_loss 66.1686783\n",
            "lp_loss 2.48562455\n",
            "dc_loss 102.555138\n",
            "lp_loss 2.40723085\n",
            "dc_loss 28.9430885\n",
            "lp_loss 2.61385489\n",
            "dc_loss 24.7566319\n",
            "lp_loss 3.39529252\n",
            "dc_loss 110.61412\n",
            "lp_loss 2.87652349\n",
            "dc_loss 38.4097672\n",
            "lp_loss 2.7260375\n",
            "dc_loss 51.5689316\n",
            "lp_loss 3.17660022\n",
            "dc_loss 150.972855\n",
            "lp_loss 2.54562759\n",
            "dc_loss 50.4656\n",
            "lp_loss 3.29963231\n",
            "dc_loss 122.39296\n",
            "lp_loss 3.08773\n",
            "dc_loss 127.831276\n",
            "lp_loss 3.33888912\n",
            "dc_loss 94.0890427\n",
            "lp_loss 2.80606699\n",
            "dc_loss 75.1518326\n",
            "lp_loss 2.76714873\n",
            "dc_loss 73.9723358\n",
            "lp_loss 2.84850121\n",
            "dc_loss 91.6021\n",
            "lp_loss 3.70715094\n",
            "dc_loss 22.6566124\n",
            "lp_loss 3.47353411\n",
            "dc_loss 121.319374\n",
            "lp_loss 2.85314\n",
            "dc_loss 43.1566086\n",
            "lp_loss 2.47590065\n",
            "dc_loss 43.9855957\n",
            "lp_loss 3.39410591\n",
            "dc_loss 101.127823\n",
            "lp_loss 2.96175623\n",
            "dc_loss 42.5109138\n",
            "lp_loss 2.80634212\n",
            "dc_loss 74.2271805\n",
            "lp_loss 3.47613215\n",
            "dc_loss 75.0912399\n",
            "lp_loss 2.46818542\n",
            "dc_loss 70.0791245\n",
            "lp_loss 3.34553552\n",
            "dc_loss 58.1854362\n",
            "lp_loss 2.46876979\n",
            "dc_loss 66.04039\n",
            "lp_loss 2.81889248\n",
            "dc_loss 75.3596573\n",
            "lp_loss 2.60404348\n",
            "dc_loss 57.7251053\n",
            "lp_loss 2.53913498\n",
            "dc_loss 99.7320786\n",
            "lp_loss 3.41812873\n",
            "dc_loss 40.6943474\n",
            "lp_loss 3.51734495\n",
            "dc_loss 121.960266\n",
            "lp_loss 2.74080038\n",
            "dc_loss 28.614399\n",
            "lp_loss 3.94318175\n",
            "dc_loss 94.9391632\n",
            "lp_loss 2.90971398\n",
            "dc_loss 72.8354187\n",
            "lp_loss 2.97335124\n",
            "dc_loss 57.2836\n",
            "lp_loss 2.65355825\n",
            "dc_loss 138.967606\n",
            "lp_loss 4.36908913\n",
            "dc_loss 85.7695923\n",
            "lp_loss 3.05229211\n",
            "dc_loss 76.4670639\n",
            "lp_loss 2.70902586\n",
            "dc_loss 125.189102\n",
            "2020-02-06 18:08:33.403701\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.868371189\n",
            "domain_classification_accuracy: 0.246212125\n",
            "label_prediction_accuracy - Test: 0.731060624 2804\n",
            "label_prediction_accuracy - Target Test: 0.731060624\n",
            "label_prediction_accuracy - Target : 0.290909082\n",
            "Beginning of epoch: 6\n",
            "lp_loss 2.59520698\n",
            "dc_loss 69.4460602\n",
            "lp_loss 2.96766782\n",
            "dc_loss 92.2462\n",
            "lp_loss 2.87875319\n",
            "dc_loss 56.0248528\n",
            "lp_loss 2.68414068\n",
            "dc_loss 17.1644936\n",
            "lp_loss 3.98908448\n",
            "dc_loss 25.6817379\n",
            "lp_loss 3.74877644\n",
            "dc_loss 77.3063126\n",
            "lp_loss 3.19016051\n",
            "dc_loss 104.245285\n",
            "lp_loss 2.4029088\n",
            "dc_loss 50.0654907\n",
            "lp_loss 2.58717299\n",
            "dc_loss 59.1492615\n",
            "lp_loss 2.72193408\n",
            "dc_loss 166.619949\n",
            "lp_loss 2.31496644\n",
            "dc_loss 100.075058\n",
            "lp_loss 2.74248719\n",
            "dc_loss 40.1510696\n",
            "lp_loss 4.09918594\n",
            "dc_loss 34.7447701\n",
            "lp_loss 2.93838835\n",
            "dc_loss 61.0447693\n",
            "lp_loss 3.05152655\n",
            "dc_loss 10.8481178\n",
            "lp_loss 3.14262986\n",
            "dc_loss 57.2564697\n",
            "lp_loss 2.66018295\n",
            "dc_loss 56.3582764\n",
            "lp_loss 2.9583168\n",
            "dc_loss 57.7641\n",
            "lp_loss 3.2796669\n",
            "dc_loss 118.474388\n",
            "lp_loss 3.11821747\n",
            "dc_loss 138.083893\n",
            "lp_loss 2.44742441\n",
            "dc_loss 31.1488457\n",
            "lp_loss 2.84402585\n",
            "dc_loss 119.088211\n",
            "lp_loss 4.28550148\n",
            "dc_loss 75.9584198\n",
            "lp_loss 2.45026469\n",
            "dc_loss 70.3433075\n",
            "lp_loss 2.79929829\n",
            "dc_loss 15.5594969\n",
            "lp_loss 4.03141737\n",
            "dc_loss 18.3530312\n",
            "lp_loss 3.12496233\n",
            "dc_loss 26.8400059\n",
            "lp_loss 3.16795588\n",
            "dc_loss 56.5738297\n",
            "lp_loss 3.17120409\n",
            "dc_loss 73.4313889\n",
            "lp_loss 2.50494957\n",
            "dc_loss 69.7433\n",
            "lp_loss 3.06666851\n",
            "dc_loss 41.8354416\n",
            "lp_loss 2.67703867\n",
            "dc_loss 66.720932\n",
            "lp_loss 3.56486702\n",
            "dc_loss 99.4318848\n",
            "lp_loss 2.52807879\n",
            "dc_loss 67.7516937\n",
            "lp_loss 3.10750675\n",
            "dc_loss 47.8801498\n",
            "lp_loss 3.06639099\n",
            "dc_loss 69.3661499\n",
            "lp_loss 2.37302041\n",
            "dc_loss 110.481628\n",
            "lp_loss 2.89384127\n",
            "dc_loss 93.761879\n",
            "lp_loss 2.45894194\n",
            "dc_loss 51.1790886\n",
            "lp_loss 2.6172967\n",
            "dc_loss 87.027153\n",
            "lp_loss 2.55478334\n",
            "dc_loss 107.788879\n",
            "lp_loss 3.20056629\n",
            "dc_loss 70.4338074\n",
            "lp_loss 3.05126929\n",
            "dc_loss 25.964777\n",
            "lp_loss 3.03832817\n",
            "dc_loss 90.6640701\n",
            "lp_loss 3.7225709\n",
            "dc_loss 88.6426544\n",
            "lp_loss 3.16306114\n",
            "dc_loss 94.6061\n",
            "lp_loss 3.13806534\n",
            "dc_loss 65.5370331\n",
            "lp_loss 2.97610807\n",
            "dc_loss 51.5708733\n",
            "lp_loss 2.51016879\n",
            "dc_loss 80.3898392\n",
            "lp_loss 3.43056679\n",
            "dc_loss 141.73407\n",
            "lp_loss 2.80111814\n",
            "dc_loss 69.1889191\n",
            "lp_loss 3.40960097\n",
            "dc_loss 60.6088028\n",
            "lp_loss 3.15448213\n",
            "dc_loss 36.2677841\n",
            "lp_loss 3.44556165\n",
            "dc_loss 54.2618637\n",
            "lp_loss 2.92842\n",
            "dc_loss 112.718666\n",
            "lp_loss 2.62766862\n",
            "dc_loss 56.2577133\n",
            "lp_loss 3.12863684\n",
            "dc_loss 36.1508408\n",
            "lp_loss 2.35163069\n",
            "dc_loss 54.7612076\n",
            "lp_loss 3.63957453\n",
            "dc_loss 92.2053604\n",
            "lp_loss 2.71627879\n",
            "dc_loss 68.3250351\n",
            "lp_loss 3.18078327\n",
            "dc_loss 64.3265\n",
            "lp_loss 2.88643169\n",
            "dc_loss 56.7787666\n",
            "lp_loss 2.38915348\n",
            "dc_loss 115.382889\n",
            "lp_loss 3.10816813\n",
            "dc_loss 57.0534286\n",
            "lp_loss 2.65188074\n",
            "dc_loss 58.0255203\n",
            "lp_loss 3.27150679\n",
            "dc_loss 114.980301\n",
            "lp_loss 2.76858115\n",
            "dc_loss 46.7830582\n",
            "lp_loss 2.65997267\n",
            "dc_loss 37.5066\n",
            "lp_loss 2.4406848\n",
            "dc_loss 109.646385\n",
            "lp_loss 2.98257732\n",
            "dc_loss 72.4338837\n",
            "lp_loss 3.06711411\n",
            "dc_loss 139.879364\n",
            "lp_loss 2.72959852\n",
            "dc_loss 127.230286\n",
            "lp_loss 3.14914894\n",
            "dc_loss 84.2715454\n",
            "lp_loss 3.71196723\n",
            "dc_loss 133.043976\n",
            "lp_loss 2.80985403\n",
            "dc_loss 158.66156\n",
            "lp_loss 2.94102192\n",
            "dc_loss 86.2418137\n",
            "lp_loss 3.87431526\n",
            "dc_loss 59.6076889\n",
            "lp_loss 2.87333441\n",
            "dc_loss 82.0369492\n",
            "lp_loss 2.49275064\n",
            "dc_loss 65.7751\n",
            "lp_loss 2.51767302\n",
            "dc_loss 75.6646\n",
            "lp_loss 2.51342511\n",
            "dc_loss 81.5924225\n",
            "lp_loss 2.66288495\n",
            "dc_loss 87.3544769\n",
            "lp_loss 2.86290693\n",
            "dc_loss 49.5560837\n",
            "lp_loss 2.48429275\n",
            "dc_loss 116.860207\n",
            "lp_loss 3.07979226\n",
            "dc_loss 37.1440163\n",
            "lp_loss 3.50448227\n",
            "dc_loss 155.183578\n",
            "lp_loss 2.38494492\n",
            "dc_loss 49.0297585\n",
            "lp_loss 3.70332456\n",
            "dc_loss 56.4274712\n",
            "lp_loss 2.27251768\n",
            "dc_loss 53.1549263\n",
            "lp_loss 3.90592408\n",
            "dc_loss 124.908897\n",
            "lp_loss 3.31732845\n",
            "dc_loss 117.916306\n",
            "lp_loss 4.04883957\n",
            "dc_loss 125.504868\n",
            "lp_loss 3.35004473\n",
            "dc_loss 56.0795784\n",
            "lp_loss 3.01008463\n",
            "dc_loss 55.7354927\n",
            "lp_loss 2.44884491\n",
            "dc_loss 74.8655701\n",
            "lp_loss 2.72932196\n",
            "dc_loss 131.679199\n",
            "lp_loss 2.64336014\n",
            "dc_loss 143.222748\n",
            "lp_loss 3.02701378\n",
            "dc_loss 92.6905594\n",
            "lp_loss 3.10838509\n",
            "dc_loss 38.9716377\n",
            "lp_loss 2.88348699\n",
            "dc_loss 116.356583\n",
            "lp_loss 3.56439543\n",
            "dc_loss 70.2921753\n",
            "lp_loss 2.37096286\n",
            "dc_loss 139.78537\n",
            "lp_loss 3.31646347\n",
            "dc_loss 86.0043564\n",
            "lp_loss 3.39396453\n",
            "dc_loss 117.520523\n",
            "lp_loss 2.61220264\n",
            "dc_loss 98.4619904\n",
            "lp_loss 2.76723\n",
            "dc_loss 78.4529877\n",
            "lp_loss 2.6568079\n",
            "dc_loss 86.9724\n",
            "lp_loss 3.0042758\n",
            "dc_loss 94.18927\n",
            "lp_loss 3.56084919\n",
            "dc_loss 78.9668579\n",
            "lp_loss 3.17460251\n",
            "dc_loss 67.4647\n",
            "lp_loss 2.53190517\n",
            "dc_loss 115.363258\n",
            "lp_loss 2.55548811\n",
            "dc_loss 88.7390671\n",
            "lp_loss 2.97055912\n",
            "dc_loss 74.6870804\n",
            "lp_loss 3.50188732\n",
            "dc_loss 60.422966\n",
            "lp_loss 3.08123899\n",
            "dc_loss 10.8347807\n",
            "lp_loss 3.33471251\n",
            "dc_loss 57.9173203\n",
            "lp_loss 3.10905623\n",
            "dc_loss 129.844284\n",
            "lp_loss 3.07124114\n",
            "dc_loss 46.1656189\n",
            "lp_loss 3.01247501\n",
            "dc_loss 59.9576225\n",
            "lp_loss 3.58217621\n",
            "dc_loss 67.1429443\n",
            "lp_loss 2.43355656\n",
            "dc_loss 101.548271\n",
            "lp_loss 2.8056016\n",
            "dc_loss 140.937668\n",
            "lp_loss 2.5126431\n",
            "dc_loss 134.957153\n",
            "lp_loss 2.85066223\n",
            "dc_loss 78.7457809\n",
            "lp_loss 2.51723242\n",
            "dc_loss 56.9559441\n",
            "lp_loss 2.56753588\n",
            "dc_loss 64.6820068\n",
            "lp_loss 2.66369295\n",
            "dc_loss 23.0712337\n",
            "lp_loss 2.80588341\n",
            "dc_loss 25.9882145\n",
            "lp_loss 3.58141422\n",
            "dc_loss 63.8501701\n",
            "lp_loss 2.66597819\n",
            "dc_loss 66.534584\n",
            "lp_loss 2.8187809\n",
            "dc_loss 81.254776\n",
            "lp_loss 2.50238252\n",
            "dc_loss 110.01709\n",
            "lp_loss 3.11118221\n",
            "dc_loss 62.1324692\n",
            "lp_loss 3.49474955\n",
            "dc_loss 68.4407425\n",
            "lp_loss 2.76459742\n",
            "dc_loss 66.8173\n",
            "lp_loss 3.05930471\n",
            "dc_loss 28.0384407\n",
            "lp_loss 2.44143367\n",
            "dc_loss 17.8802719\n",
            "lp_loss 2.78262663\n",
            "dc_loss 113.028481\n",
            "lp_loss 3.31337404\n",
            "dc_loss 144.545822\n",
            "lp_loss 3.04192\n",
            "dc_loss 140.404861\n",
            "lp_loss 3.15099859\n",
            "dc_loss 10.6765442\n",
            "lp_loss 2.43098569\n",
            "dc_loss 100.706635\n",
            "lp_loss 2.95759225\n",
            "dc_loss 139.925949\n",
            "lp_loss 2.93063664\n",
            "dc_loss 0.857119679\n",
            "lp_loss 4.04648495\n",
            "dc_loss 101.242188\n",
            "lp_loss 2.41049218\n",
            "dc_loss 50.6843796\n",
            "lp_loss 2.71214914\n",
            "dc_loss 53.2639847\n",
            "lp_loss 2.9808538\n",
            "dc_loss 77.1149521\n",
            "lp_loss 3.30238652\n",
            "dc_loss 36.1503181\n",
            "lp_loss 2.53591728\n",
            "dc_loss 68.02\n",
            "lp_loss 2.45473194\n",
            "dc_loss 82.314476\n",
            "lp_loss 2.86322498\n",
            "dc_loss 71.5796356\n",
            "lp_loss 3.32768488\n",
            "dc_loss 39.8949738\n",
            "lp_loss 3.23784971\n",
            "dc_loss 103.313416\n",
            "lp_loss 3.68310118\n",
            "dc_loss 54.9432869\n",
            "lp_loss 2.42823696\n",
            "dc_loss 132.595779\n",
            "lp_loss 3.06606\n",
            "dc_loss 93.2820282\n",
            "lp_loss 3.64700985\n",
            "dc_loss 78.4896393\n",
            "lp_loss 3.01751375\n",
            "dc_loss 95.6598511\n",
            "lp_loss 2.59555173\n",
            "dc_loss 65.587265\n",
            "lp_loss 2.87843847\n",
            "dc_loss 97.0444946\n",
            "lp_loss 3.115242\n",
            "dc_loss 78.7571\n",
            "lp_loss 3.17297292\n",
            "dc_loss 38.0980606\n",
            "lp_loss 2.2785604\n",
            "dc_loss 112.510521\n",
            "lp_loss 2.5871563\n",
            "dc_loss 75.2516937\n",
            "lp_loss 2.71624422\n",
            "dc_loss 104.086777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptZ9AVk1uiaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape = (48,52,3),classes = 11)\n",
        "inputs = tf.keras.Input(shape=(48,52,3))\n",
        "x = base_model.get_layer('block1_conv1')(inputs)\n",
        "x = base_model.get_layer('block1_conv2')(x)\n",
        "x = base_model.get_layer('block1_pool')(x)\n",
        "x = base_model.get_layer('block2_conv1')(x)\n",
        "y = Flatten()(x)\n",
        "outputs = tf.keras.layers.Dense(11, activation=tf.nn.softmax)(y)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0002),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFby75QU7UYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ca144cf3-c843-42f5-e6d3-2d3401c8d6e9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 48, 52, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 52, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 52, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 26, 128)       73856     \n",
            "_________________________________________________________________\n",
            "flatten_34 (Flatten)         (None, 79872)             0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 11)                878603    \n",
            "=================================================================\n",
            "Total params: 991,179\n",
            "Trainable params: 991,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jqqJjwpEAPH",
        "colab_type": "code",
        "outputId": "e52e4aa4-47bd-429f-b67b-fd349558fa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "x1 = np.squeeze(tf.reshape(upsampling.return_latent_variables(dataset.x_train), (upsampling.return_latent_variables(dataset.x_train).shape[0], 48,52,3)))\n",
        "x2 = np.squeeze(upsampling.return_latent_variables(dataset.x_target_test))\n",
        "x_val = np.squeeze(tf.reshape(upsampling.return_latent_variables(dataset.x_val), (upsampling.return_latent_variables(dataset.x_val).shape[0], 48,52,3)))\n",
        "y_val = dataset.y_val\n",
        "y1 = dataset.y_train\n",
        "y2 = dataset.y_target_test\n",
        "y3 = dataset.y_test\n",
        "#view1 = dataset.view_source\n",
        "#view2 = dataset.view_target\n",
        "#x = tf.concat([x1, x2], axis = 0)\n",
        "#views = tf.concat([view1, view2], axis = 0)\n",
        "model.fit(x1, y1, batch_size = 50, epochs = 20, verbose = True, validation_data = (x_val, y_val))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1056 samples, validate on 264 samples\n",
            "Epoch 1/20\n",
            "1056/1056 [==============================] - 1s 564us/sample - loss: 71.9950 - sparse_categorical_accuracy: 0.2254 - val_loss: 2.1741 - val_sparse_categorical_accuracy: 0.3485\n",
            "Epoch 2/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 1.3781 - sparse_categorical_accuracy: 0.5322 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.7841\n",
            "Epoch 3/20\n",
            "1056/1056 [==============================] - 0s 243us/sample - loss: 0.3352 - sparse_categorical_accuracy: 0.8816 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.8636\n",
            "Epoch 4/20\n",
            "1056/1056 [==============================] - 0s 247us/sample - loss: 0.1621 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.3696 - val_sparse_categorical_accuracy: 0.8561\n",
            "Epoch 5/20\n",
            "1056/1056 [==============================] - 0s 243us/sample - loss: 0.1112 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2758 - val_sparse_categorical_accuracy: 0.8977\n",
            "Epoch 6/20\n",
            "1056/1056 [==============================] - 0s 243us/sample - loss: 0.0610 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.3175 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 7/20\n",
            "1056/1056 [==============================] - 0s 245us/sample - loss: 0.0423 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9242\n",
            "Epoch 8/20\n",
            "1056/1056 [==============================] - 0s 242us/sample - loss: 0.0452 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9015\n",
            "Epoch 9/20\n",
            "1056/1056 [==============================] - 0s 243us/sample - loss: 0.0294 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.3026 - val_sparse_categorical_accuracy: 0.8788\n",
            "Epoch 10/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 0.0143 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.2428 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 11/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 0.0072 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2498 - val_sparse_categorical_accuracy: 0.9167\n",
            "Epoch 12/20\n",
            "1056/1056 [==============================] - 0s 242us/sample - loss: 0.0621 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9356\n",
            "Epoch 13/20\n",
            "1056/1056 [==============================] - 0s 241us/sample - loss: 0.0085 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.2531 - val_sparse_categorical_accuracy: 0.9129\n",
            "Epoch 14/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 0.0043 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2392 - val_sparse_categorical_accuracy: 0.9129\n",
            "Epoch 15/20\n",
            "1056/1056 [==============================] - 0s 242us/sample - loss: 0.0048 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.2950 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 16/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 0.0183 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.2769 - val_sparse_categorical_accuracy: 0.9129\n",
            "Epoch 17/20\n",
            "1056/1056 [==============================] - 0s 243us/sample - loss: 0.0061 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2870 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 18/20\n",
            "1056/1056 [==============================] - 0s 244us/sample - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2782 - val_sparse_categorical_accuracy: 0.9167\n",
            "Epoch 19/20\n",
            "1056/1056 [==============================] - 0s 245us/sample - loss: 9.8820e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2865 - val_sparse_categorical_accuracy: 0.9205\n",
            "Epoch 20/20\n",
            "1056/1056 [==============================] - 0s 246us/sample - loss: 8.4852e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2888 - val_sparse_categorical_accuracy: 0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1a43ff358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPpiIMp1ECo0",
        "colab_type": "code",
        "outputId": "08c0f7f5-3130-4908-d339-7626de8fec63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(np.squeeze(tf.reshape(upsampling.return_latent_variables(dataset.x_test), (upsampling.return_latent_variables(dataset.x_test).shape[0], 48,52,3))), y3)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165/165 [==============================] - 0s 142us/sample - loss: 9.9766 - sparse_categorical_accuracy: 0.1697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.976595572269325, 0.16969697]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46I5YJyA9V9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f5d4806-ec52-4cd2-c39c-27d124fa8ec5"
      },
      "source": [
        "model.get_layer('block2_conv1').output"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'block2_conv1/Identity:0' shape=(None, 24, 26, 128) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_j7rNBDFUCZ",
        "colab_type": "code",
        "outputId": "99be5e8f-826b-4c3d-c70a-b93bf887d146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
        "\n",
        "model1 = tf.keras.models.Model([model.inputs],[model.get_layer('block2_conv1').output, model.output])\n",
        "callbacks = [\n",
        "    GradCAMCallback(\n",
        "      validation_data=(x_val,y_val),\n",
        "        class_index=1,\n",
        "        output_dir='../grad_cam'\n",
        "    )]\n",
        "\n",
        "model.fit(x1, y1, batch_size = 2, epochs = 1, verbose = True, callbacks = callbacks)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-3476d7d5bdff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_explain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_cam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradCAMCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block2_conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m callbacks = [\n\u001b[1;32m      5\u001b[0m     GradCAMCallback(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 324\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_1:0\", shape=(None, 48, 52, 3), dtype=float32) at layer \"input_1\". The following previous layers were accessed without issue: ['input_2']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kEzuAKQFdQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "e81ddbab-5306-42a8-fe38-664e4290ab85"
      },
      "source": [
        "from tf_explain.callbacks.occlusion_sensitivity import OcclusionSensitivityCallback\n",
        "\n",
        "callbacks = [\n",
        "    OcclusionSensitivityCallback(\n",
        "        validation_data=(x_val, y_val),\n",
        "        class_index=0,\n",
        "        patch_size=2,\n",
        "        output_dir='../occlusion',\n",
        "    ),\n",
        "]\n",
        "\n",
        "model.fit(x1, y1, batch_size=2, epochs=2, callbacks=callbacks)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1056 samples\n",
            "Epoch 1/2\n",
            "1040/1056 [============================>.] - ETA: 0s - loss: 0.2500 - sparse_categorical_accuracy: 0.8942"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ec8cac1a49c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/callbacks/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOcclusionSensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         grid = explainer.explain(\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, class_index, patch_size, colormap)\u001b[0m\n\u001b[1;32m     47\u001b[0m             [\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sensitivity_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             ]\n\u001b[1;32m     51\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m             [\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sensitivity_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             ]\n\u001b[1;32m     51\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mget_sensitivity_map\u001b[0;34m(self, model, image, class_index, patch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mcoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         ):\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0msensitivity_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 24 is out of bounds for axis 0 with size 24"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yF58m3qQ1F-",
        "colab_type": "code",
        "outputId": "e6574cc2-2564-41cb-af31-aa8324f2f12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "basic = BasicModel(lr = [0.1,0.001,0.001])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log folder created as ../log/basic_model_13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P56GW_HnSbe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_crazy = Dataset(batch_size = 5, data_path_index = 1)\n",
        "dataset_crazy.load_dataset_paths()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvFNPfNrS2k-",
        "colab_type": "code",
        "outputId": "83176840-1cf7-494d-c5ef-109364ef36a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset_crazy.crossview_split(split_dict = split_dict['IXMAS']['allocentric'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training samples: 1056\n",
            "Validation samples: 264\n",
            "Test samples: 330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w10i65NvS9Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_basic(model_to_train, model_fe,  dataset, batch_size = None, epochs = 10):\n",
        "\n",
        "        if batch_size == None:\n",
        "            batch_size = dataset.batch_size\n",
        "            \n",
        "        source = dataset.source_paths  \n",
        "        size_source = len(source)\n",
        "        print('Source size:', size_source)\n",
        "        source = tf.data.Dataset.from_tensor_slices((source))\n",
        "        source = source.shuffle(size_source, reshuffle_each_iteration=True)\n",
        "        source = source.repeat(epochs).batch(batch_size)\n",
        "        \n",
        "        test = dataset.test_paths\n",
        "        size_test = len(test)\n",
        "        print('Test size:', size_test)\n",
        "        test = tf.data.Dataset.from_tensor_slices((test))\n",
        "        test = test.shuffle(size_test, reshuffle_each_iteration=True)\n",
        "        test = list(test)\n",
        "\n",
        "        size_target = len(dataset.target_paths)\n",
        "        target = dataset.target_paths\n",
        "        print('Target size:', size_target)\n",
        "        target = tf.data.Dataset.from_tensor_slices((target))\n",
        "        target = list(target)\n",
        "\n",
        "        dataset.loading_batches(batch = test, test = True, batch_size = size_test)\n",
        "        dataset.loading_batches(batch = target, target_test = True, batch_size = size_target)\n",
        "        x_target_test, y_target_test = dataset.x_target_test, dataset.y_target_test\n",
        "        counter = 0\n",
        "        epoch = 0\n",
        "        print(datetime.datetime.now())\n",
        "        print('Beginning of epoch:', epoch + 1)\n",
        "        for batch in source:\n",
        "            counter += 1\n",
        "            if np.floor(counter * batch_size / size_source) > epoch:\n",
        "                print(datetime.datetime.now())\n",
        "                epoch = np.floor(counter * batch_size / size_source)\n",
        "             \n",
        "                tf.print('testing')\n",
        "\n",
        "                #model_to_train.test_source_only(model_fe.return_latent_variables(dataset.x_val), dataset.y_val)\n",
        "                model_to_train.test_target(model_fe.return_latent_variables(x_target_test),y_target_test)\n",
        "                model_to_train.log()\n",
        "                    \n",
        "                \n",
        "                print('Beginning of epoch:', int(epoch + 1)) \n",
        "            dataset.loading_batches(batch = batch, source = True, test = False, target = False, batch_size = batch_size)\n",
        "            x_class, y_class, x_domain, views_class, views_domain = model_fe.return_latent_variables(dataset.x_train), dataset.y_train, dataset.x_test, dataset.view_train, dataset.view_test\n",
        "            \n",
        "               \n",
        "            model_to_train.single_train(x_class, y_class)\n",
        "            \n",
        "            #if (counter % 10) == 0:\n",
        "            #    model.log()\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mp39pfZZ9ue",
        "colab_type": "code",
        "outputId": "d4bafd2e-47fb-4f50-979b-33214000479d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_basic(basic, upsampling,  dataset_crazy, epochs = 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source size: 1056\n",
            "Test size: 264\n",
            "Target size: 330\n",
            "2020-01-30 19:30:16.548076\n",
            "Beginning of epoch: 1\n",
            "lp_loss 1.16368818\n",
            "lp_loss 0.545988441\n",
            "lp_loss 0.920503438\n",
            "lp_loss 1.94024372\n",
            "lp_loss 0.508986354\n",
            "lp_loss 0.604050279\n",
            "lp_loss 0.235701561\n",
            "lp_loss 0.205390617\n",
            "lp_loss 0.899050713\n",
            "lp_loss 0.347815812\n",
            "lp_loss 2.99601722\n",
            "lp_loss 0.77999258\n",
            "lp_loss 4.49892902\n",
            "lp_loss 1.20110118\n",
            "lp_loss 0.893284142\n",
            "lp_loss 1.04733431\n",
            "lp_loss 1.48916423\n",
            "lp_loss 3.09978056\n",
            "lp_loss 0.951269507\n",
            "lp_loss 2.57986856\n",
            "lp_loss 0.287584662\n",
            "lp_loss 1.10724473\n",
            "lp_loss 0.757636368\n",
            "lp_loss 0.376875252\n",
            "lp_loss 0.258089453\n",
            "lp_loss 3.13164759\n",
            "lp_loss 0.245135739\n",
            "lp_loss 1.39937532\n",
            "lp_loss 3.98866272\n",
            "lp_loss 1.40170515\n",
            "lp_loss 0.608978152\n",
            "lp_loss 1.38254619\n",
            "lp_loss 0.694128215\n",
            "lp_loss 0.0346269719\n",
            "lp_loss 0.516841471\n",
            "lp_loss 0.2021617\n",
            "lp_loss 1.86776853\n",
            "lp_loss 2.09439802\n",
            "lp_loss 4.08180428\n",
            "lp_loss 0.656950235\n",
            "lp_loss 0.527894\n",
            "lp_loss 1.23216677\n",
            "lp_loss 3.55550504\n",
            "lp_loss 1.00987244\n",
            "lp_loss 0.224117905\n",
            "lp_loss 0.607791781\n",
            "lp_loss 2.47576308\n",
            "lp_loss 0.928583264\n",
            "lp_loss 1.34871459\n",
            "lp_loss 0.528710723\n",
            "lp_loss 0.436169684\n",
            "lp_loss 0.381227165\n",
            "lp_loss 0.611883044\n",
            "lp_loss 0.672960103\n",
            "lp_loss 1.76596677\n",
            "lp_loss 1.78085303\n",
            "lp_loss 0.582014441\n",
            "lp_loss 1.29828429\n",
            "lp_loss 2.05202699\n",
            "lp_loss 0.227923393\n",
            "lp_loss 0.982624888\n",
            "lp_loss 0.666104436\n",
            "lp_loss 0.973745823\n",
            "lp_loss 0.218221471\n",
            "lp_loss 0.599386275\n",
            "lp_loss 0.296800077\n",
            "lp_loss 0.436097682\n",
            "lp_loss 0.30490905\n",
            "lp_loss 0.403674126\n",
            "lp_loss 0.66696924\n",
            "lp_loss 0.833480239\n",
            "lp_loss 2.51106453\n",
            "lp_loss 0.684954941\n",
            "lp_loss 1.27589536\n",
            "lp_loss 2.33225679\n",
            "lp_loss 2.518857\n",
            "lp_loss 0.888955\n",
            "lp_loss 1.27714217\n",
            "lp_loss 0.0968729109\n",
            "lp_loss 0.756727397\n",
            "lp_loss 1.65066624\n",
            "lp_loss 0.587090611\n",
            "lp_loss 1.13408804\n",
            "lp_loss 0.859333515\n",
            "lp_loss 0.883336902\n",
            "lp_loss 0.733289599\n",
            "lp_loss 0.516272\n",
            "lp_loss 0.0870985612\n",
            "lp_loss 0.545771897\n",
            "lp_loss 0.909698844\n",
            "lp_loss 0.172947213\n",
            "lp_loss 0.124089375\n",
            "lp_loss 2.82674813\n",
            "lp_loss 1.1990397\n",
            "lp_loss 0.357088774\n",
            "lp_loss 0.737615108\n",
            "lp_loss 1.76838326\n",
            "lp_loss 0.387642235\n",
            "lp_loss 0.570562243\n",
            "lp_loss 0.775837898\n",
            "lp_loss 0.401388109\n",
            "lp_loss 0.287664354\n",
            "lp_loss 1.27365732\n",
            "lp_loss 0.143063307\n",
            "lp_loss 0.454057455\n",
            "lp_loss 0.589845598\n",
            "lp_loss 0.827677071\n",
            "lp_loss 0.824450374\n",
            "lp_loss 1.02048039\n",
            "lp_loss 1.31055367\n",
            "lp_loss 0.95854032\n",
            "lp_loss 0.491168797\n",
            "lp_loss 0.108625546\n",
            "lp_loss 0.279293\n",
            "lp_loss 2.2106061\n",
            "lp_loss 0.821162879\n",
            "lp_loss 2.19972181\n",
            "lp_loss 1.00589824\n",
            "lp_loss 0.196944118\n",
            "lp_loss 0.311913162\n",
            "lp_loss 0.107814811\n",
            "lp_loss 1.70576644\n",
            "lp_loss 0.524956286\n",
            "lp_loss 1.40037656\n",
            "lp_loss 0.668616951\n",
            "lp_loss 2.5384531\n",
            "lp_loss 0.443683386\n",
            "lp_loss 2.31436944\n",
            "lp_loss 2.9718461\n",
            "lp_loss 1.17466128\n",
            "lp_loss 1.37039018\n",
            "lp_loss 1.247926\n",
            "lp_loss 0.212538525\n",
            "lp_loss 0.348630965\n",
            "lp_loss 0.452888876\n",
            "lp_loss 1.45668185\n",
            "lp_loss 2.43708277\n",
            "lp_loss 1.30930066\n",
            "lp_loss 0.375649482\n",
            "lp_loss 0.956641197\n",
            "lp_loss 1.70964599\n",
            "lp_loss 0.206123263\n",
            "lp_loss 1.05903924\n",
            "lp_loss 1.02010345\n",
            "lp_loss 0.847255886\n",
            "lp_loss 0.626457691\n",
            "lp_loss 0.655287683\n",
            "lp_loss 0.993003368\n",
            "lp_loss 0.293880612\n",
            "lp_loss 0.705591798\n",
            "lp_loss 1.09715438\n",
            "lp_loss 0.706311047\n",
            "lp_loss 0.666892588\n",
            "lp_loss 0.640248895\n",
            "lp_loss 0.403025\n",
            "lp_loss 1.22025275\n",
            "lp_loss 0.327845812\n",
            "lp_loss 1.10896134\n",
            "lp_loss 3.18515134\n",
            "lp_loss 0.441805303\n",
            "lp_loss 0.106608689\n",
            "lp_loss 0.338540852\n",
            "lp_loss 1.41071165\n",
            "lp_loss 0.108303472\n",
            "lp_loss 1.52963221\n",
            "lp_loss 0.347819984\n",
            "lp_loss 0.619634807\n",
            "lp_loss 0.555043101\n",
            "lp_loss 0.256390512\n",
            "lp_loss 1.68988109\n",
            "lp_loss 0.394851476\n",
            "lp_loss 0.385942549\n",
            "lp_loss 0.758828342\n",
            "lp_loss 0.411439031\n",
            "lp_loss 0.629707456\n",
            "lp_loss 0.252014309\n",
            "lp_loss 0.995105863\n",
            "lp_loss 0.689860106\n",
            "lp_loss 0.359026432\n",
            "lp_loss 0.4055852\n",
            "lp_loss 0.471203566\n",
            "lp_loss 1.82297444\n",
            "lp_loss 0.275851578\n",
            "lp_loss 0.408008397\n",
            "lp_loss 0.174488127\n",
            "lp_loss 0.118775681\n",
            "lp_loss 0.601954341\n",
            "lp_loss 0.606199145\n",
            "lp_loss 0.918187797\n",
            "lp_loss 0.161196068\n",
            "lp_loss 0.566213131\n",
            "lp_loss 1.97096848\n",
            "lp_loss 0.176022559\n",
            "lp_loss 0.369410872\n",
            "lp_loss 0.410286337\n",
            "lp_loss 0.416282237\n",
            "lp_loss 0.114538267\n",
            "lp_loss 0.928030968\n",
            "lp_loss 0.937257111\n",
            "lp_loss 0.610016704\n",
            "lp_loss 0.9576267\n",
            "lp_loss 0.395456314\n",
            "lp_loss 0.497062773\n",
            "lp_loss 0.973769188\n",
            "lp_loss 0.330677688\n",
            "lp_loss 0.153512195\n",
            "lp_loss 1.31714368\n",
            "lp_loss 0.155858189\n",
            "lp_loss 2.18773103\n",
            "lp_loss 0.822018743\n",
            "lp_loss 0.483554661\n",
            "2020-01-30 19:30:28.576139\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.745283\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 1795\n",
            "label_prediction_accuracy - Target: 0.209090903\n",
            "Beginning of epoch: 2\n",
            "lp_loss 0.839548588\n",
            "lp_loss 0.253500521\n",
            "lp_loss 1.98428082\n",
            "lp_loss 0.198449522\n",
            "lp_loss 0.529040694\n",
            "lp_loss 0.960953891\n",
            "lp_loss 0.511628032\n",
            "lp_loss 0.254635513\n",
            "lp_loss 2.4627552\n",
            "lp_loss 0.463439167\n",
            "lp_loss 0.40687862\n",
            "lp_loss 1.4547317\n",
            "lp_loss 0.113939956\n",
            "lp_loss 0.158493876\n",
            "lp_loss 0.821491838\n",
            "lp_loss 0.698713899\n",
            "lp_loss 0.588941038\n",
            "lp_loss 0.0766920596\n",
            "lp_loss 0.16151607\n",
            "lp_loss 1.03411639\n",
            "lp_loss 0.14081499\n",
            "lp_loss 1.61486852\n",
            "lp_loss 0.214374825\n",
            "lp_loss 1.11534262\n",
            "lp_loss 0.264142156\n",
            "lp_loss 0.266629398\n",
            "lp_loss 0.0976020843\n",
            "lp_loss 0.971856415\n",
            "lp_loss 0.873817801\n",
            "lp_loss 0.311428934\n",
            "lp_loss 1.0520438\n",
            "lp_loss 0.879143357\n",
            "lp_loss 0.791537464\n",
            "lp_loss 0.443406582\n",
            "lp_loss 1.59138656\n",
            "lp_loss 0.671490669\n",
            "lp_loss 0.0228805523\n",
            "lp_loss 0.338809431\n",
            "lp_loss 1.25114608\n",
            "lp_loss 1.58744562\n",
            "lp_loss 1.52912891\n",
            "lp_loss 2.01712728\n",
            "lp_loss 1.65155959\n",
            "lp_loss 0.718054771\n",
            "lp_loss 1.44859624\n",
            "lp_loss 0.371821821\n",
            "lp_loss 0.528284\n",
            "lp_loss 0.450007915\n",
            "lp_loss 0.872043788\n",
            "lp_loss 0.284392864\n",
            "lp_loss 0.198167145\n",
            "lp_loss 0.278384984\n",
            "lp_loss 0.214457244\n",
            "lp_loss 0.0693566129\n",
            "lp_loss 1.77672827\n",
            "lp_loss 0.0884685069\n",
            "lp_loss 0.870831788\n",
            "lp_loss 0.323085964\n",
            "lp_loss 0.292325556\n",
            "lp_loss 0.22277531\n",
            "lp_loss 0.683741391\n",
            "lp_loss 0.968786895\n",
            "lp_loss 0.807817101\n",
            "lp_loss 0.086711\n",
            "lp_loss 0.335028738\n",
            "lp_loss 0.532238662\n",
            "lp_loss 0.415503889\n",
            "lp_loss 1.15524614\n",
            "lp_loss 1.17504942\n",
            "lp_loss 0.102137744\n",
            "lp_loss 0.35505107\n",
            "lp_loss 1.42975366\n",
            "lp_loss 1.33661175\n",
            "lp_loss 0.36263141\n",
            "lp_loss 1.02339613\n",
            "lp_loss 1.74492764\n",
            "lp_loss 1.55793834\n",
            "lp_loss 0.536042094\n",
            "lp_loss 0.935609639\n",
            "lp_loss 1.82046437\n",
            "lp_loss 0.280686021\n",
            "lp_loss 2.07755804\n",
            "lp_loss 1.10591006\n",
            "lp_loss 0.418469727\n",
            "lp_loss 0.451351643\n",
            "lp_loss 1.89824033\n",
            "lp_loss 0.236209035\n",
            "lp_loss 0.255053282\n",
            "lp_loss 0.237277776\n",
            "lp_loss 0.98663789\n",
            "lp_loss 1.29806447\n",
            "lp_loss 0.687925935\n",
            "lp_loss 1.44473517\n",
            "lp_loss 0.184011728\n",
            "lp_loss 0.548356414\n",
            "lp_loss 0.381670564\n",
            "lp_loss 0.305976212\n",
            "lp_loss 0.896433055\n",
            "lp_loss 0.522941768\n",
            "lp_loss 0.651853681\n",
            "lp_loss 0.474075973\n",
            "lp_loss 0.194507614\n",
            "lp_loss 0.135937244\n",
            "lp_loss 0.894537747\n",
            "lp_loss 0.165003657\n",
            "lp_loss 0.948108077\n",
            "lp_loss 0.315146029\n",
            "lp_loss 0.593271911\n",
            "lp_loss 0.907046497\n",
            "lp_loss 0.109333776\n",
            "lp_loss 0.144166291\n",
            "lp_loss 0.170439631\n",
            "lp_loss 0.241134927\n",
            "lp_loss 0.652876198\n",
            "lp_loss 0.233384892\n",
            "lp_loss 0.133312568\n",
            "lp_loss 0.246777385\n",
            "lp_loss 0.173593044\n",
            "lp_loss 0.740318656\n",
            "lp_loss 0.300847769\n",
            "lp_loss 0.568634868\n",
            "lp_loss 0.236540794\n",
            "lp_loss 0.731021523\n",
            "lp_loss 0.406924963\n",
            "lp_loss 0.9698928\n",
            "lp_loss 0.201716229\n",
            "lp_loss 0.398310691\n",
            "lp_loss 0.339315116\n",
            "lp_loss 0.719751894\n",
            "lp_loss 1.01590788\n",
            "lp_loss 1.43324506\n",
            "lp_loss 0.987004101\n",
            "lp_loss 0.643515766\n",
            "lp_loss 0.236622766\n",
            "lp_loss 1.08401501\n",
            "lp_loss 0.22907123\n",
            "lp_loss 0.055772163\n",
            "lp_loss 0.833074093\n",
            "lp_loss 0.140941963\n",
            "lp_loss 1.22959125\n",
            "lp_loss 0.663646519\n",
            "lp_loss 0.459886372\n",
            "lp_loss 0.121835545\n",
            "lp_loss 0.15992856\n",
            "lp_loss 1.12410831\n",
            "lp_loss 0.538253367\n",
            "lp_loss 0.364196807\n",
            "lp_loss 0.348088622\n",
            "lp_loss 0.250032425\n",
            "lp_loss 0.621996\n",
            "lp_loss 0.571098924\n",
            "lp_loss 0.368132561\n",
            "lp_loss 0.743468165\n",
            "lp_loss 0.886234403\n",
            "lp_loss 0.970804513\n",
            "lp_loss 0.0915623754\n",
            "lp_loss 3.56020427\n",
            "lp_loss 0.725479245\n",
            "lp_loss 0.25138098\n",
            "lp_loss 0.150338173\n",
            "lp_loss 0.178921282\n",
            "lp_loss 0.616597056\n",
            "lp_loss 1.11866748\n",
            "lp_loss 2.03227854\n",
            "lp_loss 0.15662761\n",
            "lp_loss 2.13903904\n",
            "lp_loss 4.06831408\n",
            "lp_loss 0.911129177\n",
            "lp_loss 0.341311306\n",
            "lp_loss 0.687401056\n",
            "lp_loss 0.636784256\n",
            "lp_loss 0.419334412\n",
            "lp_loss 0.740529418\n",
            "lp_loss 0.547463417\n",
            "lp_loss 0.29124558\n",
            "lp_loss 0.872868717\n",
            "lp_loss 0.856183827\n",
            "lp_loss 0.209931657\n",
            "lp_loss 0.900342464\n",
            "lp_loss 0.735203266\n",
            "lp_loss 0.263403535\n",
            "lp_loss 0.620188534\n",
            "lp_loss 0.874617\n",
            "lp_loss 1.2783488\n",
            "lp_loss 2.10525703\n",
            "lp_loss 1.13220561\n",
            "lp_loss 0.624156475\n",
            "lp_loss 1.0195322\n",
            "lp_loss 0.66250813\n",
            "lp_loss 0.585015655\n",
            "lp_loss 0.857460797\n",
            "lp_loss 0.764759898\n",
            "lp_loss 0.382299751\n",
            "lp_loss 0.942901254\n",
            "lp_loss 0.870797932\n",
            "lp_loss 0.144171283\n",
            "lp_loss 1.87015569\n",
            "lp_loss 0.555640459\n",
            "lp_loss 0.219710588\n",
            "lp_loss 0.634672701\n",
            "lp_loss 2.31703639\n",
            "lp_loss 0.409194469\n",
            "lp_loss 0.367189527\n",
            "lp_loss 0.200150639\n",
            "lp_loss 0.693958461\n",
            "lp_loss 1.071854\n",
            "lp_loss 1.41189969\n",
            "lp_loss 2.05458212\n",
            "lp_loss 0.184182927\n",
            "lp_loss 0.664138734\n",
            "lp_loss 0.127214819\n",
            "2020-01-30 19:30:40.519301\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.788625598\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 2006\n",
            "label_prediction_accuracy - Target: 0.209090903\n",
            "Beginning of epoch: 3\n",
            "lp_loss 0.0617498085\n",
            "lp_loss 0.438426495\n",
            "lp_loss 0.172680199\n",
            "lp_loss 1.94218099\n",
            "lp_loss 1.99155116\n",
            "lp_loss 0.19621253\n",
            "lp_loss 0.191281825\n",
            "lp_loss 0.671587527\n",
            "lp_loss 0.36547175\n",
            "lp_loss 0.487712085\n",
            "lp_loss 0.480574667\n",
            "lp_loss 0.668891907\n",
            "lp_loss 0.658749342\n",
            "lp_loss 0.342399359\n",
            "lp_loss 0.437927067\n",
            "lp_loss 0.661683917\n",
            "lp_loss 1.08453727\n",
            "lp_loss 0.130077034\n",
            "lp_loss 0.52838558\n",
            "lp_loss 0.791518152\n",
            "lp_loss 0.40920496\n",
            "lp_loss 1.01012433\n",
            "lp_loss 1.2136209\n",
            "lp_loss 0.406417668\n",
            "lp_loss 0.330166817\n",
            "lp_loss 0.35405609\n",
            "lp_loss 0.300459057\n",
            "lp_loss 0.231647849\n",
            "lp_loss 0.102599844\n",
            "lp_loss 0.0388071872\n",
            "lp_loss 0.657351792\n",
            "lp_loss 0.83594954\n",
            "lp_loss 0.146884352\n",
            "lp_loss 1.25243688\n",
            "lp_loss 0.410122484\n",
            "lp_loss 1.55235457\n",
            "lp_loss 0.472136796\n",
            "lp_loss 0.510051906\n",
            "lp_loss 0.521845341\n",
            "lp_loss 0.259749562\n",
            "lp_loss 0.312347561\n",
            "lp_loss 0.0642527416\n",
            "lp_loss 0.337443501\n",
            "lp_loss 0.664575756\n",
            "lp_loss 1.09995294\n",
            "lp_loss 0.632499218\n",
            "lp_loss 1.00718319\n",
            "lp_loss 0.130844489\n",
            "lp_loss 0.904242516\n",
            "lp_loss 1.0331471\n",
            "lp_loss 1.42793524\n",
            "lp_loss 0.615771592\n",
            "lp_loss 0.0767304376\n",
            "lp_loss 0.52342689\n",
            "lp_loss 0.579419672\n",
            "lp_loss 0.680449069\n",
            "lp_loss 0.323317468\n",
            "lp_loss 0.796079576\n",
            "lp_loss 0.640051603\n",
            "lp_loss 0.874859929\n",
            "lp_loss 0.142947197\n",
            "lp_loss 0.954118371\n",
            "lp_loss 0.766130209\n",
            "lp_loss 1.42860103\n",
            "lp_loss 0.0430343933\n",
            "lp_loss 0.363892704\n",
            "lp_loss 0.746708333\n",
            "lp_loss 0.489717811\n",
            "lp_loss 0.974492431\n",
            "lp_loss 0.0484103225\n",
            "lp_loss 0.397795111\n",
            "lp_loss 1.27325642\n",
            "lp_loss 0.974501\n",
            "lp_loss 0.537963808\n",
            "lp_loss 1.17185175\n",
            "lp_loss 1.16474354\n",
            "lp_loss 1.2936058\n",
            "lp_loss 2.02367878\n",
            "lp_loss 4.04889345\n",
            "lp_loss 0.432705224\n",
            "lp_loss 0.436625957\n",
            "lp_loss 1.60125232\n",
            "lp_loss 0.844779\n",
            "lp_loss 0.226829961\n",
            "lp_loss 0.241462663\n",
            "lp_loss 0.291035503\n",
            "lp_loss 0.176488459\n",
            "lp_loss 0.399811685\n",
            "lp_loss 0.112851992\n",
            "lp_loss 0.529524505\n",
            "lp_loss 0.57238\n",
            "lp_loss 0.477122307\n",
            "lp_loss 0.0997618139\n",
            "lp_loss 0.578956902\n",
            "lp_loss 0.595679224\n",
            "lp_loss 0.663660347\n",
            "lp_loss 0.570455611\n",
            "lp_loss 0.889151\n",
            "lp_loss 0.351840407\n",
            "lp_loss 0.371599019\n",
            "lp_loss 0.736450791\n",
            "lp_loss 0.121086083\n",
            "lp_loss 0.601078749\n",
            "lp_loss 0.231362462\n",
            "lp_loss 0.63411808\n",
            "lp_loss 0.213821292\n",
            "lp_loss 1.61858678\n",
            "lp_loss 0.772815824\n",
            "lp_loss 0.265732259\n",
            "lp_loss 0.249842733\n",
            "lp_loss 0.114407226\n",
            "lp_loss 0.182119325\n",
            "lp_loss 0.0913227201\n",
            "lp_loss 0.557515264\n",
            "lp_loss 0.390060484\n",
            "lp_loss 0.464860022\n",
            "lp_loss 0.264547378\n",
            "lp_loss 0.832925498\n",
            "lp_loss 0.160152301\n",
            "lp_loss 1.03069913\n",
            "lp_loss 0.286840141\n",
            "lp_loss 0.396373659\n",
            "lp_loss 0.485709041\n",
            "lp_loss 0.120011926\n",
            "lp_loss 1.27414501\n",
            "lp_loss 0.415459156\n",
            "lp_loss 0.116642639\n",
            "lp_loss 0.878172398\n",
            "lp_loss 0.318912804\n",
            "lp_loss 1.04627216\n",
            "lp_loss 0.378453553\n",
            "lp_loss 0.229389071\n",
            "lp_loss 0.722149372\n",
            "lp_loss 0.22122173\n",
            "lp_loss 0.292509258\n",
            "lp_loss 0.198855087\n",
            "lp_loss 0.481150866\n",
            "lp_loss 0.429708\n",
            "lp_loss 0.743702769\n",
            "lp_loss 0.0842256695\n",
            "lp_loss 0.457420975\n",
            "lp_loss 0.710802674\n",
            "lp_loss 0.819711685\n",
            "lp_loss 0.471540868\n",
            "lp_loss 0.239947647\n",
            "lp_loss 1.10407889\n",
            "lp_loss 0.208581969\n",
            "lp_loss 0.781057835\n",
            "lp_loss 0.0826521516\n",
            "lp_loss 0.415201098\n",
            "lp_loss 1.99761081\n",
            "lp_loss 0.0968082771\n",
            "lp_loss 0.322577238\n",
            "lp_loss 0.588111877\n",
            "lp_loss 0.877982616\n",
            "lp_loss 1.06333518\n",
            "lp_loss 0.559638083\n",
            "lp_loss 0.353353322\n",
            "lp_loss 0.262560278\n",
            "lp_loss 3.21976018\n",
            "lp_loss 0.523682833\n",
            "lp_loss 0.113023654\n",
            "lp_loss 0.131687582\n",
            "lp_loss 0.0638875589\n",
            "lp_loss 0.623955846\n",
            "lp_loss 0.603484869\n",
            "lp_loss 1.5942663\n",
            "lp_loss 1.32026017\n",
            "lp_loss 1.08174717\n",
            "lp_loss 0.46462974\n",
            "lp_loss 0.172223881\n",
            "lp_loss 1.90357018\n",
            "lp_loss 0.354446322\n",
            "lp_loss 0.312245071\n",
            "lp_loss 1.13568604\n",
            "lp_loss 0.327465385\n",
            "lp_loss 0.307043552\n",
            "lp_loss 0.629854\n",
            "lp_loss 0.553407371\n",
            "lp_loss 0.806888282\n",
            "lp_loss 0.357018679\n",
            "lp_loss 1.02895451\n",
            "lp_loss 0.667505562\n",
            "lp_loss 0.455511332\n",
            "lp_loss 0.866807103\n",
            "lp_loss 0.836772561\n",
            "lp_loss 0.393361479\n",
            "lp_loss 0.181319743\n",
            "lp_loss 1.00449228\n",
            "lp_loss 0.0827273875\n",
            "lp_loss 0.765271783\n",
            "lp_loss 0.293987572\n",
            "lp_loss 1.32700861\n",
            "lp_loss 0.240837291\n",
            "lp_loss 0.273680985\n",
            "lp_loss 1.76947653\n",
            "lp_loss 0.569468141\n",
            "lp_loss 0.526606202\n",
            "lp_loss 0.814518631\n",
            "lp_loss 0.389652729\n",
            "lp_loss 0.557255328\n",
            "lp_loss 1.55897915\n",
            "lp_loss 0.84376061\n",
            "lp_loss 0.0912562\n",
            "lp_loss 0.342376083\n",
            "lp_loss 0.287636697\n",
            "lp_loss 0.4291026\n",
            "lp_loss 0.229817107\n",
            "lp_loss 0.50034982\n",
            "lp_loss 1.05052912\n",
            "lp_loss 0.331754535\n",
            "2020-01-30 19:30:52.408295\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.803791463\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 2217\n",
            "label_prediction_accuracy - Target: 0.227272734\n",
            "Beginning of epoch: 4\n",
            "lp_loss 0.194154114\n",
            "lp_loss 0.0636784509\n",
            "lp_loss 0.181423306\n",
            "lp_loss 0.338582695\n",
            "lp_loss 0.869273543\n",
            "lp_loss 0.39940083\n",
            "lp_loss 0.673483849\n",
            "lp_loss 0.0481290929\n",
            "lp_loss 0.778458178\n",
            "lp_loss 0.9455055\n",
            "lp_loss 0.0426775627\n",
            "lp_loss 0.617789328\n",
            "lp_loss 0.317362487\n",
            "lp_loss 0.661606848\n",
            "lp_loss 0.264594495\n",
            "lp_loss 0.258853942\n",
            "lp_loss 0.42543298\n",
            "lp_loss 0.698971868\n",
            "lp_loss 0.85809052\n",
            "lp_loss 0.700181782\n",
            "lp_loss 0.646396399\n",
            "lp_loss 0.583695173\n",
            "lp_loss 1.33293378\n",
            "lp_loss 0.203345254\n",
            "lp_loss 0.207449108\n",
            "lp_loss 0.831256509\n",
            "lp_loss 0.893705726\n",
            "lp_loss 0.808100402\n",
            "lp_loss 0.309431255\n",
            "lp_loss 1.00606763\n",
            "lp_loss 0.284786\n",
            "lp_loss 0.947605431\n",
            "lp_loss 0.147680402\n",
            "lp_loss 1.59634233\n",
            "lp_loss 1.09429669\n",
            "lp_loss 0.175306857\n",
            "lp_loss 0.220712036\n",
            "lp_loss 0.827333629\n",
            "lp_loss 0.0824279338\n",
            "lp_loss 0.358418554\n",
            "lp_loss 0.364523709\n",
            "lp_loss 1.04697978\n",
            "lp_loss 0.935291886\n",
            "lp_loss 0.184798568\n",
            "lp_loss 0.687225223\n",
            "lp_loss 0.266522318\n",
            "lp_loss 1.03550017\n",
            "lp_loss 0.63099283\n",
            "lp_loss 0.268973887\n",
            "lp_loss 0.205695435\n",
            "lp_loss 0.655168235\n",
            "lp_loss 0.347506732\n",
            "lp_loss 1.28199816\n",
            "lp_loss 0.838260829\n",
            "lp_loss 0.335699648\n",
            "lp_loss 0.655113876\n",
            "lp_loss 0.476091683\n",
            "lp_loss 0.617685616\n",
            "lp_loss 0.174394831\n",
            "lp_loss 0.498830378\n",
            "lp_loss 0.42904824\n",
            "lp_loss 1.59210241\n",
            "lp_loss 0.455961466\n",
            "lp_loss 0.018795684\n",
            "lp_loss 0.769195914\n",
            "lp_loss 1.02455842\n",
            "lp_loss 0.447298288\n",
            "lp_loss 0.517118335\n",
            "lp_loss 1.2542479\n",
            "lp_loss 0.124552049\n",
            "lp_loss 0.678937614\n",
            "lp_loss 0.658594728\n",
            "lp_loss 0.200959295\n",
            "lp_loss 1.25573802\n",
            "lp_loss 1.38952661\n",
            "lp_loss 0.425796747\n",
            "lp_loss 0.82169944\n",
            "lp_loss 0.263662219\n",
            "lp_loss 0.376791656\n",
            "lp_loss 0.912652791\n",
            "lp_loss 0.75362885\n",
            "lp_loss 1.00613785\n",
            "lp_loss 0.768751\n",
            "lp_loss 0.995462537\n",
            "lp_loss 0.393776089\n",
            "lp_loss 0.711553335\n",
            "lp_loss 1.43865263\n",
            "lp_loss 0.277121\n",
            "lp_loss 0.178928211\n",
            "lp_loss 0.849443436\n",
            "lp_loss 0.191331729\n",
            "lp_loss 0.407549143\n",
            "lp_loss 0.283559382\n",
            "lp_loss 0.75188303\n",
            "lp_loss 0.9756549\n",
            "lp_loss 0.219395712\n",
            "lp_loss 0.461666673\n",
            "lp_loss 1.10874605\n",
            "lp_loss 0.563167691\n",
            "lp_loss 0.576804459\n",
            "lp_loss 0.155410856\n",
            "lp_loss 0.294899404\n",
            "lp_loss 0.437748909\n",
            "lp_loss 0.536085844\n",
            "lp_loss 0.809729576\n",
            "lp_loss 0.683524\n",
            "lp_loss 1.18106818\n",
            "lp_loss 1.1026299\n",
            "lp_loss 0.0387441888\n",
            "lp_loss 0.321273923\n",
            "lp_loss 0.308545411\n",
            "lp_loss 0.659967303\n",
            "lp_loss 0.333694041\n",
            "lp_loss 0.118792437\n",
            "lp_loss 0.502257943\n",
            "lp_loss 1.14809906\n",
            "lp_loss 1.20904088\n",
            "lp_loss 0.0614707246\n",
            "lp_loss 0.249667048\n",
            "lp_loss 0.563584447\n",
            "lp_loss 0.21059835\n",
            "lp_loss 0.530931473\n",
            "lp_loss 0.655585408\n",
            "lp_loss 0.158590317\n",
            "lp_loss 1.01291156\n",
            "lp_loss 1.07783675\n",
            "lp_loss 0.0583609343\n",
            "lp_loss 1.12314\n",
            "lp_loss 0.333349943\n",
            "lp_loss 0.389981151\n",
            "lp_loss 0.309328705\n",
            "lp_loss 0.406323373\n",
            "lp_loss 0.370983779\n",
            "lp_loss 1.89912641\n",
            "lp_loss 0.27706036\n",
            "lp_loss 1.29584467\n",
            "lp_loss 0.0213037021\n",
            "lp_loss 0.309629411\n",
            "lp_loss 0.135025948\n",
            "lp_loss 1.89920211\n",
            "lp_loss 0.996160328\n",
            "lp_loss 0.215050936\n",
            "lp_loss 0.649222493\n",
            "lp_loss 0.917544\n",
            "lp_loss 0.416002035\n",
            "lp_loss 0.605141342\n",
            "lp_loss 0.467415512\n",
            "lp_loss 0.0816117\n",
            "lp_loss 0.099144\n",
            "lp_loss 1.54818797\n",
            "lp_loss 0.899316\n",
            "lp_loss 0.103156067\n",
            "lp_loss 0.0953262597\n",
            "lp_loss 0.233933613\n",
            "lp_loss 0.182894036\n",
            "lp_loss 0.470612913\n",
            "lp_loss 1.10825825\n",
            "lp_loss 0.462355912\n",
            "lp_loss 0.65856111\n",
            "lp_loss 0.072725676\n",
            "lp_loss 0.296026856\n",
            "lp_loss 0.346054971\n",
            "lp_loss 0.330310673\n",
            "lp_loss 0.695373952\n",
            "lp_loss 0.00582628744\n",
            "lp_loss 0.583652675\n",
            "lp_loss 1.78180575\n",
            "lp_loss 0.763605177\n",
            "lp_loss 0.264790297\n",
            "lp_loss 0.885597706\n",
            "lp_loss 0.696669936\n",
            "lp_loss 0.211151958\n",
            "lp_loss 0.296674788\n",
            "lp_loss 0.285281688\n",
            "lp_loss 0.688191354\n",
            "lp_loss 1.50631547\n",
            "lp_loss 1.08735204\n",
            "lp_loss 0.537416101\n",
            "lp_loss 0.507678449\n",
            "lp_loss 0.64558661\n",
            "lp_loss 1.35622728\n",
            "lp_loss 0.0395353772\n",
            "lp_loss 0.767360091\n",
            "lp_loss 0.960226417\n",
            "lp_loss 0.849218726\n",
            "lp_loss 0.0788332373\n",
            "lp_loss 1.51737678\n",
            "lp_loss 0.375113189\n",
            "lp_loss 0.644727409\n",
            "lp_loss 0.0552540533\n",
            "lp_loss 0.466869265\n",
            "lp_loss 0.452011347\n",
            "lp_loss 0.170260325\n",
            "lp_loss 0.327397168\n",
            "lp_loss 0.436492205\n",
            "lp_loss 0.477651268\n",
            "lp_loss 0.279046\n",
            "lp_loss 0.62268126\n",
            "lp_loss 0.718814969\n",
            "lp_loss 0.375389278\n",
            "lp_loss 0.275963485\n",
            "lp_loss 0.854007721\n",
            "lp_loss 0.916082203\n",
            "lp_loss 0.903256238\n",
            "lp_loss 0.535055161\n",
            "lp_loss 1.57862866\n",
            "lp_loss 0.921023726\n",
            "lp_loss 1.15341401\n",
            "lp_loss 0.366437018\n",
            "lp_loss 0.321662843\n",
            "lp_loss 0.8314206\n",
            "2020-01-30 19:31:04.648488\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.806635082\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 2428\n",
            "label_prediction_accuracy - Target: 0.233333334\n",
            "Beginning of epoch: 5\n",
            "lp_loss 0.539886\n",
            "lp_loss 0.500643373\n",
            "lp_loss 0.869164824\n",
            "lp_loss 1.36075091\n",
            "lp_loss 0.317113817\n",
            "lp_loss 1.07023239\n",
            "lp_loss 0.966667473\n",
            "lp_loss 0.925854564\n",
            "lp_loss 0.355066836\n",
            "lp_loss 0.199792296\n",
            "lp_loss 0.980511546\n",
            "lp_loss 0.0777689\n",
            "lp_loss 0.558589101\n",
            "lp_loss 0.397505343\n",
            "lp_loss 0.286479264\n",
            "lp_loss 0.458357\n",
            "lp_loss 0.152571484\n",
            "lp_loss 0.886972129\n",
            "lp_loss 1.05320108\n",
            "lp_loss 0.531119168\n",
            "lp_loss 0.973684132\n",
            "lp_loss 0.492343336\n",
            "lp_loss 0.398722172\n",
            "lp_loss 0.437284529\n",
            "lp_loss 0.793863893\n",
            "lp_loss 0.193216473\n",
            "lp_loss 0.097131893\n",
            "lp_loss 0.490234941\n",
            "lp_loss 0.0843861848\n",
            "lp_loss 0.81484735\n",
            "lp_loss 0.346245\n",
            "lp_loss 1.47606599\n",
            "lp_loss 0.944782734\n",
            "lp_loss 0.303724945\n",
            "lp_loss 0.0777110234\n",
            "lp_loss 1.05578768\n",
            "lp_loss 0.307876468\n",
            "lp_loss 0.200349689\n",
            "lp_loss 0.644863665\n",
            "lp_loss 1.09069765\n",
            "lp_loss 0.172149763\n",
            "lp_loss 0.259596169\n",
            "lp_loss 0.498225302\n",
            "lp_loss 1.92321706\n",
            "lp_loss 0.604017138\n",
            "lp_loss 0.189090699\n",
            "lp_loss 0.654239118\n",
            "lp_loss 0.137797028\n",
            "lp_loss 0.181770608\n",
            "lp_loss 0.252352476\n",
            "lp_loss 0.178516954\n",
            "lp_loss 0.0384738669\n",
            "lp_loss 0.24261713\n",
            "lp_loss 0.295028359\n",
            "lp_loss 1.99229681\n",
            "lp_loss 0.265604675\n",
            "lp_loss 1.07411611\n",
            "lp_loss 1.19989777\n",
            "lp_loss 0.398860842\n",
            "lp_loss 0.836224198\n",
            "lp_loss 0.716548562\n",
            "lp_loss 0.507840812\n",
            "lp_loss 0.345130265\n",
            "lp_loss 0.180064321\n",
            "lp_loss 0.8030653\n",
            "lp_loss 1.40105665\n",
            "lp_loss 0.278017491\n",
            "lp_loss 0.358413637\n",
            "lp_loss 0.141193971\n",
            "lp_loss 0.213475257\n",
            "lp_loss 1.06133902\n",
            "lp_loss 0.408781856\n",
            "lp_loss 1.09691596\n",
            "lp_loss 0.184166908\n",
            "lp_loss 1.03574407\n",
            "lp_loss 0.502350688\n",
            "lp_loss 0.730681777\n",
            "lp_loss 0.180727869\n",
            "lp_loss 0.85761404\n",
            "lp_loss 0.541625261\n",
            "lp_loss 0.40032658\n",
            "lp_loss 0.466885149\n",
            "lp_loss 0.641210198\n",
            "lp_loss 0.6408692\n",
            "lp_loss 0.0210406072\n",
            "lp_loss 0.305739373\n",
            "lp_loss 0.370568663\n",
            "lp_loss 0.883396804\n",
            "lp_loss 0.491653919\n",
            "lp_loss 0.188738868\n",
            "lp_loss 0.0547917485\n",
            "lp_loss 0.293777883\n",
            "lp_loss 0.254679978\n",
            "lp_loss 0.18437691\n",
            "lp_loss 0.580276072\n",
            "lp_loss 1.63823187\n",
            "lp_loss 0.420283258\n",
            "lp_loss 0.724548757\n",
            "lp_loss 2.07784605\n",
            "lp_loss 0.649657547\n",
            "lp_loss 0.277857244\n",
            "lp_loss 0.670409\n",
            "lp_loss 0.107140467\n",
            "lp_loss 0.457369983\n",
            "lp_loss 0.223855972\n",
            "lp_loss 1.3484509\n",
            "lp_loss 0.191308618\n",
            "lp_loss 1.2043525\n",
            "lp_loss 1.36389506\n",
            "lp_loss 1.77348018\n",
            "lp_loss 0.217387363\n",
            "lp_loss 0.058221627\n",
            "lp_loss 0.929032683\n",
            "lp_loss 0.781556\n",
            "lp_loss 0.92865169\n",
            "lp_loss 0.504904032\n",
            "lp_loss 0.101717904\n",
            "lp_loss 0.757681549\n",
            "lp_loss 0.200913221\n",
            "lp_loss 1.1287\n",
            "lp_loss 0.261362553\n",
            "lp_loss 0.527678\n",
            "lp_loss 0.371458352\n",
            "lp_loss 0.228632122\n",
            "lp_loss 0.336942971\n",
            "lp_loss 0.220224649\n",
            "lp_loss 0.378982961\n",
            "lp_loss 0.979010403\n",
            "lp_loss 0.234665707\n",
            "lp_loss 0.235744074\n",
            "lp_loss 0.369247139\n",
            "lp_loss 0.143314034\n",
            "lp_loss 0.126058832\n",
            "lp_loss 0.0777779669\n",
            "lp_loss 0.597824812\n",
            "lp_loss 0.145122916\n",
            "lp_loss 0.522338331\n",
            "lp_loss 1.82316041\n",
            "lp_loss 0.161441892\n",
            "lp_loss 0.416679561\n",
            "lp_loss 0.32380867\n",
            "lp_loss 0.728082657\n",
            "lp_loss 1.87571907\n",
            "lp_loss 0.461461246\n",
            "lp_loss 1.42903113\n",
            "lp_loss 1.64676309\n",
            "lp_loss 0.446765\n",
            "lp_loss 0.123893321\n",
            "lp_loss 0.351212561\n",
            "lp_loss 0.123898506\n",
            "lp_loss 1.26230741\n",
            "lp_loss 0.555267513\n",
            "lp_loss 2.2099123\n",
            "lp_loss 0.748428\n",
            "lp_loss 0.479666889\n",
            "lp_loss 0.684701264\n",
            "lp_loss 1.83317447\n",
            "lp_loss 0.413155854\n",
            "lp_loss 0.195818871\n",
            "lp_loss 0.309491336\n",
            "lp_loss 0.932816\n",
            "lp_loss 0.0711548179\n",
            "lp_loss 0.341594934\n",
            "lp_loss 0.215081692\n",
            "lp_loss 0.492076963\n",
            "lp_loss 0.112357691\n",
            "lp_loss 0.589643061\n",
            "lp_loss 1.61129189\n",
            "lp_loss 0.425161451\n",
            "lp_loss 1.30416894\n",
            "lp_loss 0.550027728\n",
            "lp_loss 1.38238633\n",
            "lp_loss 0.925024033\n",
            "lp_loss 1.1389668\n",
            "lp_loss 0.933711231\n",
            "lp_loss 0.956907153\n",
            "lp_loss 0.589316845\n",
            "lp_loss 0.314351499\n",
            "lp_loss 0.35437429\n",
            "lp_loss 0.530596733\n",
            "lp_loss 0.342777908\n",
            "lp_loss 0.0846073404\n",
            "lp_loss 0.384378344\n",
            "lp_loss 0.126476035\n",
            "lp_loss 2.55085087\n",
            "lp_loss 0.34542951\n",
            "lp_loss 0.582207561\n",
            "lp_loss 0.562488377\n",
            "lp_loss 0.419192255\n",
            "lp_loss 0.0929245204\n",
            "lp_loss 0.29076162\n",
            "lp_loss 0.788987637\n",
            "lp_loss 0.573898\n",
            "lp_loss 0.463003218\n",
            "lp_loss 0.618475199\n",
            "lp_loss 0.623963952\n",
            "lp_loss 0.828756332\n",
            "lp_loss 0.207991123\n",
            "lp_loss 0.137773708\n",
            "lp_loss 0.166034743\n",
            "lp_loss 0.166168705\n",
            "lp_loss 0.922776043\n",
            "lp_loss 0.350584745\n",
            "lp_loss 1.02485728\n",
            "lp_loss 1.66671348\n",
            "lp_loss 0.364699423\n",
            "lp_loss 0.258498\n",
            "lp_loss 1.59342241\n",
            "lp_loss 1.35261905\n",
            "lp_loss 0.683208287\n",
            "lp_loss 1.30486798\n",
            "2020-01-30 19:31:16.669671\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.810426533\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 2639\n",
            "label_prediction_accuracy - Target: 0.196969703\n",
            "Beginning of epoch: 6\n",
            "lp_loss 0.431916952\n",
            "lp_loss 0.162329853\n",
            "lp_loss 0.23143594\n",
            "lp_loss 0.0328680947\n",
            "lp_loss 0.267463624\n",
            "lp_loss 0.101741888\n",
            "lp_loss 0.216762215\n",
            "lp_loss 0.383807093\n",
            "lp_loss 0.18721123\n",
            "lp_loss 0.548591435\n",
            "lp_loss 1.20260799\n",
            "lp_loss 0.335827708\n",
            "lp_loss 0.746294618\n",
            "lp_loss 0.378817379\n",
            "lp_loss 1.81648827\n",
            "lp_loss 0.397066772\n",
            "lp_loss 0.258729696\n",
            "lp_loss 0.781634867\n",
            "lp_loss 1.10790586\n",
            "lp_loss 0.164679974\n",
            "lp_loss 0.373689353\n",
            "lp_loss 0.260485798\n",
            "lp_loss 0.118194461\n",
            "lp_loss 0.607616067\n",
            "lp_loss 3.09692\n",
            "lp_loss 0.295457333\n",
            "lp_loss 1.03240669\n",
            "lp_loss 0.349304348\n",
            "lp_loss 0.388194263\n",
            "lp_loss 0.137726545\n",
            "lp_loss 0.334154606\n",
            "lp_loss 1.61567712\n",
            "lp_loss 0.762341261\n",
            "lp_loss 0.359304309\n",
            "lp_loss 0.302376747\n",
            "lp_loss 0.192188486\n",
            "lp_loss 0.137730762\n",
            "lp_loss 0.191697642\n",
            "lp_loss 0.625683427\n",
            "lp_loss 0.357137948\n",
            "lp_loss 0.587935567\n",
            "lp_loss 0.118841648\n",
            "lp_loss 0.373856366\n",
            "lp_loss 0.297302783\n",
            "lp_loss 0.206991434\n",
            "lp_loss 1.8981787\n",
            "lp_loss 0.209362313\n",
            "lp_loss 0.428632021\n",
            "lp_loss 0.193745\n",
            "lp_loss 1.14549494\n",
            "lp_loss 0.0157011058\n",
            "lp_loss 1.27929449\n",
            "lp_loss 0.248564482\n",
            "lp_loss 0.762915254\n",
            "lp_loss 0.21576497\n",
            "lp_loss 0.367495149\n",
            "lp_loss 3.46353865\n",
            "lp_loss 1.030159\n",
            "lp_loss 0.725795746\n",
            "lp_loss 0.167043865\n",
            "lp_loss 0.421888918\n",
            "lp_loss 0.204376504\n",
            "lp_loss 0.535884\n",
            "lp_loss 0.0860994086\n",
            "lp_loss 0.328258812\n",
            "lp_loss 0.526729763\n",
            "lp_loss 0.291688412\n",
            "lp_loss 0.467452526\n",
            "lp_loss 0.122543611\n",
            "lp_loss 0.170733884\n",
            "lp_loss 0.365707338\n",
            "lp_loss 0.195159525\n",
            "lp_loss 0.175755695\n",
            "lp_loss 0.480781406\n",
            "lp_loss 0.0430041328\n",
            "lp_loss 0.371108502\n",
            "lp_loss 1.56588554\n",
            "lp_loss 0.487917423\n",
            "lp_loss 0.103800215\n",
            "lp_loss 0.797112703\n",
            "lp_loss 1.13708031\n",
            "lp_loss 0.22815299\n",
            "lp_loss 0.735512078\n",
            "lp_loss 2.672158\n",
            "lp_loss 0.0941441506\n",
            "lp_loss 0.235581845\n",
            "lp_loss 0.555834949\n",
            "lp_loss 0.335226148\n",
            "lp_loss 0.360229075\n",
            "lp_loss 0.49530381\n",
            "lp_loss 0.249711394\n",
            "lp_loss 0.698570073\n",
            "lp_loss 0.395278305\n",
            "lp_loss 0.986789048\n",
            "lp_loss 0.349229038\n",
            "lp_loss 0.337089181\n",
            "lp_loss 0.743290305\n",
            "lp_loss 0.441763967\n",
            "lp_loss 0.286574543\n",
            "lp_loss 1.44313502\n",
            "lp_loss 0.212221816\n",
            "lp_loss 0.695047081\n",
            "lp_loss 1.32633936\n",
            "lp_loss 0.642048359\n",
            "lp_loss 0.849893451\n",
            "lp_loss 0.108462848\n",
            "lp_loss 1.96266866\n",
            "lp_loss 1.49640584\n",
            "lp_loss 0.375043809\n",
            "lp_loss 0.255072176\n",
            "lp_loss 0.273674786\n",
            "lp_loss 1.14436328\n",
            "lp_loss 1.60726106\n",
            "lp_loss 0.95944804\n",
            "lp_loss 1.25701749\n",
            "lp_loss 0.122555122\n",
            "lp_loss 0.0750180706\n",
            "lp_loss 1.10423684\n",
            "lp_loss 0.346430749\n",
            "lp_loss 0.542464793\n",
            "lp_loss 0.443511069\n",
            "lp_loss 1.47002017\n",
            "lp_loss 0.378158927\n",
            "lp_loss 0.373572648\n",
            "lp_loss 0.0361236706\n",
            "lp_loss 1.15323353\n",
            "lp_loss 0.470485508\n",
            "lp_loss 0.337282568\n",
            "lp_loss 1.96868491\n",
            "lp_loss 0.402517408\n",
            "lp_loss 0.29169336\n",
            "lp_loss 0.217718095\n",
            "lp_loss 0.329609096\n",
            "lp_loss 0.251705706\n",
            "lp_loss 1.33331037\n",
            "lp_loss 1.04001784\n",
            "lp_loss 0.983431041\n",
            "lp_loss 0.119102761\n",
            "lp_loss 0.133569673\n",
            "lp_loss 1.05468142\n",
            "lp_loss 0.803949952\n",
            "lp_loss 0.682321489\n",
            "lp_loss 0.202222347\n",
            "lp_loss 0.482539266\n",
            "lp_loss 0.930605888\n",
            "lp_loss 0.600723088\n",
            "lp_loss 0.685651362\n",
            "lp_loss 0.108746968\n",
            "lp_loss 0.248137325\n",
            "lp_loss 0.452319533\n",
            "lp_loss 0.374064922\n",
            "lp_loss 0.0690741912\n",
            "lp_loss 0.562554538\n",
            "lp_loss 0.486614287\n",
            "lp_loss 0.487650812\n",
            "lp_loss 0.5391078\n",
            "lp_loss 1.50129724\n",
            "lp_loss 0.444809109\n",
            "lp_loss 0.212939262\n",
            "lp_loss 1.07957113\n",
            "lp_loss 1.65332317\n",
            "lp_loss 0.351911247\n",
            "lp_loss 0.474076182\n",
            "lp_loss 0.0923452452\n",
            "lp_loss 1.09316063\n",
            "lp_loss 1.0078131\n",
            "lp_loss 0.322220981\n",
            "lp_loss 0.195034415\n",
            "lp_loss 0.183265045\n",
            "lp_loss 0.476195633\n",
            "lp_loss 0.646792293\n",
            "lp_loss 0.218470186\n",
            "lp_loss 0.741086483\n",
            "lp_loss 0.566988766\n",
            "lp_loss 0.558183849\n",
            "lp_loss 0.0467231162\n",
            "lp_loss 1.19687915\n",
            "lp_loss 0.67881453\n",
            "lp_loss 0.523941159\n",
            "lp_loss 1.20827663\n",
            "lp_loss 1.18180943\n",
            "lp_loss 0.278760731\n",
            "lp_loss 0.784960687\n",
            "lp_loss 1.40639579\n",
            "lp_loss 0.476061046\n",
            "lp_loss 0.858789802\n",
            "lp_loss 0.727201223\n",
            "lp_loss 0.197125793\n",
            "lp_loss 0.307291269\n",
            "lp_loss 1.28248894\n",
            "lp_loss 0.378229678\n",
            "lp_loss 0.384459406\n",
            "lp_loss 0.237974793\n",
            "lp_loss 0.939013839\n",
            "lp_loss 0.635225415\n",
            "lp_loss 2.00512838\n",
            "lp_loss 0.842934489\n",
            "lp_loss 0.353298247\n",
            "lp_loss 0.827192187\n",
            "lp_loss 0.522190452\n",
            "lp_loss 0.202004582\n",
            "lp_loss 0.629093111\n",
            "lp_loss 0.26033324\n",
            "lp_loss 0.573937118\n",
            "lp_loss 1.10269594\n",
            "lp_loss 0.438816458\n",
            "lp_loss 0.177381277\n",
            "lp_loss 0.216271207\n",
            "lp_loss 0.10247121\n",
            "lp_loss 0.547859967\n",
            "lp_loss 0.401155859\n",
            "lp_loss 0.596843958\n",
            "2020-01-30 19:31:28.708631\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.825471699\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 2851\n",
            "label_prediction_accuracy - Target: 0.25151515\n",
            "Beginning of epoch: 7\n",
            "lp_loss 0.917688966\n",
            "lp_loss 0.188831508\n",
            "lp_loss 0.171180546\n",
            "lp_loss 0.207702592\n",
            "lp_loss 1.50411057\n",
            "lp_loss 0.84376061\n",
            "lp_loss 0.683243275\n",
            "lp_loss 2.20014215\n",
            "lp_loss 0.187343583\n",
            "lp_loss 0.362937629\n",
            "lp_loss 0.323815763\n",
            "lp_loss 2.88399577\n",
            "lp_loss 0.89470017\n",
            "lp_loss 0.140208364\n",
            "lp_loss 0.414100736\n",
            "lp_loss 0.961937785\n",
            "lp_loss 1.58230627\n",
            "lp_loss 0.587005794\n",
            "lp_loss 0.270381689\n",
            "lp_loss 0.233913824\n",
            "lp_loss 0.0192540735\n",
            "lp_loss 0.578404069\n",
            "lp_loss 1.43406415\n",
            "lp_loss 1.15240979\n",
            "lp_loss 1.21280432\n",
            "lp_loss 0.370891035\n",
            "lp_loss 0.128049463\n",
            "lp_loss 0.66657275\n",
            "lp_loss 0.316274732\n",
            "lp_loss 0.158607572\n",
            "lp_loss 0.264278829\n",
            "lp_loss 1.02785909\n",
            "lp_loss 1.13597655\n",
            "lp_loss 0.0927461609\n",
            "lp_loss 0.0974384919\n",
            "lp_loss 0.229364082\n",
            "lp_loss 1.07281435\n",
            "lp_loss 0.781848\n",
            "lp_loss 0.191519573\n",
            "lp_loss 0.184252575\n",
            "lp_loss 0.239733011\n",
            "lp_loss 0.254109472\n",
            "lp_loss 0.087536633\n",
            "lp_loss 0.125913396\n",
            "lp_loss 0.552994192\n",
            "lp_loss 0.361686409\n",
            "lp_loss 1.03409803\n",
            "lp_loss 0.305122554\n",
            "lp_loss 0.966265\n",
            "lp_loss 1.14461637\n",
            "lp_loss 0.586628258\n",
            "lp_loss 0.209968776\n",
            "lp_loss 0.578391671\n",
            "lp_loss 0.328630984\n",
            "lp_loss 0.197971448\n",
            "lp_loss 1.0097506\n",
            "lp_loss 0.182272911\n",
            "lp_loss 0.956831634\n",
            "lp_loss 1.27785265\n",
            "lp_loss 0.541078448\n",
            "lp_loss 0.500756323\n",
            "lp_loss 0.155056566\n",
            "lp_loss 0.179964751\n",
            "lp_loss 1.30854487\n",
            "lp_loss 0.0608713813\n",
            "lp_loss 1.70371151\n",
            "lp_loss 1.19138038\n",
            "lp_loss 0.15580821\n",
            "lp_loss 0.0924718231\n",
            "lp_loss 0.215132043\n",
            "lp_loss 1.05049038\n",
            "lp_loss 0.0278056469\n",
            "lp_loss 0.106081404\n",
            "lp_loss 0.605031371\n",
            "lp_loss 0.390565217\n",
            "lp_loss 0.50044167\n",
            "lp_loss 0.374895155\n",
            "lp_loss 2.12531137\n",
            "lp_loss 0.458758026\n",
            "lp_loss 0.125631526\n",
            "lp_loss 0.763754845\n",
            "lp_loss 1.79337728\n",
            "lp_loss 0.578576326\n",
            "lp_loss 0.100391641\n",
            "lp_loss 1.18555665\n",
            "lp_loss 0.238249347\n",
            "lp_loss 0.336741239\n",
            "lp_loss 0.210085899\n",
            "lp_loss 0.759117365\n",
            "lp_loss 0.194556624\n",
            "lp_loss 0.130259037\n",
            "lp_loss 0.845625877\n",
            "lp_loss 0.445190519\n",
            "lp_loss 0.197495386\n",
            "lp_loss 0.263308436\n",
            "lp_loss 0.0341635831\n",
            "lp_loss 0.0954256132\n",
            "lp_loss 0.577928722\n",
            "lp_loss 0.332104266\n",
            "lp_loss 1.0122112\n",
            "lp_loss 0.361830235\n",
            "lp_loss 0.137219459\n",
            "lp_loss 0.847335935\n",
            "lp_loss 0.380462885\n",
            "lp_loss 0.444834769\n",
            "lp_loss 0.642001927\n",
            "lp_loss 0.390346318\n",
            "lp_loss 0.742404342\n",
            "lp_loss 0.584005535\n",
            "lp_loss 0.429762304\n",
            "lp_loss 0.820895672\n",
            "lp_loss 0.313693225\n",
            "lp_loss 0.599293292\n",
            "lp_loss 0.325868934\n",
            "lp_loss 0.41117382\n",
            "lp_loss 0.833102822\n",
            "lp_loss 0.0197565518\n",
            "lp_loss 0.289621055\n",
            "lp_loss 1.41162229\n",
            "lp_loss 0.0934118181\n",
            "lp_loss 0.183299661\n",
            "lp_loss 0.659338057\n",
            "lp_loss 1.14849639\n",
            "lp_loss 0.564522207\n",
            "lp_loss 0.42771107\n",
            "lp_loss 0.151958793\n",
            "lp_loss 0.339686394\n",
            "lp_loss 0.218970537\n",
            "lp_loss 0.510013103\n",
            "lp_loss 0.314216316\n",
            "lp_loss 0.554959953\n",
            "lp_loss 0.062295936\n",
            "lp_loss 1.47768009\n",
            "lp_loss 0.424675465\n",
            "lp_loss 0.635924578\n",
            "lp_loss 0.164507896\n",
            "lp_loss 0.0377546921\n",
            "lp_loss 0.9854334\n",
            "lp_loss 0.12067382\n",
            "lp_loss 0.986942172\n",
            "lp_loss 0.251499\n",
            "lp_loss 0.411331177\n",
            "lp_loss 0.71577996\n",
            "lp_loss 0.0459891409\n",
            "lp_loss 0.082781665\n",
            "lp_loss 0.390053689\n",
            "lp_loss 0.0767908841\n",
            "lp_loss 0.496669114\n",
            "lp_loss 0.420689911\n",
            "lp_loss 0.735182583\n",
            "lp_loss 1.51092839\n",
            "lp_loss 0.119277641\n",
            "lp_loss 0.962636\n",
            "lp_loss 0.645193636\n",
            "lp_loss 0.77721405\n",
            "lp_loss 0.0651651\n",
            "lp_loss 0.08617194\n",
            "lp_loss 0.109736286\n",
            "lp_loss 0.219209835\n",
            "lp_loss 0.157185242\n",
            "lp_loss 0.570566475\n",
            "lp_loss 0.527683675\n",
            "lp_loss 0.49920702\n",
            "lp_loss 0.750164151\n",
            "lp_loss 0.635751903\n",
            "lp_loss 0.2591362\n",
            "lp_loss 0.261431843\n",
            "lp_loss 0.198306635\n",
            "lp_loss 1.00852668\n",
            "lp_loss 0.68303287\n",
            "lp_loss 4.77247524\n",
            "lp_loss 0.100604609\n",
            "lp_loss 0.321552545\n",
            "lp_loss 2.2141819\n",
            "lp_loss 0.0847780555\n",
            "lp_loss 0.256517857\n",
            "lp_loss 0.432387024\n",
            "lp_loss 0.204794198\n",
            "lp_loss 0.383999288\n",
            "lp_loss 0.86839658\n",
            "lp_loss 0.103244588\n",
            "lp_loss 0.245935887\n",
            "lp_loss 0.518503606\n",
            "lp_loss 0.317592263\n",
            "lp_loss 0.340572745\n",
            "lp_loss 0.585968137\n",
            "lp_loss 0.354767263\n",
            "lp_loss 1.10455859\n",
            "lp_loss 0.179547384\n",
            "lp_loss 0.406057596\n",
            "lp_loss 0.888575375\n",
            "lp_loss 0.363511503\n",
            "lp_loss 0.793337047\n",
            "lp_loss 1.43447125\n",
            "lp_loss 0.372527361\n",
            "lp_loss 1.48538399\n",
            "lp_loss 0.458746523\n",
            "lp_loss 0.102684058\n",
            "lp_loss 0.0338903368\n",
            "lp_loss 0.827899635\n",
            "lp_loss 0.346175581\n",
            "lp_loss 0.118938074\n",
            "lp_loss 0.0346407928\n",
            "lp_loss 0.0793814436\n",
            "lp_loss 0.388685197\n",
            "lp_loss 0.921441555\n",
            "lp_loss 0.358149916\n",
            "lp_loss 0.357792\n",
            "lp_loss 0.264790058\n",
            "lp_loss 0.808762252\n",
            "lp_loss 0.150541767\n",
            "2020-01-30 19:31:40.916884\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.843601882\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 3062\n",
            "label_prediction_accuracy - Target: 0.230303034\n",
            "Beginning of epoch: 8\n",
            "lp_loss 0.389881611\n",
            "lp_loss 0.244658351\n",
            "lp_loss 1.00784361\n",
            "lp_loss 0.540677071\n",
            "lp_loss 0.626101673\n",
            "lp_loss 0.0318783969\n",
            "lp_loss 0.321142048\n",
            "lp_loss 0.143329665\n",
            "lp_loss 0.275749415\n",
            "lp_loss 0.105841957\n",
            "lp_loss 0.314456165\n",
            "lp_loss 0.373921096\n",
            "lp_loss 0.16465649\n",
            "lp_loss 0.0189092811\n",
            "lp_loss 0.471119791\n",
            "lp_loss 0.176048741\n",
            "lp_loss 0.153829172\n",
            "lp_loss 0.183882564\n",
            "lp_loss 0.131266281\n",
            "lp_loss 1.94115138\n",
            "lp_loss 1.25207245\n",
            "lp_loss 0.382732928\n",
            "lp_loss 0.140161961\n",
            "lp_loss 0.15182665\n",
            "lp_loss 0.597619176\n",
            "lp_loss 0.323147833\n",
            "lp_loss 1.81459486\n",
            "lp_loss 0.166307122\n",
            "lp_loss 0.252245903\n",
            "lp_loss 0.909359097\n",
            "lp_loss 0.34600091\n",
            "lp_loss 0.600113332\n",
            "lp_loss 1.19128394\n",
            "lp_loss 1.0083375\n",
            "lp_loss 0.542469621\n",
            "lp_loss 0.30870083\n",
            "lp_loss 0.23304446\n",
            "lp_loss 0.137978345\n",
            "lp_loss 0.473055184\n",
            "lp_loss 0.541805267\n",
            "lp_loss 0.361628592\n",
            "lp_loss 0.120746255\n",
            "lp_loss 0.547368526\n",
            "lp_loss 0.897577286\n",
            "lp_loss 0.436880022\n",
            "lp_loss 1.04789805\n",
            "lp_loss 0.0429407284\n",
            "lp_loss 0.272781432\n",
            "lp_loss 0.395717472\n",
            "lp_loss 0.281863749\n",
            "lp_loss 0.541681528\n",
            "lp_loss 0.767903507\n",
            "lp_loss 0.169878513\n",
            "lp_loss 0.392597377\n",
            "lp_loss 0.482301414\n",
            "lp_loss 0.235294893\n",
            "lp_loss 0.531953931\n",
            "lp_loss 0.361859113\n",
            "lp_loss 0.714683235\n",
            "lp_loss 0.320760667\n",
            "lp_loss 0.64176625\n",
            "lp_loss 0.23102209\n",
            "lp_loss 0.261248887\n",
            "lp_loss 0.373545438\n",
            "lp_loss 0.0796952769\n",
            "lp_loss 0.106459282\n",
            "lp_loss 0.645744503\n",
            "lp_loss 0.391614795\n",
            "lp_loss 0.483645439\n",
            "lp_loss 1.05173063\n",
            "lp_loss 1.52870309\n",
            "lp_loss 0.310459942\n",
            "lp_loss 0.782261848\n",
            "lp_loss 0.977593899\n",
            "lp_loss 0.752412617\n",
            "lp_loss 1.82929099\n",
            "lp_loss 1.1623621\n",
            "lp_loss 0.438241094\n",
            "lp_loss 0.393485606\n",
            "lp_loss 1.62018299\n",
            "lp_loss 1.05628932\n",
            "lp_loss 0.215698481\n",
            "lp_loss 1.35924101\n",
            "lp_loss 0.592916906\n",
            "lp_loss 0.157996014\n",
            "lp_loss 0.288279027\n",
            "lp_loss 0.441326767\n",
            "lp_loss 0.585083783\n",
            "lp_loss 0.348998904\n",
            "lp_loss 0.165125892\n",
            "lp_loss 0.138886064\n",
            "lp_loss 1.1645062\n",
            "lp_loss 0.303916156\n",
            "lp_loss 1.83056486\n",
            "lp_loss 1.13547015\n",
            "lp_loss 0.684015334\n",
            "lp_loss 0.209551841\n",
            "lp_loss 0.672579646\n",
            "lp_loss 0.322028309\n",
            "lp_loss 0.374176353\n",
            "lp_loss 1.40170836\n",
            "lp_loss 0.257139206\n",
            "lp_loss 0.312102646\n",
            "lp_loss 0.600501\n",
            "lp_loss 0.237596273\n",
            "lp_loss 0.0256942846\n",
            "lp_loss 0.908954322\n",
            "lp_loss 4.99567699\n",
            "lp_loss 0.756779552\n",
            "lp_loss 0.187060326\n",
            "lp_loss 0.527749538\n",
            "lp_loss 1.01233506\n",
            "lp_loss 0.0839458331\n",
            "lp_loss 0.380293339\n",
            "lp_loss 0.997258663\n",
            "lp_loss 1.06651855\n",
            "lp_loss 0.0868769065\n",
            "lp_loss 0.174425259\n",
            "lp_loss 0.516737878\n",
            "lp_loss 0.258547217\n",
            "lp_loss 0.379297405\n",
            "lp_loss 0.633932292\n",
            "lp_loss 1.18713546\n",
            "lp_loss 0.0543851256\n",
            "lp_loss 0.381295592\n",
            "lp_loss 1.12467349\n",
            "lp_loss 0.218350559\n",
            "lp_loss 0.324729502\n",
            "lp_loss 0.780643344\n",
            "lp_loss 0.251367837\n",
            "lp_loss 1.45467472\n",
            "lp_loss 0.231068209\n",
            "lp_loss 1.11082149\n",
            "lp_loss 0.590870082\n",
            "lp_loss 0.414729297\n",
            "lp_loss 0.696963787\n",
            "lp_loss 0.510994196\n",
            "lp_loss 0.440754741\n",
            "lp_loss 0.116447404\n",
            "lp_loss 0.105781034\n",
            "lp_loss 0.886261\n",
            "lp_loss 0.800259471\n",
            "lp_loss 1.57912683\n",
            "lp_loss 0.41103524\n",
            "lp_loss 0.33486411\n",
            "lp_loss 0.259631127\n",
            "lp_loss 0.383455187\n",
            "lp_loss 0.23536773\n",
            "lp_loss 0.6149773\n",
            "lp_loss 0.416410029\n",
            "lp_loss 1.07116413\n",
            "lp_loss 0.259587705\n",
            "lp_loss 0.564791381\n",
            "lp_loss 0.193704188\n",
            "lp_loss 0.111588255\n",
            "lp_loss 0.337165833\n",
            "lp_loss 0.753864825\n",
            "lp_loss 0.32318455\n",
            "lp_loss 0.669013321\n",
            "lp_loss 0.495351017\n",
            "lp_loss 0.307277501\n",
            "lp_loss 0.449727207\n",
            "lp_loss 0.548252285\n",
            "lp_loss 0.108900547\n",
            "lp_loss 0.347887874\n",
            "lp_loss 0.844195247\n",
            "lp_loss 0.455426931\n",
            "lp_loss 0.19105342\n",
            "lp_loss 0.696175277\n",
            "lp_loss 0.317315578\n",
            "lp_loss 0.137390405\n",
            "lp_loss 0.324498743\n",
            "lp_loss 0.320217311\n",
            "lp_loss 0.306532681\n",
            "lp_loss 0.784611702\n",
            "lp_loss 0.497327387\n",
            "lp_loss 0.3329162\n",
            "lp_loss 0.159524173\n",
            "lp_loss 0.220188096\n",
            "lp_loss 0.557376742\n",
            "lp_loss 0.31117332\n",
            "lp_loss 0.559351385\n",
            "lp_loss 0.514051676\n",
            "lp_loss 0.415800184\n",
            "lp_loss 0.763296902\n",
            "lp_loss 0.593343735\n",
            "lp_loss 0.354074717\n",
            "lp_loss 0.712981\n",
            "lp_loss 0.278886616\n",
            "lp_loss 0.747830212\n",
            "lp_loss 0.912757039\n",
            "lp_loss 0.455625206\n",
            "lp_loss 0.613720953\n",
            "lp_loss 0.233828947\n",
            "lp_loss 0.453605324\n",
            "lp_loss 0.166116908\n",
            "lp_loss 0.537507892\n",
            "lp_loss 0.0603722855\n",
            "lp_loss 0.358876169\n",
            "lp_loss 0.6832757\n",
            "lp_loss 0.0550318\n",
            "lp_loss 0.270633429\n",
            "lp_loss 0.411147594\n",
            "lp_loss 1.74691939\n",
            "lp_loss 0.344477147\n",
            "lp_loss 1.15777898\n",
            "lp_loss 1.19185925\n",
            "lp_loss 0.830502868\n",
            "lp_loss 0.887671769\n",
            "lp_loss 0.252566755\n",
            "lp_loss 0.333974779\n",
            "2020-01-30 19:31:52.999811\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.836966813\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 3273\n",
            "label_prediction_accuracy - Target: 0.24242425\n",
            "Beginning of epoch: 9\n",
            "lp_loss 0.149927586\n",
            "lp_loss 0.0927556306\n",
            "lp_loss 1.14353955\n",
            "lp_loss 0.469343424\n",
            "lp_loss 0.109646738\n",
            "lp_loss 0.510172725\n",
            "lp_loss 0.310233712\n",
            "lp_loss 0.856111646\n",
            "lp_loss 0.0745172\n",
            "lp_loss 0.0985471\n",
            "lp_loss 0.730420947\n",
            "lp_loss 1.24437165\n",
            "lp_loss 0.364032447\n",
            "lp_loss 1.40062022\n",
            "lp_loss 0.546901166\n",
            "lp_loss 1.46805298\n",
            "lp_loss 0.287808\n",
            "lp_loss 0.370555103\n",
            "lp_loss 0.346242249\n",
            "lp_loss 0.0696436912\n",
            "lp_loss 0.284725457\n",
            "lp_loss 1.35987401\n",
            "lp_loss 0.371391565\n",
            "lp_loss 0.206684038\n",
            "lp_loss 0.471619844\n",
            "lp_loss 0.352605283\n",
            "lp_loss 0.380453676\n",
            "lp_loss 0.182180107\n",
            "lp_loss 0.986262441\n",
            "lp_loss 0.491354406\n",
            "lp_loss 0.379776716\n",
            "lp_loss 0.428064018\n",
            "lp_loss 0.384268463\n",
            "lp_loss 0.346993387\n",
            "lp_loss 1.04125452\n",
            "lp_loss 0.382745266\n",
            "lp_loss 0.386899382\n",
            "lp_loss 0.926765263\n",
            "lp_loss 0.398419082\n",
            "lp_loss 0.509332836\n",
            "lp_loss 0.196018\n",
            "lp_loss 1.18778515\n",
            "lp_loss 0.105678096\n",
            "lp_loss 0.265806615\n",
            "lp_loss 0.811640084\n",
            "lp_loss 0.673534095\n",
            "lp_loss 1.72862077\n",
            "lp_loss 1.08479619\n",
            "lp_loss 0.761927783\n",
            "lp_loss 0.187087476\n",
            "lp_loss 0.502127349\n",
            "lp_loss 0.271133363\n",
            "lp_loss 0.094423227\n",
            "lp_loss 0.227082297\n",
            "lp_loss 0.325565577\n",
            "lp_loss 0.174885184\n",
            "lp_loss 0.0377600379\n",
            "lp_loss 0.429662526\n",
            "lp_loss 0.3268179\n",
            "lp_loss 0.45460549\n",
            "lp_loss 0.266474575\n",
            "lp_loss 1.57684779\n",
            "lp_loss 0.393561661\n",
            "lp_loss 0.667044044\n",
            "lp_loss 0.494121611\n",
            "lp_loss 1.07747245\n",
            "lp_loss 0.269904971\n",
            "lp_loss 0.687976897\n",
            "lp_loss 1.26115513\n",
            "lp_loss 1.12643683\n",
            "lp_loss 0.213087559\n",
            "lp_loss 0.834571242\n",
            "lp_loss 0.145088345\n",
            "lp_loss 0.245606109\n",
            "lp_loss 0.134952441\n",
            "lp_loss 0.0522108898\n",
            "lp_loss 0.222335055\n",
            "lp_loss 0.113186203\n",
            "lp_loss 0.399548948\n",
            "lp_loss 0.368287623\n",
            "lp_loss 1.00009072\n",
            "lp_loss 0.669484377\n",
            "lp_loss 0.601698\n",
            "lp_loss 0.533706069\n",
            "lp_loss 0.387351513\n",
            "lp_loss 0.50200361\n",
            "lp_loss 0.207550764\n",
            "lp_loss 0.724986196\n",
            "lp_loss 0.104292072\n",
            "lp_loss 0.222137243\n",
            "lp_loss 0.324048489\n",
            "lp_loss 0.326083839\n",
            "lp_loss 0.100911833\n",
            "lp_loss 0.317980945\n",
            "lp_loss 1.23822844\n",
            "lp_loss 1.25290406\n",
            "lp_loss 0.0613479391\n",
            "lp_loss 0.906531334\n",
            "lp_loss 0.427075058\n",
            "lp_loss 0.939402759\n",
            "lp_loss 0.469452053\n",
            "lp_loss 0.165917143\n",
            "lp_loss 0.156557113\n",
            "lp_loss 0.172577888\n",
            "lp_loss 1.53468502\n",
            "lp_loss 1.07264054\n",
            "lp_loss 0.250652969\n",
            "lp_loss 0.235214025\n",
            "lp_loss 0.125384837\n",
            "lp_loss 0.166078269\n",
            "lp_loss 0.910057187\n",
            "lp_loss 1.19250798\n",
            "lp_loss 0.715271115\n",
            "lp_loss 0.629765093\n",
            "lp_loss 0.256907403\n",
            "lp_loss 0.551441848\n",
            "lp_loss 0.720574498\n",
            "lp_loss 0.453873068\n",
            "lp_loss 0.64622122\n",
            "lp_loss 0.289555371\n",
            "lp_loss 0.305566847\n",
            "lp_loss 0.297101349\n",
            "lp_loss 0.241477296\n",
            "lp_loss 0.826594949\n",
            "lp_loss 0.327336848\n",
            "lp_loss 0.235299259\n",
            "lp_loss 0.763020217\n",
            "lp_loss 0.0861805677\n",
            "lp_loss 0.288906395\n",
            "lp_loss 0.112049103\n",
            "lp_loss 0.550684\n",
            "lp_loss 0.34351337\n",
            "lp_loss 0.406931698\n",
            "lp_loss 0.152599335\n",
            "lp_loss 0.453822523\n",
            "lp_loss 0.111730993\n",
            "lp_loss 1.90674531\n",
            "lp_loss 1.25074482\n",
            "lp_loss 0.183206\n",
            "lp_loss 0.242155403\n",
            "lp_loss 0.223527387\n",
            "lp_loss 0.063144125\n",
            "lp_loss 0.26973775\n",
            "lp_loss 0.0883872509\n",
            "lp_loss 0.154414207\n",
            "lp_loss 0.730938375\n",
            "lp_loss 0.87988472\n",
            "lp_loss 0.430606931\n",
            "lp_loss 0.0875761807\n",
            "lp_loss 0.822792649\n",
            "lp_loss 0.0797428489\n",
            "lp_loss 0.36663866\n",
            "lp_loss 0.213978678\n",
            "lp_loss 0.607298\n",
            "lp_loss 0.200374722\n",
            "lp_loss 0.430078357\n",
            "lp_loss 0.152444258\n",
            "lp_loss 0.197381586\n",
            "lp_loss 0.480366409\n",
            "lp_loss 0.424007267\n",
            "lp_loss 0.892608941\n",
            "lp_loss 0.594640553\n",
            "lp_loss 1.03676248\n",
            "lp_loss 0.106794164\n",
            "lp_loss 1.6202358\n",
            "lp_loss 0.57612735\n",
            "lp_loss 0.305526912\n",
            "lp_loss 0.879200935\n",
            "lp_loss 0.202124745\n",
            "lp_loss 0.217805296\n",
            "lp_loss 0.315659\n",
            "lp_loss 0.277090222\n",
            "lp_loss 0.426553398\n",
            "lp_loss 0.665634394\n",
            "lp_loss 0.54343605\n",
            "lp_loss 0.430519432\n",
            "lp_loss 0.153082252\n",
            "lp_loss 0.788874388\n",
            "lp_loss 0.774233043\n",
            "lp_loss 0.369082332\n",
            "lp_loss 0.243043378\n",
            "lp_loss 0.669580817\n",
            "lp_loss 1.39507496\n",
            "lp_loss 1.53885174\n",
            "lp_loss 0.376887262\n",
            "lp_loss 0.344900131\n",
            "lp_loss 0.0932936221\n",
            "lp_loss 0.325389981\n",
            "lp_loss 0.261116922\n",
            "lp_loss 0.744770169\n",
            "lp_loss 0.346790969\n",
            "lp_loss 0.646425962\n",
            "lp_loss 1.32906437\n",
            "lp_loss 0.318962753\n",
            "lp_loss 0.17208609\n",
            "lp_loss 0.382452697\n",
            "lp_loss 0.77652657\n",
            "lp_loss 0.53545\n",
            "lp_loss 0.846651435\n",
            "lp_loss 1.08581805\n",
            "lp_loss 0.0944191068\n",
            "lp_loss 0.307060301\n",
            "lp_loss 0.072814405\n",
            "lp_loss 0.125353187\n",
            "lp_loss 0.353158236\n",
            "lp_loss 0.0864415765\n",
            "lp_loss 0.093831785\n",
            "lp_loss 0.537994564\n",
            "lp_loss 0.328540981\n",
            "lp_loss 0.623931468\n",
            "lp_loss 0.70669663\n",
            "2020-01-30 19:32:05.409657\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.843601882\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 3484\n",
            "label_prediction_accuracy - Target: 0.272727281\n",
            "Beginning of epoch: 10\n",
            "lp_loss 0.535480618\n",
            "lp_loss 0.275817543\n",
            "lp_loss 0.745183766\n",
            "lp_loss 0.218426272\n",
            "lp_loss 0.140810356\n",
            "lp_loss 0.0432559475\n",
            "lp_loss 0.296561182\n",
            "lp_loss 0.260015\n",
            "lp_loss 0.914742768\n",
            "lp_loss 1.41302836\n",
            "lp_loss 0.39775914\n",
            "lp_loss 0.163677797\n",
            "lp_loss 0.643189669\n",
            "lp_loss 0.20653303\n",
            "lp_loss 0.246249646\n",
            "lp_loss 0.17471303\n",
            "lp_loss 0.37102747\n",
            "lp_loss 0.505340457\n",
            "lp_loss 0.632683396\n",
            "lp_loss 0.71935004\n",
            "lp_loss 0.194058523\n",
            "lp_loss 0.454313338\n",
            "lp_loss 0.459344536\n",
            "lp_loss 0.475047767\n",
            "lp_loss 0.511546195\n",
            "lp_loss 0.374005377\n",
            "lp_loss 0.768454194\n",
            "lp_loss 1.69442177\n",
            "lp_loss 0.324433118\n",
            "lp_loss 0.437216818\n",
            "lp_loss 0.791012347\n",
            "lp_loss 0.297953427\n",
            "lp_loss 0.184822842\n",
            "lp_loss 0.31447342\n",
            "lp_loss 0.808915615\n",
            "lp_loss 0.061714232\n",
            "lp_loss 0.700897634\n",
            "lp_loss 0.334424973\n",
            "lp_loss 0.256043732\n",
            "lp_loss 0.863370121\n",
            "lp_loss 0.531174481\n",
            "lp_loss 0.238923639\n",
            "lp_loss 0.196850017\n",
            "lp_loss 0.417874157\n",
            "lp_loss 0.239305943\n",
            "lp_loss 1.25902057\n",
            "lp_loss 0.18327\n",
            "lp_loss 0.201676756\n",
            "lp_loss 0.294530094\n",
            "lp_loss 0.762428224\n",
            "lp_loss 0.401332051\n",
            "lp_loss 0.10553284\n",
            "lp_loss 1.24585342\n",
            "lp_loss 0.376263529\n",
            "lp_loss 0.62178719\n",
            "lp_loss 0.202161223\n",
            "lp_loss 0.041729074\n",
            "lp_loss 0.853568673\n",
            "lp_loss 0.922958076\n",
            "lp_loss 1.64949894\n",
            "lp_loss 0.88225615\n",
            "lp_loss 0.276621521\n",
            "lp_loss 0.237117618\n",
            "lp_loss 0.26081568\n",
            "lp_loss 0.134239793\n",
            "lp_loss 0.404759645\n",
            "lp_loss 0.20417437\n",
            "lp_loss 0.505335212\n",
            "lp_loss 0.333281457\n",
            "lp_loss 0.372026712\n",
            "lp_loss 0.29527992\n",
            "lp_loss 0.202012211\n",
            "lp_loss 0.436732829\n",
            "lp_loss 0.0673329681\n",
            "lp_loss 0.232528925\n",
            "lp_loss 0.648119\n",
            "lp_loss 0.583563507\n",
            "lp_loss 0.710383296\n",
            "lp_loss 0.281748235\n",
            "lp_loss 0.417664915\n",
            "lp_loss 0.188640147\n",
            "lp_loss 0.854497075\n",
            "lp_loss 0.252957374\n",
            "lp_loss 0.287744284\n",
            "lp_loss 0.211842179\n",
            "lp_loss 0.0145760309\n",
            "lp_loss 0.251746893\n",
            "lp_loss 1.02762294\n",
            "lp_loss 0.0874955878\n",
            "lp_loss 0.17384854\n",
            "lp_loss 0.774166107\n",
            "lp_loss 1.80750656\n",
            "lp_loss 0.654024\n",
            "lp_loss 0.231535\n",
            "lp_loss 0.0716383606\n",
            "lp_loss 0.121492967\n",
            "lp_loss 0.0288341306\n",
            "lp_loss 0.193844035\n",
            "lp_loss 0.28823477\n",
            "lp_loss 0.204032704\n",
            "lp_loss 0.681773543\n",
            "lp_loss 0.354834378\n",
            "lp_loss 0.668613851\n",
            "lp_loss 0.722698808\n",
            "lp_loss 1.40729082\n",
            "lp_loss 0.550741136\n",
            "lp_loss 0.121571206\n",
            "lp_loss 0.823470294\n",
            "lp_loss 0.122793332\n",
            "lp_loss 0.227005079\n",
            "lp_loss 0.631223202\n",
            "lp_loss 0.492211491\n",
            "lp_loss 0.280266792\n",
            "lp_loss 0.17945385\n",
            "lp_loss 0.828379512\n",
            "lp_loss 0.649543405\n",
            "lp_loss 0.291990787\n",
            "lp_loss 0.737656355\n",
            "lp_loss 0.770937383\n",
            "lp_loss 0.0852948651\n",
            "lp_loss 1.14718843\n",
            "lp_loss 0.0593471415\n",
            "lp_loss 0.242784694\n",
            "lp_loss 0.186774731\n",
            "lp_loss 0.447345644\n",
            "lp_loss 0.164817601\n",
            "lp_loss 0.721123695\n",
            "lp_loss 0.323441148\n",
            "lp_loss 0.500787914\n",
            "lp_loss 0.411459595\n",
            "lp_loss 0.410161108\n",
            "lp_loss 0.246518806\n",
            "lp_loss 0.173313797\n",
            "lp_loss 0.0396882519\n",
            "lp_loss 1.30414879\n",
            "lp_loss 1.35107064\n",
            "lp_loss 1.4480828\n",
            "lp_loss 0.0813841149\n",
            "lp_loss 0.324991405\n",
            "lp_loss 0.576669931\n",
            "lp_loss 0.338643432\n",
            "lp_loss 0.481377691\n",
            "lp_loss 0.963593364\n",
            "lp_loss 0.451704919\n",
            "lp_loss 0.124998949\n",
            "lp_loss 1.25987232\n",
            "lp_loss 1.4387666\n",
            "lp_loss 0.219084769\n",
            "lp_loss 0.344922662\n",
            "lp_loss 0.435398042\n",
            "lp_loss 0.300115436\n",
            "lp_loss 0.229952812\n",
            "lp_loss 0.254536718\n",
            "lp_loss 0.0206547212\n",
            "lp_loss 0.572360814\n",
            "lp_loss 2.7433672\n",
            "lp_loss 0.0788847581\n",
            "lp_loss 0.240858465\n",
            "lp_loss 1.53582799\n",
            "lp_loss 0.108952031\n",
            "lp_loss 0.709877491\n",
            "lp_loss 0.565746427\n",
            "lp_loss 0.316988349\n",
            "lp_loss 0.492397368\n",
            "lp_loss 0.179884672\n",
            "lp_loss 0.662603199\n",
            "lp_loss 0.722537816\n",
            "lp_loss 0.828866959\n",
            "lp_loss 0.031668108\n",
            "lp_loss 0.415851265\n",
            "lp_loss 0.153998286\n",
            "lp_loss 1.22749174\n",
            "lp_loss 0.23616457\n",
            "lp_loss 1.28642404\n",
            "lp_loss 0.352637589\n",
            "lp_loss 0.24352932\n",
            "lp_loss 0.183970183\n",
            "lp_loss 0.317071676\n",
            "lp_loss 0.41871047\n",
            "lp_loss 0.856422722\n",
            "lp_loss 0.160380766\n",
            "lp_loss 0.253302\n",
            "lp_loss 0.0375744551\n",
            "lp_loss 0.616863608\n",
            "lp_loss 0.110507585\n",
            "lp_loss 0.0997070596\n",
            "lp_loss 0.23716107\n",
            "lp_loss 0.0988700688\n",
            "lp_loss 0.341220796\n",
            "lp_loss 0.180181086\n",
            "lp_loss 0.865868211\n",
            "lp_loss 0.155397698\n",
            "lp_loss 0.439121425\n",
            "lp_loss 0.247038171\n",
            "lp_loss 0.0857947469\n",
            "lp_loss 0.413824171\n",
            "lp_loss 0.353262037\n",
            "lp_loss 0.698328\n",
            "lp_loss 0.200543955\n",
            "lp_loss 0.139818698\n",
            "lp_loss 0.17504704\n",
            "lp_loss 0.428492725\n",
            "lp_loss 0.121338569\n",
            "lp_loss 0.557083189\n",
            "lp_loss 0.392659\n",
            "lp_loss 0.0787012726\n",
            "lp_loss 0.408597291\n",
            "lp_loss 0.247096896\n",
            "lp_loss 0.695986867\n",
            "lp_loss 0.976121724\n",
            "lp_loss 0.0909276754\n",
            "2020-01-30 19:32:17.368085\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.860663533\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 3695\n",
            "label_prediction_accuracy - Target: 0.230303034\n",
            "Beginning of epoch: 11\n",
            "lp_loss 0.166019723\n",
            "lp_loss 0.048286479\n",
            "lp_loss 0.0365511402\n",
            "lp_loss 0.0989007801\n",
            "lp_loss 0.565898538\n",
            "lp_loss 0.275103182\n",
            "lp_loss 0.791961193\n",
            "lp_loss 0.859893203\n",
            "lp_loss 0.0340365097\n",
            "lp_loss 0.294757187\n",
            "lp_loss 0.254828542\n",
            "lp_loss 0.80352819\n",
            "lp_loss 0.544179797\n",
            "lp_loss 0.0285286251\n",
            "lp_loss 0.386328518\n",
            "lp_loss 1.14088619\n",
            "lp_loss 0.880419433\n",
            "lp_loss 0.847100377\n",
            "lp_loss 0.182925612\n",
            "lp_loss 0.380865425\n",
            "lp_loss 0.319746017\n",
            "lp_loss 0.637206554\n",
            "lp_loss 2.05943966\n",
            "lp_loss 0.405399501\n",
            "lp_loss 0.732863545\n",
            "lp_loss 0.099343054\n",
            "lp_loss 0.0788485557\n",
            "lp_loss 0.550759256\n",
            "lp_loss 0.423266739\n",
            "lp_loss 0.278959781\n",
            "lp_loss 0.464152664\n",
            "lp_loss 0.448476225\n",
            "lp_loss 0.176751941\n",
            "lp_loss 0.416752\n",
            "lp_loss 0.359770477\n",
            "lp_loss 0.161337584\n",
            "lp_loss 0.563442409\n",
            "lp_loss 0.591467679\n",
            "lp_loss 0.297585905\n",
            "lp_loss 0.693080902\n",
            "lp_loss 0.407532215\n",
            "lp_loss 0.216351196\n",
            "lp_loss 0.52971375\n",
            "lp_loss 0.138919681\n",
            "lp_loss 0.111478113\n",
            "lp_loss 0.184207588\n",
            "lp_loss 0.409750521\n",
            "lp_loss 1.08752596\n",
            "lp_loss 0.487834841\n",
            "lp_loss 0.0559520721\n",
            "lp_loss 0.28935349\n",
            "lp_loss 2.36860418\n",
            "lp_loss 0.0437372923\n",
            "lp_loss 0.104544438\n",
            "lp_loss 0.418107837\n",
            "lp_loss 0.564544439\n",
            "lp_loss 0.91363585\n",
            "lp_loss 0.865446091\n",
            "lp_loss 0.748013496\n",
            "lp_loss 0.671569467\n",
            "lp_loss 0.343171299\n",
            "lp_loss 0.361841381\n",
            "lp_loss 0.208912656\n",
            "lp_loss 0.497930825\n",
            "lp_loss 0.828664303\n",
            "lp_loss 0.362909585\n",
            "lp_loss 1.73659897\n",
            "lp_loss 0.307332486\n",
            "lp_loss 0.0553662255\n",
            "lp_loss 0.312591642\n",
            "lp_loss 0.692934394\n",
            "lp_loss 0.11796777\n",
            "lp_loss 1.11174071\n",
            "lp_loss 1.74896884\n",
            "lp_loss 0.174325928\n",
            "lp_loss 0.128319204\n",
            "lp_loss 0.809538066\n",
            "lp_loss 0.600989223\n",
            "lp_loss 0.16776529\n",
            "lp_loss 0.778616309\n",
            "lp_loss 2.55426669\n",
            "lp_loss 0.0728354\n",
            "lp_loss 0.127737045\n",
            "lp_loss 0.370394796\n",
            "lp_loss 0.758715749\n",
            "lp_loss 0.320863128\n",
            "lp_loss 0.293462038\n",
            "lp_loss 1.06830394\n",
            "lp_loss 0.0523950867\n",
            "lp_loss 0.699194\n",
            "lp_loss 0.909679413\n",
            "lp_loss 0.225893646\n",
            "lp_loss 0.496442467\n",
            "lp_loss 0.295349747\n",
            "lp_loss 0.815345109\n",
            "lp_loss 0.709919155\n",
            "lp_loss 0.971761882\n",
            "lp_loss 0.419643879\n",
            "lp_loss 0.156295076\n",
            "lp_loss 1.64536917\n",
            "lp_loss 0.0973616391\n",
            "lp_loss 0.434718788\n",
            "lp_loss 0.271164238\n",
            "lp_loss 0.258084357\n",
            "lp_loss 0.0598297343\n",
            "lp_loss 0.765359044\n",
            "lp_loss 0.201616138\n",
            "lp_loss 0.179138437\n",
            "lp_loss 0.145083666\n",
            "lp_loss 0.584959388\n",
            "lp_loss 0.196080342\n",
            "lp_loss 0.711724162\n",
            "lp_loss 0.0275003258\n",
            "lp_loss 0.276884526\n",
            "lp_loss 0.621430099\n",
            "lp_loss 0.0975498632\n",
            "lp_loss 0.901495576\n",
            "lp_loss 0.21736601\n",
            "lp_loss 0.0285753254\n",
            "lp_loss 0.14991428\n",
            "lp_loss 1.0015111\n",
            "lp_loss 0.327785\n",
            "lp_loss 0.549140334\n",
            "lp_loss 0.11303971\n",
            "lp_loss 0.321699709\n",
            "lp_loss 0.646174908\n",
            "lp_loss 0.638731122\n",
            "lp_loss 0.377650082\n",
            "lp_loss 0.0957010537\n",
            "lp_loss 0.906591594\n",
            "lp_loss 0.322178304\n",
            "lp_loss 0.252437919\n",
            "lp_loss 0.0147452597\n",
            "lp_loss 0.249192789\n",
            "lp_loss 0.162767291\n",
            "lp_loss 0.107767858\n",
            "lp_loss 1.05532193\n",
            "lp_loss 0.128304094\n",
            "lp_loss 0.972804248\n",
            "lp_loss 0.237704605\n",
            "lp_loss 0.535965562\n",
            "lp_loss 0.168613523\n",
            "lp_loss 0.210819766\n",
            "lp_loss 1.05509102\n",
            "lp_loss 0.403854072\n",
            "lp_loss 0.682124436\n",
            "lp_loss 1.22819483\n",
            "lp_loss 0.0364305861\n",
            "lp_loss 0.515538573\n",
            "lp_loss 0.534493923\n",
            "lp_loss 0.942279816\n",
            "lp_loss 0.396241665\n",
            "lp_loss 0.382830292\n",
            "lp_loss 7.24338627\n",
            "lp_loss 0.0829808563\n",
            "lp_loss 0.123055562\n",
            "lp_loss 0.143189698\n",
            "lp_loss 0.329301059\n",
            "lp_loss 0.187649935\n",
            "lp_loss 0.257479\n",
            "lp_loss 0.626011789\n",
            "lp_loss 0.701306224\n",
            "lp_loss 0.159279138\n",
            "lp_loss 0.048602242\n",
            "lp_loss 0.712263465\n",
            "lp_loss 0.039157249\n",
            "lp_loss 0.296759427\n",
            "lp_loss 0.428794712\n",
            "lp_loss 0.914815903\n",
            "lp_loss 0.0741114244\n",
            "lp_loss 0.232264549\n",
            "lp_loss 0.803296864\n",
            "lp_loss 1.22805202\n",
            "lp_loss 0.445381731\n",
            "lp_loss 0.484374136\n",
            "lp_loss 0.767914414\n",
            "lp_loss 0.173685342\n",
            "lp_loss 0.886249542\n",
            "lp_loss 1.66327667\n",
            "lp_loss 0.902043\n",
            "lp_loss 0.14741382\n",
            "lp_loss 0.544608235\n",
            "lp_loss 0.288750082\n",
            "lp_loss 0.231118515\n",
            "lp_loss 0.201896787\n",
            "lp_loss 0.961666405\n",
            "lp_loss 0.153932825\n",
            "lp_loss 0.149630755\n",
            "lp_loss 0.282639742\n",
            "lp_loss 0.391512692\n",
            "lp_loss 0.146477118\n",
            "lp_loss 0.312524438\n",
            "lp_loss 0.426601887\n",
            "lp_loss 0.720006585\n",
            "lp_loss 0.916641831\n",
            "lp_loss 0.094292\n",
            "lp_loss 0.0634147\n",
            "lp_loss 0.234011203\n",
            "lp_loss 0.38146621\n",
            "lp_loss 0.600349784\n",
            "lp_loss 0.214176446\n",
            "lp_loss 1.79349256\n",
            "lp_loss 0.123553202\n",
            "lp_loss 0.444731772\n",
            "lp_loss 0.425628096\n",
            "lp_loss 0.40301308\n",
            "lp_loss 0.416965067\n",
            "lp_loss 0.438019931\n",
            "lp_loss 0.564783633\n",
            "lp_loss 1.51486373\n",
            "lp_loss 0.758139312\n",
            "lp_loss 0.159399912\n",
            "2020-01-30 19:32:29.493220\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.837735832\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 3907\n",
            "label_prediction_accuracy - Target: 0.25151515\n",
            "Beginning of epoch: 12\n",
            "lp_loss 0.0284906868\n",
            "lp_loss 0.117186114\n",
            "lp_loss 0.238366917\n",
            "lp_loss 0.741051316\n",
            "lp_loss 0.40449366\n",
            "lp_loss 0.293226421\n",
            "lp_loss 1.97417128\n",
            "lp_loss 0.432936579\n",
            "lp_loss 0.804054439\n",
            "lp_loss 0.560753822\n",
            "lp_loss 0.213884026\n",
            "lp_loss 0.515369534\n",
            "lp_loss 0.124629773\n",
            "lp_loss 0.0768329874\n",
            "lp_loss 0.164023072\n",
            "lp_loss 0.310973823\n",
            "lp_loss 0.0928186\n",
            "lp_loss 0.585623085\n",
            "lp_loss 0.646424\n",
            "lp_loss 0.0258856509\n",
            "lp_loss 0.149803922\n",
            "lp_loss 0.32804063\n",
            "lp_loss 0.150430351\n",
            "lp_loss 0.592804432\n",
            "lp_loss 0.175972983\n",
            "lp_loss 0.186881691\n",
            "lp_loss 2.73650122\n",
            "lp_loss 0.292596251\n",
            "lp_loss 0.0900210589\n",
            "lp_loss 0.453199863\n",
            "lp_loss 0.0222621374\n",
            "lp_loss 0.106354795\n",
            "lp_loss 0.55853349\n",
            "lp_loss 0.173655525\n",
            "lp_loss 0.294727266\n",
            "lp_loss 0.901251674\n",
            "lp_loss 0.531008899\n",
            "lp_loss 1.23182845\n",
            "lp_loss 0.1157398\n",
            "lp_loss 0.0452454\n",
            "lp_loss 0.0324972644\n",
            "lp_loss 0.0799046904\n",
            "lp_loss 0.632986903\n",
            "lp_loss 0.518719912\n",
            "lp_loss 0.470965564\n",
            "lp_loss 0.176807374\n",
            "lp_loss 0.0773863718\n",
            "lp_loss 0.212294415\n",
            "lp_loss 0.0367997\n",
            "lp_loss 1.17404199\n",
            "lp_loss 0.171581224\n",
            "lp_loss 0.305568188\n",
            "lp_loss 0.0380548351\n",
            "lp_loss 0.17131348\n",
            "lp_loss 0.115337849\n",
            "lp_loss 0.193269879\n",
            "lp_loss 0.0898904949\n",
            "lp_loss 0.0573942177\n",
            "lp_loss 0.594212234\n",
            "lp_loss 0.852471173\n",
            "lp_loss 0.124608457\n",
            "lp_loss 0.224854499\n",
            "lp_loss 0.154279456\n",
            "lp_loss 0.117533587\n",
            "lp_loss 0.520484567\n",
            "lp_loss 0.309623659\n",
            "lp_loss 0.187767267\n",
            "lp_loss 0.840089619\n",
            "lp_loss 0.128744468\n",
            "lp_loss 0.201879308\n",
            "lp_loss 0.0357972346\n",
            "lp_loss 0.372459948\n",
            "lp_loss 2.8164947\n",
            "lp_loss 0.828313053\n",
            "lp_loss 0.574913323\n",
            "lp_loss 0.0502584092\n",
            "lp_loss 0.236780837\n",
            "lp_loss 0.176148564\n",
            "lp_loss 1.07192135\n",
            "lp_loss 0.0404279493\n",
            "lp_loss 0.276843727\n",
            "lp_loss 0.432537794\n",
            "lp_loss 0.134368852\n",
            "lp_loss 0.469131529\n",
            "lp_loss 0.668101668\n",
            "lp_loss 1.30848622\n",
            "lp_loss 0.315574288\n",
            "lp_loss 0.17626591\n",
            "lp_loss 1.50150084\n",
            "lp_loss 0.532178879\n",
            "lp_loss 0.30475378\n",
            "lp_loss 0.285615087\n",
            "lp_loss 0.383431762\n",
            "lp_loss 0.0827918202\n",
            "lp_loss 0.269682556\n",
            "lp_loss 0.245075315\n",
            "lp_loss 0.682195365\n",
            "lp_loss 0.706355691\n",
            "lp_loss 1.43721867\n",
            "lp_loss 0.160587341\n",
            "lp_loss 0.0816142708\n",
            "lp_loss 0.0734213144\n",
            "lp_loss 0.279944807\n",
            "lp_loss 0.15920113\n",
            "lp_loss 0.307483852\n",
            "lp_loss 0.22736004\n",
            "lp_loss 0.107477546\n",
            "lp_loss 0.269714057\n",
            "lp_loss 0.935281575\n",
            "lp_loss 1.38985014\n",
            "lp_loss 0.267380804\n",
            "lp_loss 0.200634435\n",
            "lp_loss 1.19696212\n",
            "lp_loss 0.154403776\n",
            "lp_loss 0.396626264\n",
            "lp_loss 0.268550426\n",
            "lp_loss 0.928392589\n",
            "lp_loss 1.05531859\n",
            "lp_loss 0.194407016\n",
            "lp_loss 0.119064115\n",
            "lp_loss 0.0679445267\n",
            "lp_loss 0.104819737\n",
            "lp_loss 0.705955684\n",
            "lp_loss 0.211419702\n",
            "lp_loss 0.621556282\n",
            "lp_loss 1.16105461\n",
            "lp_loss 0.269949585\n",
            "lp_loss 0.421422958\n",
            "lp_loss 0.355472505\n",
            "lp_loss 0.0957998261\n",
            "lp_loss 0.208072349\n",
            "lp_loss 0.0487506352\n",
            "lp_loss 0.122380212\n",
            "lp_loss 0.0262469705\n",
            "lp_loss 0.264401376\n",
            "lp_loss 0.215386301\n",
            "lp_loss 0.052178096\n",
            "lp_loss 0.681225419\n",
            "lp_loss 0.803463161\n",
            "lp_loss 0.484298229\n",
            "lp_loss 0.329377234\n",
            "lp_loss 0.527685404\n",
            "lp_loss 1.3989253\n",
            "lp_loss 2.5317688\n",
            "lp_loss 0.131057695\n",
            "lp_loss 0.201201439\n",
            "lp_loss 0.757808805\n",
            "lp_loss 0.600814223\n",
            "lp_loss 0.589008451\n",
            "lp_loss 0.105597258\n",
            "lp_loss 0.263204962\n",
            "lp_loss 0.097943075\n",
            "lp_loss 0.0623115897\n",
            "lp_loss 0.143218711\n",
            "lp_loss 0.0937689096\n",
            "lp_loss 0.229024455\n",
            "lp_loss 0.255070329\n",
            "lp_loss 0.987203479\n",
            "lp_loss 0.255966961\n",
            "lp_loss 0.866263211\n",
            "lp_loss 0.433051646\n",
            "lp_loss 0.479996204\n",
            "lp_loss 0.573611319\n",
            "lp_loss 0.10276711\n",
            "lp_loss 0.452557564\n",
            "lp_loss 0.283842027\n",
            "lp_loss 0.435054213\n",
            "lp_loss 0.0650148839\n",
            "lp_loss 0.57665658\n",
            "lp_loss 1.15797973\n",
            "lp_loss 1.87159765\n",
            "lp_loss 0.540070117\n",
            "lp_loss 0.297563851\n",
            "lp_loss 0.201235026\n",
            "lp_loss 1.38602543\n",
            "lp_loss 0.0836958438\n",
            "lp_loss 0.518317878\n",
            "lp_loss 0.120693006\n",
            "lp_loss 0.247729942\n",
            "lp_loss 0.448403835\n",
            "lp_loss 0.171813354\n",
            "lp_loss 0.325913727\n",
            "lp_loss 0.688600838\n",
            "lp_loss 0.141078711\n",
            "lp_loss 0.43996945\n",
            "lp_loss 0.2240251\n",
            "lp_loss 0.496257395\n",
            "lp_loss 0.77569443\n",
            "lp_loss 0.618804514\n",
            "lp_loss 1.45288253\n",
            "lp_loss 0.0370019861\n",
            "lp_loss 0.139519751\n",
            "lp_loss 1.55514657\n",
            "lp_loss 0.625927806\n",
            "lp_loss 0.96007812\n",
            "lp_loss 0.10940437\n",
            "lp_loss 0.19613184\n",
            "lp_loss 0.112535141\n",
            "lp_loss 0.711005569\n",
            "lp_loss 0.343150407\n",
            "lp_loss 0.318911046\n",
            "lp_loss 0.379578859\n",
            "lp_loss 0.519675434\n",
            "lp_loss 1.42295432\n",
            "lp_loss 0.23379007\n",
            "lp_loss 1.47482395\n",
            "lp_loss 0.325540841\n",
            "lp_loss 0.347030759\n",
            "lp_loss 0.418015242\n",
            "lp_loss 1.38743365\n",
            "lp_loss 0.753802419\n",
            "2020-01-30 19:32:41.742444\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.865402818\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 4118\n",
            "label_prediction_accuracy - Target: 0.239393935\n",
            "Beginning of epoch: 13\n",
            "lp_loss 0.182382226\n",
            "lp_loss 0.111931287\n",
            "lp_loss 0.689056337\n",
            "lp_loss 0.369537354\n",
            "lp_loss 1.40721989\n",
            "lp_loss 0.402970374\n",
            "lp_loss 0.0950812623\n",
            "lp_loss 0.164553955\n",
            "lp_loss 0.407075703\n",
            "lp_loss 0.594060779\n",
            "lp_loss 0.0910517201\n",
            "lp_loss 0.0894091576\n",
            "lp_loss 0.0526124835\n",
            "lp_loss 0.268913269\n",
            "lp_loss 0.0987661928\n",
            "lp_loss 0.545453906\n",
            "lp_loss 0.498167127\n",
            "lp_loss 2.57114697\n",
            "lp_loss 0.491401255\n",
            "lp_loss 0.117142543\n",
            "lp_loss 0.251432031\n",
            "lp_loss 0.938294053\n",
            "lp_loss 0.535405\n",
            "lp_loss 0.202836901\n",
            "lp_loss 0.0713665336\n",
            "lp_loss 0.623487949\n",
            "lp_loss 0.418495357\n",
            "lp_loss 0.229709059\n",
            "lp_loss 1.17123461\n",
            "lp_loss 0.0851096511\n",
            "lp_loss 0.984844565\n",
            "lp_loss 0.961713135\n",
            "lp_loss 0.252061427\n",
            "lp_loss 0.546893477\n",
            "lp_loss 0.159030527\n",
            "lp_loss 0.180113897\n",
            "lp_loss 0.250901103\n",
            "lp_loss 0.359177709\n",
            "lp_loss 0.0843441337\n",
            "lp_loss 0.186445564\n",
            "lp_loss 0.0267506503\n",
            "lp_loss 0.3637577\n",
            "lp_loss 0.203950807\n",
            "lp_loss 0.099197872\n",
            "lp_loss 0.718403518\n",
            "lp_loss 0.491280317\n",
            "lp_loss 0.206596017\n",
            "lp_loss 0.0566697121\n",
            "lp_loss 0.0570890382\n",
            "lp_loss 0.731592655\n",
            "lp_loss 0.0301748458\n",
            "lp_loss 0.465690792\n",
            "lp_loss 0.145508915\n",
            "lp_loss 0.918667436\n",
            "lp_loss 0.0812957287\n",
            "lp_loss 0.163612887\n",
            "lp_loss 1.50411105\n",
            "lp_loss 0.261018783\n",
            "lp_loss 0.194911703\n",
            "lp_loss 0.2670241\n",
            "lp_loss 1.25834775\n",
            "lp_loss 0.866758704\n",
            "lp_loss 1.63440418\n",
            "lp_loss 0.969691873\n",
            "lp_loss 0.104495108\n",
            "lp_loss 0.116574943\n",
            "lp_loss 0.244370818\n",
            "lp_loss 0.237754032\n",
            "lp_loss 0.707799\n",
            "lp_loss 0.377177387\n",
            "lp_loss 0.522121549\n",
            "lp_loss 0.732376873\n",
            "lp_loss 0.0474185348\n",
            "lp_loss 0.147261873\n",
            "lp_loss 0.0667665\n",
            "lp_loss 0.737951636\n",
            "lp_loss 0.371657312\n",
            "lp_loss 0.611693084\n",
            "lp_loss 1.19660747\n",
            "lp_loss 0.55601263\n",
            "lp_loss 0.35516426\n",
            "lp_loss 0.234103799\n",
            "lp_loss 0.325556338\n",
            "lp_loss 0.331150472\n",
            "lp_loss 0.129469857\n",
            "lp_loss 0.0493464656\n",
            "lp_loss 0.114681125\n",
            "lp_loss 0.880191207\n",
            "lp_loss 0.247847557\n",
            "lp_loss 0.65475142\n",
            "lp_loss 1.75186276\n",
            "lp_loss 0.260236084\n",
            "lp_loss 0.492988199\n",
            "lp_loss 0.148480982\n",
            "lp_loss 0.989336312\n",
            "lp_loss 0.348815143\n",
            "lp_loss 0.0502582379\n",
            "lp_loss 0.603283763\n",
            "lp_loss 0.0393101498\n",
            "lp_loss 0.204964086\n",
            "lp_loss 0.0796561837\n",
            "lp_loss 0.384122074\n",
            "lp_loss 0.281012475\n",
            "lp_loss 0.388406813\n",
            "lp_loss 1.326563\n",
            "lp_loss 0.37126559\n",
            "lp_loss 0.455580473\n",
            "lp_loss 0.166649371\n",
            "lp_loss 0.584881186\n",
            "lp_loss 0.925893962\n",
            "lp_loss 0.0997707695\n",
            "lp_loss 0.192018718\n",
            "lp_loss 0.750257611\n",
            "lp_loss 1.48154807\n",
            "lp_loss 0.207922608\n",
            "lp_loss 0.912811756\n",
            "lp_loss 0.128458828\n",
            "lp_loss 0.348082215\n",
            "lp_loss 0.149216563\n",
            "lp_loss 0.989641786\n",
            "lp_loss 0.167082101\n",
            "lp_loss 0.771097302\n",
            "lp_loss 0.869356811\n",
            "lp_loss 0.322384268\n",
            "lp_loss 0.359898418\n",
            "lp_loss 0.737774\n",
            "lp_loss 0.641356647\n",
            "lp_loss 0.10940659\n",
            "lp_loss 0.430472523\n",
            "lp_loss 0.76375252\n",
            "lp_loss 0.798122525\n",
            "lp_loss 0.721920609\n",
            "lp_loss 0.31575948\n",
            "lp_loss 0.249174356\n",
            "lp_loss 0.207328275\n",
            "lp_loss 0.192767143\n",
            "lp_loss 0.333939075\n",
            "lp_loss 0.0463339165\n",
            "lp_loss 0.583902836\n",
            "lp_loss 0.980353534\n",
            "lp_loss 1.15577412\n",
            "lp_loss 1.26927257\n",
            "lp_loss 0.399903238\n",
            "lp_loss 0.418851197\n",
            "lp_loss 0.0119600017\n",
            "lp_loss 0.241361663\n",
            "lp_loss 0.0791866779\n",
            "lp_loss 0.987720668\n",
            "lp_loss 0.640108\n",
            "lp_loss 0.677981913\n",
            "lp_loss 0.442432791\n",
            "lp_loss 0.299290836\n",
            "lp_loss 1.29340208\n",
            "lp_loss 0.270979077\n",
            "lp_loss 0.904313922\n",
            "lp_loss 1.43910289\n",
            "lp_loss 0.17491512\n",
            "lp_loss 0.0297437198\n",
            "lp_loss 0.482352793\n",
            "lp_loss 0.754454494\n",
            "lp_loss 0.214414\n",
            "lp_loss 0.540646851\n",
            "lp_loss 0.332949042\n",
            "lp_loss 0.726123035\n",
            "lp_loss 0.309563547\n",
            "lp_loss 0.0304989275\n",
            "lp_loss 0.272542477\n",
            "lp_loss 0.185483396\n",
            "lp_loss 0.00716342125\n",
            "lp_loss 0.0340038\n",
            "lp_loss 0.170838982\n",
            "lp_loss 0.145785391\n",
            "lp_loss 0.107722029\n",
            "lp_loss 0.218750268\n",
            "lp_loss 0.354953885\n",
            "lp_loss 0.120526433\n",
            "lp_loss 0.428820699\n",
            "lp_loss 0.373970687\n",
            "lp_loss 0.129107744\n",
            "lp_loss 0.468237\n",
            "lp_loss 0.0326288752\n",
            "lp_loss 0.329596728\n",
            "lp_loss 0.163627818\n",
            "lp_loss 0.276745945\n",
            "lp_loss 0.695548356\n",
            "lp_loss 0.923243046\n",
            "lp_loss 0.171523824\n",
            "lp_loss 0.152303517\n",
            "lp_loss 0.759560287\n",
            "lp_loss 0.119378112\n",
            "lp_loss 0.50223577\n",
            "lp_loss 0.205287769\n",
            "lp_loss 0.946878135\n",
            "lp_loss 0.544404387\n",
            "lp_loss 0.0565573685\n",
            "lp_loss 0.177800328\n",
            "lp_loss 0.687318385\n",
            "lp_loss 0.400891304\n",
            "lp_loss 0.481117874\n",
            "lp_loss 0.0749750957\n",
            "lp_loss 0.0981269\n",
            "lp_loss 0.0774924606\n",
            "lp_loss 0.180330828\n",
            "lp_loss 1.11832595\n",
            "lp_loss 0.242028385\n",
            "lp_loss 0.630881548\n",
            "lp_loss 0.602100849\n",
            "lp_loss 0.0244902745\n",
            "lp_loss 0.709063888\n",
            "lp_loss 0.150353342\n",
            "lp_loss 0.506148219\n",
            "2020-01-30 19:32:54.098918\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.867298603\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 4329\n",
            "label_prediction_accuracy - Target: 0.218181819\n",
            "Beginning of epoch: 14\n",
            "lp_loss 1.5190593\n",
            "lp_loss 0.395613253\n",
            "lp_loss 0.13480933\n",
            "lp_loss 0.0828174278\n",
            "lp_loss 0.0759622082\n",
            "lp_loss 0.50415951\n",
            "lp_loss 0.300400555\n",
            "lp_loss 1.21980894\n",
            "lp_loss 0.905867934\n",
            "lp_loss 0.531451821\n",
            "lp_loss 0.641767204\n",
            "lp_loss 0.440663487\n",
            "lp_loss 0.117237903\n",
            "lp_loss 0.171766788\n",
            "lp_loss 0.346823543\n",
            "lp_loss 0.58784616\n",
            "lp_loss 0.0296413358\n",
            "lp_loss 0.163709193\n",
            "lp_loss 0.531312287\n",
            "lp_loss 0.428926617\n",
            "lp_loss 0.505532563\n",
            "lp_loss 0.0312608257\n",
            "lp_loss 0.157827765\n",
            "lp_loss 0.0692088753\n",
            "lp_loss 0.721676707\n",
            "lp_loss 0.145492926\n",
            "lp_loss 2.4010253\n",
            "lp_loss 0.157839507\n",
            "lp_loss 0.798960924\n",
            "lp_loss 1.10144877\n",
            "lp_loss 0.137708336\n",
            "lp_loss 0.304707229\n",
            "lp_loss 1.18872797\n",
            "lp_loss 0.377920508\n",
            "lp_loss 0.0683582053\n",
            "lp_loss 0.650967717\n",
            "lp_loss 0.139388666\n",
            "lp_loss 1.30114925\n",
            "lp_loss 0.0975629538\n",
            "lp_loss 0.536583483\n",
            "lp_loss 0.620904744\n",
            "lp_loss 0.127429634\n",
            "lp_loss 0.0849550143\n",
            "lp_loss 0.347167075\n",
            "lp_loss 0.140764728\n",
            "lp_loss 0.0833488852\n",
            "lp_loss 0.0175913814\n",
            "lp_loss 0.296542227\n",
            "lp_loss 0.478528976\n",
            "lp_loss 0.0369833373\n",
            "lp_loss 0.289511859\n",
            "lp_loss 0.577155\n",
            "lp_loss 0.300716341\n",
            "lp_loss 0.975868046\n",
            "lp_loss 0.887034118\n",
            "lp_loss 0.605315804\n",
            "lp_loss 0.229007632\n",
            "lp_loss 0.660002112\n",
            "lp_loss 1.95669436\n",
            "lp_loss 0.0652823895\n",
            "lp_loss 0.151427314\n",
            "lp_loss 0.307498485\n",
            "lp_loss 0.810397923\n",
            "lp_loss 1.64076233\n",
            "lp_loss 0.804474652\n",
            "lp_loss 0.462738574\n",
            "lp_loss 0.0620850325\n",
            "lp_loss 0.273043424\n",
            "lp_loss 0.108847603\n",
            "lp_loss 0.157952711\n",
            "lp_loss 1.0361656\n",
            "lp_loss 0.0800943\n",
            "lp_loss 1.57242882\n",
            "lp_loss 0.146034777\n",
            "lp_loss 0.231288821\n",
            "lp_loss 0.0846635\n",
            "lp_loss 0.500716925\n",
            "lp_loss 0.30026865\n",
            "lp_loss 0.0865994468\n",
            "lp_loss 0.378295958\n",
            "lp_loss 0.327558458\n",
            "lp_loss 0.757143259\n",
            "lp_loss 0.315275848\n",
            "lp_loss 0.41471988\n",
            "lp_loss 1.2630012\n",
            "lp_loss 0.0918532\n",
            "lp_loss 0.0759894401\n",
            "lp_loss 0.21298866\n",
            "lp_loss 0.476868689\n",
            "lp_loss 0.527560651\n",
            "lp_loss 0.181483239\n",
            "lp_loss 0.0335187837\n",
            "lp_loss 0.0270301\n",
            "lp_loss 1.53945673\n",
            "lp_loss 0.0435101613\n",
            "lp_loss 0.242330641\n",
            "lp_loss 0.443063736\n",
            "lp_loss 0.111575007\n",
            "lp_loss 0.0681567937\n",
            "lp_loss 0.171630621\n",
            "lp_loss 0.0790640712\n",
            "lp_loss 0.451972425\n",
            "lp_loss 0.639264107\n",
            "lp_loss 1.45600033\n",
            "lp_loss 0.34736526\n",
            "lp_loss 0.461228073\n",
            "lp_loss 0.733815312\n",
            "lp_loss 0.255370706\n",
            "lp_loss 0.0137336608\n",
            "lp_loss 0.270989656\n",
            "lp_loss 0.494145095\n",
            "lp_loss 0.0329679772\n",
            "lp_loss 0.258279562\n",
            "lp_loss 0.299668074\n",
            "lp_loss 0.126074463\n",
            "lp_loss 0.460631549\n",
            "lp_loss 0.552863955\n",
            "lp_loss 0.174446598\n",
            "lp_loss 0.266688496\n",
            "lp_loss 0.733725548\n",
            "lp_loss 0.429527223\n",
            "lp_loss 0.0714625344\n",
            "lp_loss 0.224146649\n",
            "lp_loss 0.155295238\n",
            "lp_loss 0.0672302842\n",
            "lp_loss 0.539735556\n",
            "lp_loss 0.141852692\n",
            "lp_loss 1.73157692\n",
            "lp_loss 0.321048319\n",
            "lp_loss 0.395794153\n",
            "lp_loss 0.326895624\n",
            "lp_loss 0.0326264203\n",
            "lp_loss 0.123447731\n",
            "lp_loss 0.0946053416\n",
            "lp_loss 0.520974696\n",
            "lp_loss 1.02147496\n",
            "lp_loss 0.287750423\n",
            "lp_loss 0.571867347\n",
            "lp_loss 2.09340835\n",
            "lp_loss 0.122230314\n",
            "lp_loss 0.562456727\n",
            "lp_loss 0.124845207\n",
            "lp_loss 0.0998667777\n",
            "lp_loss 0.494774\n",
            "lp_loss 0.413247883\n",
            "lp_loss 1.32409716\n",
            "lp_loss 0.053497415\n",
            "lp_loss 0.325002909\n",
            "lp_loss 0.307924718\n",
            "lp_loss 0.362661391\n",
            "lp_loss 0.843581855\n",
            "lp_loss 0.399891555\n",
            "lp_loss 0.353299975\n",
            "lp_loss 0.815073\n",
            "lp_loss 0.0690091103\n",
            "lp_loss 0.0523884073\n",
            "lp_loss 0.100688979\n",
            "lp_loss 0.679399431\n",
            "lp_loss 0.15773344\n",
            "lp_loss 0.888370156\n",
            "lp_loss 0.792582214\n",
            "lp_loss 0.281301945\n",
            "lp_loss 0.329536945\n",
            "lp_loss 0.414835125\n",
            "lp_loss 0.0481601581\n",
            "lp_loss 0.0866694301\n",
            "lp_loss 0.1271469\n",
            "lp_loss 0.471807659\n",
            "lp_loss 0.158175468\n",
            "lp_loss 0.050582\n",
            "lp_loss 0.0949803814\n",
            "lp_loss 0.0950966\n",
            "lp_loss 0.407297522\n",
            "lp_loss 1.23832679\n",
            "lp_loss 0.0472681448\n",
            "lp_loss 0.458470434\n",
            "lp_loss 0.297201306\n",
            "lp_loss 0.490227133\n",
            "lp_loss 0.59934622\n",
            "lp_loss 0.314670384\n",
            "lp_loss 1.17495215\n",
            "lp_loss 0.691762745\n",
            "lp_loss 0.363744527\n",
            "lp_loss 0.0687664524\n",
            "lp_loss 0.310648769\n",
            "lp_loss 0.0394755378\n",
            "lp_loss 0.145929024\n",
            "lp_loss 0.191500515\n",
            "lp_loss 0.72066468\n",
            "lp_loss 0.511678755\n",
            "lp_loss 0.0654660091\n",
            "lp_loss 0.207525209\n",
            "lp_loss 0.0372028239\n",
            "lp_loss 0.0565792806\n",
            "lp_loss 0.305407941\n",
            "lp_loss 0.165368631\n",
            "lp_loss 0.223839194\n",
            "lp_loss 0.594768\n",
            "lp_loss 1.11321747\n",
            "lp_loss 0.121444687\n",
            "lp_loss 0.247271135\n",
            "lp_loss 0.146154553\n",
            "lp_loss 0.0917335451\n",
            "lp_loss 0.137054816\n",
            "lp_loss 1.32748294\n",
            "lp_loss 0.200535625\n",
            "lp_loss 0.0667997226\n",
            "lp_loss 0.232566282\n",
            "lp_loss 0.368243963\n",
            "lp_loss 0.361764848\n",
            "lp_loss 0.120188355\n",
            "2020-01-30 19:33:06.877174\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.875829399\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 4540\n",
            "label_prediction_accuracy - Target: 0.206060603\n",
            "Beginning of epoch: 15\n",
            "lp_loss 1.69078326\n",
            "lp_loss 1.22891068\n",
            "lp_loss 0.0527276509\n",
            "lp_loss 0.37972194\n",
            "lp_loss 0.714243054\n",
            "lp_loss 0.316319644\n",
            "lp_loss 1.20329952\n",
            "lp_loss 0.143617988\n",
            "lp_loss 0.199013159\n",
            "lp_loss 0.182907119\n",
            "lp_loss 0.112965561\n",
            "lp_loss 0.378284067\n",
            "lp_loss 0.919896722\n",
            "lp_loss 0.0863055363\n",
            "lp_loss 0.324736744\n",
            "lp_loss 0.125240237\n",
            "lp_loss 1.48710024\n",
            "lp_loss 0.171108931\n",
            "lp_loss 0.48448953\n",
            "lp_loss 0.901689172\n",
            "lp_loss 0.25235346\n",
            "lp_loss 0.18186143\n",
            "lp_loss 0.0339542367\n",
            "lp_loss 0.308426648\n",
            "lp_loss 0.433129251\n",
            "lp_loss 2.08253908\n",
            "lp_loss 0.489187628\n",
            "lp_loss 0.622734249\n",
            "lp_loss 0.183343753\n",
            "lp_loss 0.4415223\n",
            "lp_loss 0.384842306\n",
            "lp_loss 0.0567594171\n",
            "lp_loss 0.518804193\n",
            "lp_loss 0.188478142\n",
            "lp_loss 0.849902749\n",
            "lp_loss 0.131771788\n",
            "lp_loss 0.431363881\n",
            "lp_loss 0.286384553\n",
            "lp_loss 0.334993899\n",
            "lp_loss 0.0954162329\n",
            "lp_loss 2.65927839\n",
            "lp_loss 0.450021923\n",
            "lp_loss 0.531499743\n",
            "lp_loss 0.651863694\n",
            "lp_loss 0.296119422\n",
            "lp_loss 0.0822613612\n",
            "lp_loss 1.08824337\n",
            "lp_loss 0.96485889\n",
            "lp_loss 0.564909458\n",
            "lp_loss 0.408525229\n",
            "lp_loss 0.943456769\n",
            "lp_loss 0.100361124\n",
            "lp_loss 0.216026619\n",
            "lp_loss 0.495128155\n",
            "lp_loss 0.356720418\n",
            "lp_loss 0.500775695\n",
            "lp_loss 1.44727945\n",
            "lp_loss 0.37679249\n",
            "lp_loss 0.104435779\n",
            "lp_loss 0.187704057\n",
            "lp_loss 0.609914601\n",
            "lp_loss 0.015469566\n",
            "lp_loss 0.0184750147\n",
            "lp_loss 0.0405799747\n",
            "lp_loss 0.293397486\n",
            "lp_loss 0.244578332\n",
            "lp_loss 0.193111643\n",
            "lp_loss 0.155020148\n",
            "lp_loss 0.153959408\n",
            "lp_loss 0.0535261221\n",
            "lp_loss 0.410034478\n",
            "lp_loss 0.0384127609\n",
            "lp_loss 0.144201398\n",
            "lp_loss 0.675587595\n",
            "lp_loss 0.0595627353\n",
            "lp_loss 0.343347937\n",
            "lp_loss 0.0256897509\n",
            "lp_loss 0.0394434407\n",
            "lp_loss 0.850836575\n",
            "lp_loss 0.414034218\n",
            "lp_loss 0.424006224\n",
            "lp_loss 0.143022209\n",
            "lp_loss 1.05073941\n",
            "lp_loss 0.300394237\n",
            "lp_loss 0.73635906\n",
            "lp_loss 0.161438376\n",
            "lp_loss 0.734973371\n",
            "lp_loss 1.09192443\n",
            "lp_loss 0.214302585\n",
            "lp_loss 0.495578289\n",
            "lp_loss 0.0751744211\n",
            "lp_loss 0.873298645\n",
            "lp_loss 0.814425349\n",
            "lp_loss 2.04658699\n",
            "lp_loss 0.134435266\n",
            "lp_loss 0.53171283\n",
            "lp_loss 0.114115462\n",
            "lp_loss 1.32633197\n",
            "lp_loss 0.669788182\n",
            "lp_loss 0.555089\n",
            "lp_loss 0.0734600797\n",
            "lp_loss 0.369326413\n",
            "lp_loss 1.24608147\n",
            "lp_loss 0.0423447266\n",
            "lp_loss 0.491190523\n",
            "lp_loss 0.526198745\n",
            "lp_loss 0.428528965\n",
            "lp_loss 1.17300081\n",
            "lp_loss 0.249001786\n",
            "lp_loss 0.351959288\n",
            "lp_loss 0.0494079143\n",
            "lp_loss 1.18604779\n",
            "lp_loss 0.0405897759\n",
            "lp_loss 0.261418045\n",
            "lp_loss 0.118788444\n",
            "lp_loss 0.320645064\n",
            "lp_loss 0.146547899\n",
            "lp_loss 0.573051155\n",
            "lp_loss 0.155731961\n",
            "lp_loss 1.09336448\n",
            "lp_loss 0.562520325\n",
            "lp_loss 0.394761771\n",
            "lp_loss 0.238013983\n",
            "lp_loss 0.529272914\n",
            "lp_loss 0.0412484854\n",
            "lp_loss 0.300766289\n",
            "lp_loss 0.312208563\n",
            "lp_loss 2.08742905\n",
            "lp_loss 0.100391068\n",
            "lp_loss 0.0403255932\n",
            "lp_loss 0.0637826473\n",
            "lp_loss 0.19148834\n",
            "lp_loss 0.157988101\n",
            "lp_loss 0.179223433\n",
            "lp_loss 0.357134163\n",
            "lp_loss 0.56782192\n",
            "lp_loss 0.10242568\n",
            "lp_loss 0.053411115\n",
            "lp_loss 1.78272915\n",
            "lp_loss 0.169993892\n",
            "lp_loss 0.273572832\n",
            "lp_loss 0.227210045\n",
            "lp_loss 0.275326937\n",
            "lp_loss 0.0815077648\n",
            "lp_loss 0.315600187\n",
            "lp_loss 0.355484337\n",
            "lp_loss 0.122166298\n",
            "lp_loss 0.250448346\n",
            "lp_loss 0.669098735\n",
            "lp_loss 0.352327049\n",
            "lp_loss 0.292116\n",
            "lp_loss 0.365112603\n",
            "lp_loss 0.855890155\n",
            "lp_loss 0.133416519\n",
            "lp_loss 0.157348841\n",
            "lp_loss 0.886414826\n",
            "lp_loss 0.859878719\n",
            "lp_loss 1.13574445\n",
            "lp_loss 0.550340474\n",
            "lp_loss 0.678444266\n",
            "lp_loss 0.670964777\n",
            "lp_loss 0.501588702\n",
            "lp_loss 1.26474774\n",
            "lp_loss 0.19504194\n",
            "lp_loss 0.0381952897\n",
            "lp_loss 0.486695349\n",
            "lp_loss 0.0985815749\n",
            "lp_loss 0.116367243\n",
            "lp_loss 0.345960915\n",
            "lp_loss 0.182642192\n",
            "lp_loss 0.454826981\n",
            "lp_loss 0.282877624\n",
            "lp_loss 0.817001522\n",
            "lp_loss 0.131070107\n",
            "lp_loss 0.42647624\n",
            "lp_loss 0.136541441\n",
            "lp_loss 0.121162847\n",
            "lp_loss 0.117288545\n",
            "lp_loss 0.971764684\n",
            "lp_loss 0.308075547\n",
            "lp_loss 0.16898489\n",
            "lp_loss 0.00824967\n",
            "lp_loss 2.04589319\n",
            "lp_loss 0.126226395\n",
            "lp_loss 0.371275485\n",
            "lp_loss 0.734002471\n",
            "lp_loss 0.685910106\n",
            "lp_loss 1.48360372\n",
            "lp_loss 0.0285664611\n",
            "lp_loss 0.355472147\n",
            "lp_loss 0.08081007\n",
            "lp_loss 0.126621678\n",
            "lp_loss 0.081742622\n",
            "lp_loss 0.550273299\n",
            "lp_loss 0.374156624\n",
            "lp_loss 0.01221037\n",
            "lp_loss 2.6925\n",
            "lp_loss 0.169255689\n",
            "lp_loss 0.34562248\n",
            "lp_loss 0.416321576\n",
            "lp_loss 0.213453934\n",
            "lp_loss 0.159119606\n",
            "lp_loss 0.107001208\n",
            "lp_loss 1.41937661\n",
            "lp_loss 0.080934\n",
            "lp_loss 0.808161259\n",
            "lp_loss 0.362664282\n",
            "lp_loss 0.629766881\n",
            "lp_loss 0.769088864\n",
            "lp_loss 0.519052684\n",
            "lp_loss 0.175970346\n",
            "2020-01-30 19:33:19.461617\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.87298578\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 4751\n",
            "label_prediction_accuracy - Target: 0.230303034\n",
            "Beginning of epoch: 16\n",
            "lp_loss 0.095543392\n",
            "lp_loss 0.0360076\n",
            "lp_loss 0.168638468\n",
            "lp_loss 0.658724904\n",
            "lp_loss 0.425367683\n",
            "lp_loss 0.0191672556\n",
            "lp_loss 0.47560063\n",
            "lp_loss 0.0611730404\n",
            "lp_loss 0.358432472\n",
            "lp_loss 0.212689191\n",
            "lp_loss 0.306893349\n",
            "lp_loss 0.672153652\n",
            "lp_loss 1.01081824\n",
            "lp_loss 0.145687342\n",
            "lp_loss 0.351184368\n",
            "lp_loss 0.69047153\n",
            "lp_loss 0.425558418\n",
            "lp_loss 0.0670452267\n",
            "lp_loss 0.0900459141\n",
            "lp_loss 0.149531603\n",
            "lp_loss 1.60699308\n",
            "lp_loss 0.773133695\n",
            "lp_loss 0.637295961\n",
            "lp_loss 0.681484461\n",
            "lp_loss 0.324453562\n",
            "lp_loss 0.652375877\n",
            "lp_loss 0.67058146\n",
            "lp_loss 0.716265321\n",
            "lp_loss 0.249768227\n",
            "lp_loss 0.704701483\n",
            "lp_loss 0.595716476\n",
            "lp_loss 0.0927795321\n",
            "lp_loss 0.11745\n",
            "lp_loss 0.245933741\n",
            "lp_loss 0.35978362\n",
            "lp_loss 0.384379387\n",
            "lp_loss 0.123076141\n",
            "lp_loss 0.197954819\n",
            "lp_loss 0.181954846\n",
            "lp_loss 0.39860785\n",
            "lp_loss 0.425831258\n",
            "lp_loss 0.645599842\n",
            "lp_loss 0.101090357\n",
            "lp_loss 0.0425760709\n",
            "lp_loss 0.106215656\n",
            "lp_loss 0.206220269\n",
            "lp_loss 0.875238895\n",
            "lp_loss 0.11777439\n",
            "lp_loss 0.00982701778\n",
            "lp_loss 0.0627884418\n",
            "lp_loss 0.510303378\n",
            "lp_loss 0.405136883\n",
            "lp_loss 0.47739\n",
            "lp_loss 0.333678186\n",
            "lp_loss 1.17921591\n",
            "lp_loss 0.400489\n",
            "lp_loss 0.0853202194\n",
            "lp_loss 0.451947272\n",
            "lp_loss 0.463974625\n",
            "lp_loss 0.397261739\n",
            "lp_loss 0.35921368\n",
            "lp_loss 0.0736537\n",
            "lp_loss 0.0771751478\n",
            "lp_loss 0.310046762\n",
            "lp_loss 0.499760151\n",
            "lp_loss 0.0820937082\n",
            "lp_loss 0.939156413\n",
            "lp_loss 0.298126161\n",
            "lp_loss 0.277971625\n",
            "lp_loss 0.097611919\n",
            "lp_loss 0.389297754\n",
            "lp_loss 0.283100694\n",
            "lp_loss 0.860482216\n",
            "lp_loss 0.376188636\n",
            "lp_loss 0.250561327\n",
            "lp_loss 1.04520202\n",
            "lp_loss 0.472720712\n",
            "lp_loss 0.70452559\n",
            "lp_loss 0.249100164\n",
            "lp_loss 0.346422404\n",
            "lp_loss 0.915118873\n",
            "lp_loss 0.176779538\n",
            "lp_loss 2.00755572\n",
            "lp_loss 0.564132333\n",
            "lp_loss 1.02835631\n",
            "lp_loss 0.604522347\n",
            "lp_loss 0.269415021\n",
            "lp_loss 0.2262187\n",
            "lp_loss 0.00722631346\n",
            "lp_loss 1.36982512\n",
            "lp_loss 0.139129013\n",
            "lp_loss 0.628534436\n",
            "lp_loss 0.473982245\n",
            "lp_loss 0.52485925\n",
            "lp_loss 0.266319215\n",
            "lp_loss 0.160146058\n",
            "lp_loss 0.391526967\n",
            "lp_loss 0.0125255343\n",
            "lp_loss 0.587307096\n",
            "lp_loss 0.624537945\n",
            "lp_loss 0.444205612\n",
            "lp_loss 0.164157659\n",
            "lp_loss 0.532698095\n",
            "lp_loss 0.741182089\n",
            "lp_loss 0.380984843\n",
            "lp_loss 1.41253459\n",
            "lp_loss 0.140497118\n",
            "lp_loss 0.108113155\n",
            "lp_loss 0.883185685\n",
            "lp_loss 0.619288802\n",
            "lp_loss 1.64492393\n",
            "lp_loss 0.216261223\n",
            "lp_loss 0.271313846\n",
            "lp_loss 0.199494317\n",
            "lp_loss 0.389849097\n",
            "lp_loss 1.27696669\n",
            "lp_loss 0.513138175\n",
            "lp_loss 0.175737694\n",
            "lp_loss 0.641213179\n",
            "lp_loss 0.284864\n",
            "lp_loss 0.0875086784\n",
            "lp_loss 0.0955020562\n",
            "lp_loss 0.349285424\n",
            "lp_loss 0.0841054469\n",
            "lp_loss 0.420419127\n",
            "lp_loss 0.27701208\n",
            "lp_loss 0.853016198\n",
            "lp_loss 0.21407564\n",
            "lp_loss 0.465336025\n",
            "lp_loss 0.289535373\n",
            "lp_loss 0.396929651\n",
            "lp_loss 0.192372739\n",
            "lp_loss 0.0843820721\n",
            "lp_loss 0.304081738\n",
            "lp_loss 0.438365757\n",
            "lp_loss 0.310434073\n",
            "lp_loss 0.228286952\n",
            "lp_loss 0.577752233\n",
            "lp_loss 4.20870495\n",
            "lp_loss 0.236535147\n",
            "lp_loss 0.527224779\n",
            "lp_loss 0.323434293\n",
            "lp_loss 0.601571918\n",
            "lp_loss 0.763606\n",
            "lp_loss 0.210551411\n",
            "lp_loss 0.313015074\n",
            "lp_loss 0.328559756\n",
            "lp_loss 0.464677185\n",
            "lp_loss 0.389669299\n",
            "lp_loss 0.335027099\n",
            "lp_loss 0.100841485\n",
            "lp_loss 0.0220517069\n",
            "lp_loss 0.265004098\n",
            "lp_loss 0.0334985442\n",
            "lp_loss 1.98027897\n",
            "lp_loss 0.658645511\n",
            "lp_loss 0.0896625295\n",
            "lp_loss 0.439077944\n",
            "lp_loss 0.27768749\n",
            "lp_loss 0.0617626421\n",
            "lp_loss 0.150178105\n",
            "lp_loss 0.318561345\n",
            "lp_loss 1.8728224\n",
            "lp_loss 0.875356674\n",
            "lp_loss 0.268295586\n",
            "lp_loss 0.364686161\n",
            "lp_loss 0.0936421603\n",
            "lp_loss 0.539207339\n",
            "lp_loss 0.049100209\n",
            "lp_loss 1.36474204\n",
            "lp_loss 0.104767844\n",
            "lp_loss 0.250242859\n",
            "lp_loss 0.603503108\n",
            "lp_loss 0.602885187\n",
            "lp_loss 0.00702997064\n",
            "lp_loss 0.363461196\n",
            "lp_loss 0.266501248\n",
            "lp_loss 0.286667138\n",
            "lp_loss 0.358036608\n",
            "lp_loss 0.193203285\n",
            "lp_loss 0.0545532517\n",
            "lp_loss 0.134811908\n",
            "lp_loss 0.53192544\n",
            "lp_loss 0.912879765\n",
            "lp_loss 1.00517046\n",
            "lp_loss 0.139864132\n",
            "lp_loss 0.150931597\n",
            "lp_loss 0.443429887\n",
            "lp_loss 0.278192878\n",
            "lp_loss 0.210162684\n",
            "lp_loss 0.0495239608\n",
            "lp_loss 0.336993039\n",
            "lp_loss 0.464372635\n",
            "lp_loss 0.243257403\n",
            "lp_loss 0.153611973\n",
            "lp_loss 0.362414181\n",
            "lp_loss 0.160947368\n",
            "lp_loss 0.632560253\n",
            "lp_loss 0.740368128\n",
            "lp_loss 0.152350083\n",
            "lp_loss 0.202084854\n",
            "lp_loss 0.40645656\n",
            "lp_loss 0.583774805\n",
            "lp_loss 0.274217755\n",
            "lp_loss 0.228859335\n",
            "lp_loss 0.0425363407\n",
            "lp_loss 0.0665403381\n",
            "lp_loss 0.921952903\n",
            "lp_loss 0.44164747\n",
            "lp_loss 0.263901949\n",
            "lp_loss 0.0572086088\n",
            "lp_loss 0.813473105\n",
            "2020-01-30 19:33:31.902484\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.862264156\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 4963\n",
            "label_prediction_accuracy - Target: 0.206060603\n",
            "Beginning of epoch: 17\n",
            "lp_loss 0.177118897\n",
            "lp_loss 0.18869397\n",
            "lp_loss 0.689161777\n",
            "lp_loss 0.986562729\n",
            "lp_loss 0.180920571\n",
            "lp_loss 0.439665705\n",
            "lp_loss 0.34042421\n",
            "lp_loss 0.258028805\n",
            "lp_loss 0.228627533\n",
            "lp_loss 2.49200296\n",
            "lp_loss 1.44420958\n",
            "lp_loss 0.366730452\n",
            "lp_loss 0.929787934\n",
            "lp_loss 0.392009169\n",
            "lp_loss 0.253007829\n",
            "lp_loss 0.149532408\n",
            "lp_loss 0.0791303888\n",
            "lp_loss 0.0516411774\n",
            "lp_loss 0.130443156\n",
            "lp_loss 0.39779824\n",
            "lp_loss 0.1530222\n",
            "lp_loss 1.25052726\n",
            "lp_loss 0.12110655\n",
            "lp_loss 0.258720279\n",
            "lp_loss 0.365126103\n",
            "lp_loss 0.536069095\n",
            "lp_loss 0.403162569\n",
            "lp_loss 0.0537422\n",
            "lp_loss 0.451641947\n",
            "lp_loss 0.18970561\n",
            "lp_loss 0.0415275\n",
            "lp_loss 0.596606612\n",
            "lp_loss 0.632863879\n",
            "lp_loss 0.14895156\n",
            "lp_loss 0.1745812\n",
            "lp_loss 0.124408484\n",
            "lp_loss 0.096491158\n",
            "lp_loss 0.0663607\n",
            "lp_loss 0.309232414\n",
            "lp_loss 0.19074522\n",
            "lp_loss 1.09973419\n",
            "lp_loss 0.0766667\n",
            "lp_loss 0.320473\n",
            "lp_loss 0.425492376\n",
            "lp_loss 0.173950508\n",
            "lp_loss 0.460791022\n",
            "lp_loss 0.171802223\n",
            "lp_loss 0.106517233\n",
            "lp_loss 0.229802564\n",
            "lp_loss 1.86210823\n",
            "lp_loss 1.03847742\n",
            "lp_loss 0.135058329\n",
            "lp_loss 0.130279496\n",
            "lp_loss 0.084126547\n",
            "lp_loss 0.393504649\n",
            "lp_loss 0.540673196\n",
            "lp_loss 0.236320704\n",
            "lp_loss 0.429410636\n",
            "lp_loss 2.80978727\n",
            "lp_loss 0.0536759868\n",
            "lp_loss 0.0491602644\n",
            "lp_loss 0.32528162\n",
            "lp_loss 0.0865669549\n",
            "lp_loss 0.730644822\n",
            "lp_loss 0.408513635\n",
            "lp_loss 0.0847269446\n",
            "lp_loss 0.644518077\n",
            "lp_loss 0.725218\n",
            "lp_loss 0.0707143694\n",
            "lp_loss 0.0532385185\n",
            "lp_loss 0.238211781\n",
            "lp_loss 0.124680437\n",
            "lp_loss 0.676369309\n",
            "lp_loss 0.241184279\n",
            "lp_loss 0.0735851601\n",
            "lp_loss 1.0119791\n",
            "lp_loss 0.609700263\n",
            "lp_loss 0.248773411\n",
            "lp_loss 0.18011336\n",
            "lp_loss 0.121324703\n",
            "lp_loss 1.00263965\n",
            "lp_loss 0.079342857\n",
            "lp_loss 0.166522771\n",
            "lp_loss 0.86116755\n",
            "lp_loss 0.617697418\n",
            "lp_loss 0.552127719\n",
            "lp_loss 0.784773648\n",
            "lp_loss 0.176813021\n",
            "lp_loss 0.269555\n",
            "lp_loss 0.0209484268\n",
            "lp_loss 0.514258742\n",
            "lp_loss 0.396696091\n",
            "lp_loss 0.305096984\n",
            "lp_loss 0.268258274\n",
            "lp_loss 0.400509655\n",
            "lp_loss 0.363989294\n",
            "lp_loss 0.0819111317\n",
            "lp_loss 0.0756754354\n",
            "lp_loss 0.689430833\n",
            "lp_loss 0.683272481\n",
            "lp_loss 0.0997750387\n",
            "lp_loss 0.575217307\n",
            "lp_loss 0.0923181549\n",
            "lp_loss 0.192048773\n",
            "lp_loss 1.52240849\n",
            "lp_loss 0.885448337\n",
            "lp_loss 0.530784309\n",
            "lp_loss 0.758050323\n",
            "lp_loss 0.138328\n",
            "lp_loss 0.0276541803\n",
            "lp_loss 1.66084671\n",
            "lp_loss 0.0659460351\n",
            "lp_loss 0.130423278\n",
            "lp_loss 0.0776588172\n",
            "lp_loss 0.0868440345\n",
            "lp_loss 0.0775429904\n",
            "lp_loss 0.187955409\n",
            "lp_loss 0.0690323263\n",
            "lp_loss 0.105034068\n",
            "lp_loss 0.0303753167\n",
            "lp_loss 0.786432445\n",
            "lp_loss 1.23717558\n",
            "lp_loss 0.338784456\n",
            "lp_loss 1.13502812\n",
            "lp_loss 1.9080565\n",
            "lp_loss 0.0917817503\n",
            "lp_loss 0.607738078\n",
            "lp_loss 0.202811122\n",
            "lp_loss 0.293547809\n",
            "lp_loss 1.87154293\n",
            "lp_loss 0.205766439\n",
            "lp_loss 1.03618932\n",
            "lp_loss 0.528672874\n",
            "lp_loss 0.200579494\n",
            "lp_loss 0.335811913\n",
            "lp_loss 0.120620832\n",
            "lp_loss 0.446164519\n",
            "lp_loss 0.088125363\n",
            "lp_loss 0.121431552\n",
            "lp_loss 0.0210610889\n",
            "lp_loss 0.689008474\n",
            "lp_loss 0.448350489\n",
            "lp_loss 0.213113263\n",
            "lp_loss 0.960449338\n",
            "lp_loss 0.248544499\n",
            "lp_loss 0.541353464\n",
            "lp_loss 0.439675\n",
            "lp_loss 0.406267792\n",
            "lp_loss 0.140626505\n",
            "lp_loss 0.787045836\n",
            "lp_loss 0.0894839\n",
            "lp_loss 0.17867586\n",
            "lp_loss 1.04220009\n",
            "lp_loss 0.609463871\n",
            "lp_loss 0.230011657\n",
            "lp_loss 0.527161121\n",
            "lp_loss 0.495209754\n",
            "lp_loss 0.0899212137\n",
            "lp_loss 0.485577345\n",
            "lp_loss 0.0254770722\n",
            "lp_loss 0.897875667\n",
            "lp_loss 0.276131213\n",
            "lp_loss 0.113536559\n",
            "lp_loss 0.0588977113\n",
            "lp_loss 0.0276934393\n",
            "lp_loss 0.41577965\n",
            "lp_loss 0.06236\n",
            "lp_loss 1.10517883\n",
            "lp_loss 0.21896939\n",
            "lp_loss 0.0478732437\n",
            "lp_loss 1.3578819\n",
            "lp_loss 1.93655074\n",
            "lp_loss 0.590795875\n",
            "lp_loss 0.386795521\n",
            "lp_loss 0.878262639\n",
            "lp_loss 0.31286329\n",
            "lp_loss 0.97846204\n",
            "lp_loss 0.0872058123\n",
            "lp_loss 0.215035826\n",
            "lp_loss 0.231909186\n",
            "lp_loss 0.0561354235\n",
            "lp_loss 0.235366911\n",
            "lp_loss 0.114477254\n",
            "lp_loss 0.685658574\n",
            "lp_loss 0.0271893088\n",
            "lp_loss 2.31627584\n",
            "lp_loss 0.105793521\n",
            "lp_loss 0.145695388\n",
            "lp_loss 0.122729138\n",
            "lp_loss 0.93433\n",
            "lp_loss 0.0642533824\n",
            "lp_loss 0.393623084\n",
            "lp_loss 1.84188199\n",
            "lp_loss 0.383960128\n",
            "lp_loss 0.718325317\n",
            "lp_loss 0.375395805\n",
            "lp_loss 0.0567851849\n",
            "lp_loss 0.175389647\n",
            "lp_loss 0.837803721\n",
            "lp_loss 1.25140727\n",
            "lp_loss 0.108830586\n",
            "lp_loss 0.0888639838\n",
            "lp_loss 0.157305568\n",
            "lp_loss 0.519160211\n",
            "lp_loss 0.739899874\n",
            "lp_loss 0.193355814\n",
            "lp_loss 0.306481034\n",
            "lp_loss 0.32561034\n",
            "lp_loss 1.32029057\n",
            "lp_loss 0.358430266\n",
            "lp_loss 0.0611457527\n",
            "2020-01-30 19:33:44.050319\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.876777232\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 5174\n",
            "label_prediction_accuracy - Target: 0.218181819\n",
            "Beginning of epoch: 18\n",
            "lp_loss 0.78237\n",
            "lp_loss 0.647545338\n",
            "lp_loss 0.304471195\n",
            "lp_loss 0.0255847666\n",
            "lp_loss 0.657926202\n",
            "lp_loss 0.0869144201\n",
            "lp_loss 0.716532707\n",
            "lp_loss 0.964955211\n",
            "lp_loss 0.437521398\n",
            "lp_loss 1.16803515\n",
            "lp_loss 0.215548709\n",
            "lp_loss 0.351819158\n",
            "lp_loss 0.181867033\n",
            "lp_loss 0.152133346\n",
            "lp_loss 0.596055806\n",
            "lp_loss 0.18138966\n",
            "lp_loss 1.12817454\n",
            "lp_loss 1.00815332\n",
            "lp_loss 0.050553523\n",
            "lp_loss 0.868502796\n",
            "lp_loss 0.27721\n",
            "lp_loss 0.116699\n",
            "lp_loss 0.602604449\n",
            "lp_loss 1.39422739\n",
            "lp_loss 0.438955396\n",
            "lp_loss 0.614631057\n",
            "lp_loss 0.0838749707\n",
            "lp_loss 1.03125501\n",
            "lp_loss 1.2487036\n",
            "lp_loss 0.747361541\n",
            "lp_loss 0.213783741\n",
            "lp_loss 0.0765911713\n",
            "lp_loss 0.201583\n",
            "lp_loss 0.416752964\n",
            "lp_loss 0.853466868\n",
            "lp_loss 0.287583172\n",
            "lp_loss 0.0809965\n",
            "lp_loss 0.546277225\n",
            "lp_loss 0.165068\n",
            "lp_loss 0.717167675\n",
            "lp_loss 0.0569782481\n",
            "lp_loss 1.00998497\n",
            "lp_loss 0.0385994725\n",
            "lp_loss 1.24280524\n",
            "lp_loss 0.639970899\n",
            "lp_loss 0.332239568\n",
            "lp_loss 0.841123462\n",
            "lp_loss 0.557785749\n",
            "lp_loss 0.0191519223\n",
            "lp_loss 0.28271386\n",
            "lp_loss 0.042090185\n",
            "lp_loss 0.458245099\n",
            "lp_loss 0.66832912\n",
            "lp_loss 0.0300857313\n",
            "lp_loss 0.152603716\n",
            "lp_loss 1.78990686\n",
            "lp_loss 0.0743522719\n",
            "lp_loss 0.532236755\n",
            "lp_loss 0.392075777\n",
            "lp_loss 1.5884794\n",
            "lp_loss 0.489452213\n",
            "lp_loss 0.280702442\n",
            "lp_loss 0.478885949\n",
            "lp_loss 1.73712\n",
            "lp_loss 0.0265673511\n",
            "lp_loss 1.4946965\n",
            "lp_loss 0.072104387\n",
            "lp_loss 0.314079821\n",
            "lp_loss 0.310784\n",
            "lp_loss 0.295401037\n",
            "lp_loss 0.641524315\n",
            "lp_loss 0.163461715\n",
            "lp_loss 0.452174902\n",
            "lp_loss 0.958346546\n",
            "lp_loss 0.20148775\n",
            "lp_loss 0.0398378968\n",
            "lp_loss 0.0523344092\n",
            "lp_loss 0.992814243\n",
            "lp_loss 0.11229068\n",
            "lp_loss 0.253354728\n",
            "lp_loss 0.0909403935\n",
            "lp_loss 0.934709191\n",
            "lp_loss 0.1935229\n",
            "lp_loss 0.435994804\n",
            "lp_loss 0.0867382288\n",
            "lp_loss 0.69126606\n",
            "lp_loss 0.0337982289\n",
            "lp_loss 0.321758807\n",
            "lp_loss 0.0272292\n",
            "lp_loss 0.752089679\n",
            "lp_loss 0.0681117922\n",
            "lp_loss 0.834570408\n",
            "lp_loss 0.272544563\n",
            "lp_loss 0.48997277\n",
            "lp_loss 0.0369886383\n",
            "lp_loss 0.101130441\n",
            "lp_loss 0.183743894\n",
            "lp_loss 0.0437380858\n",
            "lp_loss 0.00697886106\n",
            "lp_loss 0.446932554\n",
            "lp_loss 0.330266714\n",
            "lp_loss 0.0249186661\n",
            "lp_loss 0.145213395\n",
            "lp_loss 0.418773979\n",
            "lp_loss 0.101654865\n",
            "lp_loss 0.4432486\n",
            "lp_loss 0.0992874056\n",
            "lp_loss 0.392526925\n",
            "lp_loss 0.209049627\n",
            "lp_loss 0.335692942\n",
            "lp_loss 0.922406197\n",
            "lp_loss 0.091410622\n",
            "lp_loss 0.161371619\n",
            "lp_loss 0.0902614743\n",
            "lp_loss 0.680669\n",
            "lp_loss 0.031435132\n",
            "lp_loss 0.37493673\n",
            "lp_loss 0.954731584\n",
            "lp_loss 0.844198704\n",
            "lp_loss 0.118749544\n",
            "lp_loss 0.308530033\n",
            "lp_loss 0.309807062\n",
            "lp_loss 0.23600921\n",
            "lp_loss 0.171386734\n",
            "lp_loss 0.799749434\n",
            "lp_loss 0.22004199\n",
            "lp_loss 0.312682778\n",
            "lp_loss 0.146919101\n",
            "lp_loss 0.443396032\n",
            "lp_loss 0.198824212\n",
            "lp_loss 0.180182293\n",
            "lp_loss 0.105486847\n",
            "lp_loss 0.190304905\n",
            "lp_loss 0.297086865\n",
            "lp_loss 0.498918593\n",
            "lp_loss 1.45444191\n",
            "lp_loss 0.0551622\n",
            "lp_loss 1.27324677\n",
            "lp_loss 1.15953553\n",
            "lp_loss 0.590328872\n",
            "lp_loss 0.029195169\n",
            "lp_loss 0.18231833\n",
            "lp_loss 0.294787616\n",
            "lp_loss 0.321458757\n",
            "lp_loss 0.802069187\n",
            "lp_loss 0.589131474\n",
            "lp_loss 0.82978487\n",
            "lp_loss 0.176284105\n",
            "lp_loss 0.0625574663\n",
            "lp_loss 0.141980097\n",
            "lp_loss 0.0820188224\n",
            "lp_loss 0.155910566\n",
            "lp_loss 0.218642622\n",
            "lp_loss 0.226528257\n",
            "lp_loss 0.108712219\n",
            "lp_loss 0.27121222\n",
            "lp_loss 0.177779019\n",
            "lp_loss 0.183918357\n",
            "lp_loss 0.551592708\n",
            "lp_loss 0.298068464\n",
            "lp_loss 0.848374367\n",
            "lp_loss 0.106299639\n",
            "lp_loss 0.146431446\n",
            "lp_loss 0.117793843\n",
            "lp_loss 0.775818944\n",
            "lp_loss 0.297208846\n",
            "lp_loss 0.201151848\n",
            "lp_loss 0.748267055\n",
            "lp_loss 0.159825519\n",
            "lp_loss 0.353919655\n",
            "lp_loss 0.0389697775\n",
            "lp_loss 0.159242585\n",
            "lp_loss 0.168555811\n",
            "lp_loss 0.262518018\n",
            "lp_loss 0.362758517\n",
            "lp_loss 0.319679171\n",
            "lp_loss 0.380686462\n",
            "lp_loss 0.156225488\n",
            "lp_loss 0.438750893\n",
            "lp_loss 2.87754059\n",
            "lp_loss 0.0284620821\n",
            "lp_loss 0.0319324844\n",
            "lp_loss 0.20256047\n",
            "lp_loss 0.0376589075\n",
            "lp_loss 0.743292928\n",
            "lp_loss 0.285961092\n",
            "lp_loss 0.449873686\n",
            "lp_loss 0.25307861\n",
            "lp_loss 0.67268306\n",
            "lp_loss 0.126046494\n",
            "lp_loss 0.350722253\n",
            "lp_loss 1.06620455\n",
            "lp_loss 0.174016684\n",
            "lp_loss 0.0326190516\n",
            "lp_loss 1.55869246\n",
            "lp_loss 0.0166503601\n",
            "lp_loss 0.205093056\n",
            "lp_loss 0.875014901\n",
            "lp_loss 0.183449432\n",
            "lp_loss 0.242106289\n",
            "lp_loss 0.128774613\n",
            "lp_loss 0.0479587317\n",
            "lp_loss 0.155517638\n",
            "lp_loss 1.71197093\n",
            "lp_loss 0.162852198\n",
            "lp_loss 0.245050162\n",
            "lp_loss 0.241914362\n",
            "lp_loss 0.321231455\n",
            "lp_loss 0.136831969\n",
            "lp_loss 0.149247885\n",
            "lp_loss 0.186176866\n",
            "2020-01-30 19:33:56.796560\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.881516576\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 5385\n",
            "label_prediction_accuracy - Target: 0.196969703\n",
            "Beginning of epoch: 19\n",
            "lp_loss 0.0804147348\n",
            "lp_loss 0.114135206\n",
            "lp_loss 1.61477685\n",
            "lp_loss 0.166303724\n",
            "lp_loss 0.223259568\n",
            "lp_loss 0.156093627\n",
            "lp_loss 0.551962674\n",
            "lp_loss 0.313293874\n",
            "lp_loss 0.761744916\n",
            "lp_loss 0.0430878773\n",
            "lp_loss 0.259976447\n",
            "lp_loss 0.211836502\n",
            "lp_loss 0.180871516\n",
            "lp_loss 0.383692414\n",
            "lp_loss 0.219198138\n",
            "lp_loss 0.478539705\n",
            "lp_loss 0.0228617173\n",
            "lp_loss 0.279071271\n",
            "lp_loss 0.540142298\n",
            "lp_loss 0.0888641328\n",
            "lp_loss 1.11344898\n",
            "lp_loss 0.426599354\n",
            "lp_loss 0.25428614\n",
            "lp_loss 0.0639597327\n",
            "lp_loss 0.0137653\n",
            "lp_loss 0.175893277\n",
            "lp_loss 0.301109642\n",
            "lp_loss 0.139464572\n",
            "lp_loss 0.0336816795\n",
            "lp_loss 0.375559151\n",
            "lp_loss 0.857597053\n",
            "lp_loss 0.178490669\n",
            "lp_loss 0.344811946\n",
            "lp_loss 0.763967395\n",
            "lp_loss 0.6673069\n",
            "lp_loss 0.584505081\n",
            "lp_loss 0.150370911\n",
            "lp_loss 0.708313286\n",
            "lp_loss 1.90630114\n",
            "lp_loss 1.33371186\n",
            "lp_loss 0.308629334\n",
            "lp_loss 0.630534708\n",
            "lp_loss 0.110578135\n",
            "lp_loss 0.804308712\n",
            "lp_loss 0.0791762322\n",
            "lp_loss 0.190171987\n",
            "lp_loss 0.781415761\n",
            "lp_loss 0.0823355094\n",
            "lp_loss 0.726187289\n",
            "lp_loss 0.700636506\n",
            "lp_loss 0.753213525\n",
            "lp_loss 0.635808825\n",
            "lp_loss 0.084089458\n",
            "lp_loss 0.136804372\n",
            "lp_loss 0.677648902\n",
            "lp_loss 0.0788472295\n",
            "lp_loss 0.035838265\n",
            "lp_loss 0.390032351\n",
            "lp_loss 0.707651317\n",
            "lp_loss 0.0752703622\n",
            "lp_loss 0.0325005576\n",
            "lp_loss 0.118946053\n",
            "lp_loss 0.23201403\n",
            "lp_loss 0.541200697\n",
            "lp_loss 0.616198659\n",
            "lp_loss 0.554709077\n",
            "lp_loss 0.0662453\n",
            "lp_loss 0.474563897\n",
            "lp_loss 1.20899224\n",
            "lp_loss 1.01758194\n",
            "lp_loss 0.692211032\n",
            "lp_loss 1.96158886\n",
            "lp_loss 0.358758181\n",
            "lp_loss 0.219179\n",
            "lp_loss 0.89043963\n",
            "lp_loss 0.812019706\n",
            "lp_loss 0.0468996949\n",
            "lp_loss 0.461459816\n",
            "lp_loss 0.0360672437\n",
            "lp_loss 0.14593251\n",
            "lp_loss 0.553325117\n",
            "lp_loss 0.479064941\n",
            "lp_loss 0.125707433\n",
            "lp_loss 0.865440369\n",
            "lp_loss 0.0139866713\n",
            "lp_loss 0.212203339\n",
            "lp_loss 0.390324146\n",
            "lp_loss 0.0817722231\n",
            "lp_loss 0.280329585\n",
            "lp_loss 1.33632243\n",
            "lp_loss 0.262014925\n",
            "lp_loss 0.158290312\n",
            "lp_loss 0.789546251\n",
            "lp_loss 0.116968915\n",
            "lp_loss 0.0979538113\n",
            "lp_loss 0.101016924\n",
            "lp_loss 0.380818069\n",
            "lp_loss 0.442946345\n",
            "lp_loss 0.712342322\n",
            "lp_loss 0.0917443559\n",
            "lp_loss 0.399690092\n",
            "lp_loss 0.748664677\n",
            "lp_loss 0.496912062\n",
            "lp_loss 0.234336928\n",
            "lp_loss 1.21549439\n",
            "lp_loss 0.179887101\n",
            "lp_loss 0.0193989817\n",
            "lp_loss 1.82661271\n",
            "lp_loss 0.344387561\n",
            "lp_loss 0.458253562\n",
            "lp_loss 0.119279459\n",
            "lp_loss 0.0677470788\n",
            "lp_loss 0.405937672\n",
            "lp_loss 0.0543775856\n",
            "lp_loss 0.209829\n",
            "lp_loss 0.405761629\n",
            "lp_loss 0.18206732\n",
            "lp_loss 0.769435465\n",
            "lp_loss 0.241844222\n",
            "lp_loss 0.114990115\n",
            "lp_loss 0.222138599\n",
            "lp_loss 0.461222649\n",
            "lp_loss 1.32906055\n",
            "lp_loss 0.214095145\n",
            "lp_loss 0.146821946\n",
            "lp_loss 0.107774854\n",
            "lp_loss 2.39803123\n",
            "lp_loss 0.756522954\n",
            "lp_loss 2.20261788\n",
            "lp_loss 1.39860404\n",
            "lp_loss 0.146616191\n",
            "lp_loss 0.178638846\n",
            "lp_loss 0.884421945\n",
            "lp_loss 0.228711843\n",
            "lp_loss 0.185587853\n",
            "lp_loss 0.0382932499\n",
            "lp_loss 1.27447903\n",
            "lp_loss 0.198279977\n",
            "lp_loss 1.32277954\n",
            "lp_loss 0.124337651\n",
            "lp_loss 0.0954066366\n",
            "lp_loss 1.50907564\n",
            "lp_loss 0.0637674704\n",
            "lp_loss 0.418205172\n",
            "lp_loss 0.18957977\n",
            "lp_loss 0.10208597\n",
            "lp_loss 1.80189586\n",
            "lp_loss 0.102359712\n",
            "lp_loss 0.0522112548\n",
            "lp_loss 1.19257486\n",
            "lp_loss 0.170254037\n",
            "lp_loss 0.389167219\n",
            "lp_loss 0.507665515\n",
            "lp_loss 0.704130411\n",
            "lp_loss 0.666201472\n",
            "lp_loss 0.397269785\n",
            "lp_loss 0.474309295\n",
            "lp_loss 0.190370768\n",
            "lp_loss 0.0135589093\n",
            "lp_loss 0.868682683\n",
            "lp_loss 0.300168633\n",
            "lp_loss 0.122564927\n",
            "lp_loss 0.331838518\n",
            "lp_loss 0.166308746\n",
            "lp_loss 0.310289115\n",
            "lp_loss 0.178745061\n",
            "lp_loss 0.495265871\n",
            "lp_loss 0.733312488\n",
            "lp_loss 0.447152525\n",
            "lp_loss 0.292057693\n",
            "lp_loss 0.153930023\n",
            "lp_loss 1.46096158\n",
            "lp_loss 1.44559741\n",
            "lp_loss 0.170256406\n",
            "lp_loss 0.123925723\n",
            "lp_loss 0.168299705\n",
            "lp_loss 0.134028703\n",
            "lp_loss 0.167501643\n",
            "lp_loss 0.142855316\n",
            "lp_loss 0.85853672\n",
            "lp_loss 0.134737715\n",
            "lp_loss 0.245927215\n",
            "lp_loss 0.186431035\n",
            "lp_loss 0.141515821\n",
            "lp_loss 0.0955364704\n",
            "lp_loss 0.280827314\n",
            "lp_loss 0.0390764177\n",
            "lp_loss 0.442369521\n",
            "lp_loss 0.223325923\n",
            "lp_loss 0.0858144\n",
            "lp_loss 0.150588274\n",
            "lp_loss 0.452657163\n",
            "lp_loss 1.07004583\n",
            "lp_loss 0.154850021\n",
            "lp_loss 0.43226704\n",
            "lp_loss 0.00882853\n",
            "lp_loss 0.355557978\n",
            "lp_loss 1.60385191\n",
            "lp_loss 0.654885292\n",
            "lp_loss 0.741767764\n",
            "lp_loss 0.332606643\n",
            "lp_loss 0.577449203\n",
            "lp_loss 2.13375926\n",
            "lp_loss 0.128763467\n",
            "lp_loss 0.42729038\n",
            "lp_loss 2.31063914\n",
            "lp_loss 0.297041088\n",
            "lp_loss 0.121048465\n",
            "lp_loss 0.49720487\n",
            "lp_loss 0.016576631\n",
            "lp_loss 0.26130718\n",
            "2020-01-30 19:34:09.711674\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.870142162\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 5596\n",
            "label_prediction_accuracy - Target: 0.227272734\n",
            "Beginning of epoch: 20\n",
            "lp_loss 0.331375748\n",
            "lp_loss 0.130189121\n",
            "lp_loss 0.0930268\n",
            "lp_loss 0.0802378803\n",
            "lp_loss 0.288223594\n",
            "lp_loss 0.115252815\n",
            "lp_loss 0.0480459556\n",
            "lp_loss 0.151148036\n",
            "lp_loss 0.0860455781\n",
            "lp_loss 0.0793128833\n",
            "lp_loss 0.0949624628\n",
            "lp_loss 0.3402206\n",
            "lp_loss 0.108077191\n",
            "lp_loss 0.12296889\n",
            "lp_loss 0.128538102\n",
            "lp_loss 2.40031862\n",
            "lp_loss 0.394609421\n",
            "lp_loss 0.607088685\n",
            "lp_loss 0.26752919\n",
            "lp_loss 0.384381235\n",
            "lp_loss 0.294675797\n",
            "lp_loss 0.41852212\n",
            "lp_loss 0.553301632\n",
            "lp_loss 0.0401776657\n",
            "lp_loss 0.328559041\n",
            "lp_loss 0.524634659\n",
            "lp_loss 0.554594398\n",
            "lp_loss 0.063057743\n",
            "lp_loss 1.69597852\n",
            "lp_loss 0.326759398\n",
            "lp_loss 0.332793355\n",
            "lp_loss 0.0722153\n",
            "lp_loss 0.00803703628\n",
            "lp_loss 0.390912086\n",
            "lp_loss 0.624622345\n",
            "lp_loss 0.546111\n",
            "lp_loss 0.0503728688\n",
            "lp_loss 0.29023394\n",
            "lp_loss 0.105377421\n",
            "lp_loss 0.0636628866\n",
            "lp_loss 0.128434181\n",
            "lp_loss 0.0284005515\n",
            "lp_loss 0.355362922\n",
            "lp_loss 0.124511823\n",
            "lp_loss 0.372353941\n",
            "lp_loss 0.360558063\n",
            "lp_loss 0.489455521\n",
            "lp_loss 0.0835679919\n",
            "lp_loss 0.435816765\n",
            "lp_loss 0.342420131\n",
            "lp_loss 0.126194537\n",
            "lp_loss 0.89236623\n",
            "lp_loss 0.0121962298\n",
            "lp_loss 0.674412847\n",
            "lp_loss 0.166108578\n",
            "lp_loss 0.236742139\n",
            "lp_loss 0.145711347\n",
            "lp_loss 0.5166291\n",
            "lp_loss 0.520702064\n",
            "lp_loss 0.407648981\n",
            "lp_loss 0.073838532\n",
            "lp_loss 0.16568628\n",
            "lp_loss 0.358780593\n",
            "lp_loss 0.0865988657\n",
            "lp_loss 0.0323831066\n",
            "lp_loss 0.0443696454\n",
            "lp_loss 0.0142326374\n",
            "lp_loss 0.0609588847\n",
            "lp_loss 0.0819950402\n",
            "lp_loss 0.147814453\n",
            "lp_loss 0.617233157\n",
            "lp_loss 0.517916322\n",
            "lp_loss 0.498198211\n",
            "lp_loss 0.0783785135\n",
            "lp_loss 0.0461643375\n",
            "lp_loss 0.267428458\n",
            "lp_loss 0.177610278\n",
            "lp_loss 0.620705366\n",
            "lp_loss 0.0327090696\n",
            "lp_loss 0.0450036898\n",
            "lp_loss 0.0728695318\n",
            "lp_loss 0.0488862693\n",
            "lp_loss 0.345202625\n",
            "lp_loss 0.0084853489\n",
            "lp_loss 1.46353424\n",
            "lp_loss 0.203124091\n",
            "lp_loss 0.187289983\n",
            "lp_loss 0.220181465\n",
            "lp_loss 0.830680251\n",
            "lp_loss 0.275157779\n",
            "lp_loss 0.135727316\n",
            "lp_loss 0.156562909\n",
            "lp_loss 0.0485934652\n",
            "lp_loss 0.386677116\n",
            "lp_loss 0.84053421\n",
            "lp_loss 0.603832722\n",
            "lp_loss 1.57251358\n",
            "lp_loss 0.0178570114\n",
            "lp_loss 0.0484580286\n",
            "lp_loss 0.270508885\n",
            "lp_loss 0.255408168\n",
            "lp_loss 0.185272977\n",
            "lp_loss 0.704277098\n",
            "lp_loss 0.952515781\n",
            "lp_loss 0.408899635\n",
            "lp_loss 0.508250892\n",
            "lp_loss 1.54918468\n",
            "lp_loss 0.580869555\n",
            "lp_loss 1.67237115\n",
            "lp_loss 0.293506771\n",
            "lp_loss 0.427875042\n",
            "lp_loss 0.135770306\n",
            "lp_loss 0.0536765978\n",
            "lp_loss 0.672109485\n",
            "lp_loss 0.976796627\n",
            "lp_loss 0.00958259683\n",
            "lp_loss 0.0629022\n",
            "lp_loss 1.02663898\n",
            "lp_loss 0.257754147\n",
            "lp_loss 0.942344964\n",
            "lp_loss 1.87988853\n",
            "lp_loss 0.61210537\n",
            "lp_loss 0.0689210817\n",
            "lp_loss 0.982201397\n",
            "lp_loss 0.796164513\n",
            "lp_loss 0.0859903693\n",
            "lp_loss 0.656076968\n",
            "lp_loss 0.544985116\n",
            "lp_loss 0.284419596\n",
            "lp_loss 0.305984795\n",
            "lp_loss 0.139304757\n",
            "lp_loss 0.0802659243\n",
            "lp_loss 0.18147251\n",
            "lp_loss 0.400315106\n",
            "lp_loss 0.136427224\n",
            "lp_loss 0.223038048\n",
            "lp_loss 1.94162524\n",
            "lp_loss 0.353569925\n",
            "lp_loss 2.47155213\n",
            "lp_loss 0.0163910799\n",
            "lp_loss 0.175977916\n",
            "lp_loss 0.352052093\n",
            "lp_loss 0.207492277\n",
            "lp_loss 0.19261685\n",
            "lp_loss 0.288321942\n",
            "lp_loss 0.181510404\n",
            "lp_loss 0.66266191\n",
            "lp_loss 0.17169553\n",
            "lp_loss 0.556148887\n",
            "lp_loss 0.0914593562\n",
            "lp_loss 0.129406467\n",
            "lp_loss 0.0904188305\n",
            "lp_loss 0.0196280628\n",
            "lp_loss 0.0934790373\n",
            "lp_loss 0.320898682\n",
            "lp_loss 0.454010576\n",
            "lp_loss 0.441842884\n",
            "lp_loss 0.23976633\n",
            "lp_loss 0.61197561\n",
            "lp_loss 0.386001468\n",
            "lp_loss 0.0642073676\n",
            "lp_loss 0.142712831\n",
            "lp_loss 0.0897472352\n",
            "lp_loss 0.0927709788\n",
            "lp_loss 0.132703274\n",
            "lp_loss 0.546058536\n",
            "lp_loss 0.119750902\n",
            "lp_loss 0.435651124\n",
            "lp_loss 0.428592592\n",
            "lp_loss 0.116196021\n",
            "lp_loss 0.148830965\n",
            "lp_loss 0.210972503\n",
            "lp_loss 1.81297946\n",
            "lp_loss 0.0922083184\n",
            "lp_loss 0.625951469\n",
            "lp_loss 1.49876547\n",
            "lp_loss 0.0521309748\n",
            "lp_loss 0.0430455506\n",
            "lp_loss 0.180231467\n",
            "lp_loss 0.286308289\n",
            "lp_loss 0.117460325\n",
            "lp_loss 1.169842\n",
            "lp_loss 0.192745581\n",
            "lp_loss 0.53705436\n",
            "lp_loss 0.20700936\n",
            "lp_loss 0.195351452\n",
            "lp_loss 0.0747433752\n",
            "lp_loss 0.0715053231\n",
            "lp_loss 0.162469476\n",
            "lp_loss 0.249663636\n",
            "lp_loss 0.493899196\n",
            "lp_loss 0.0421222709\n",
            "lp_loss 0.335142344\n",
            "lp_loss 1.89394605\n",
            "lp_loss 0.0317536667\n",
            "lp_loss 0.383157521\n",
            "lp_loss 1.14936769\n",
            "lp_loss 0.637368441\n",
            "lp_loss 0.0136617916\n",
            "lp_loss 0.277098209\n",
            "lp_loss 0.506156445\n",
            "lp_loss 0.222058296\n",
            "lp_loss 0.674888492\n",
            "lp_loss 0.297795624\n",
            "lp_loss 0.261778861\n",
            "lp_loss 0.155207902\n",
            "lp_loss 0.195521027\n",
            "lp_loss 0.092174381\n",
            "lp_loss 0.213214129\n",
            "lp_loss 0.694315553\n",
            "lp_loss 2.52021074\n",
            "2020-01-30 19:34:23.025004\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.889099538\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 5807\n",
            "label_prediction_accuracy - Target: 0.215151519\n",
            "Beginning of epoch: 21\n",
            "lp_loss 0.679377258\n",
            "lp_loss 0.0484469831\n",
            "lp_loss 0.912894726\n",
            "lp_loss 0.0743505731\n",
            "lp_loss 0.47576952\n",
            "lp_loss 0.664831042\n",
            "lp_loss 1.34332931\n",
            "lp_loss 0.571549416\n",
            "lp_loss 1.43781495\n",
            "lp_loss 0.0759524107\n",
            "lp_loss 0.223990709\n",
            "lp_loss 0.802594364\n",
            "lp_loss 0.613295078\n",
            "lp_loss 1.11334801\n",
            "lp_loss 0.346392393\n",
            "lp_loss 0.0819791\n",
            "lp_loss 2.71020722\n",
            "lp_loss 0.34275189\n",
            "lp_loss 0.605903149\n",
            "lp_loss 0.164891869\n",
            "lp_loss 0.342261851\n",
            "lp_loss 0.519486\n",
            "lp_loss 0.0365421548\n",
            "lp_loss 0.488896757\n",
            "lp_loss 0.422582\n",
            "lp_loss 1.42892087\n",
            "lp_loss 0.142423585\n",
            "lp_loss 0.149211377\n",
            "lp_loss 0.406707585\n",
            "lp_loss 0.76927191\n",
            "lp_loss 0.813725352\n",
            "lp_loss 0.0271986667\n",
            "lp_loss 0.208131954\n",
            "lp_loss 0.588612437\n",
            "lp_loss 0.529829621\n",
            "lp_loss 0.0760144591\n",
            "lp_loss 0.330376089\n",
            "lp_loss 0.327359378\n",
            "lp_loss 0.0360013619\n",
            "lp_loss 0.398051918\n",
            "lp_loss 1.19492221\n",
            "lp_loss 0.922638237\n",
            "lp_loss 0.133447915\n",
            "lp_loss 0.0266057942\n",
            "lp_loss 2.10886478\n",
            "lp_loss 1.45778871\n",
            "lp_loss 0.253604054\n",
            "lp_loss 0.0994670391\n",
            "lp_loss 0.171096\n",
            "lp_loss 0.0786886513\n",
            "lp_loss 0.307017356\n",
            "lp_loss 0.0398618802\n",
            "lp_loss 1.5291419\n",
            "lp_loss 0.0869459063\n",
            "lp_loss 0.0342632234\n",
            "lp_loss 0.112927042\n",
            "lp_loss 0.953717232\n",
            "lp_loss 0.412693352\n",
            "lp_loss 2.00712276\n",
            "lp_loss 0.522440851\n",
            "lp_loss 0.13884595\n",
            "lp_loss 1.04507136\n",
            "lp_loss 0.171534255\n",
            "lp_loss 0.10015621\n",
            "lp_loss 0.0548245125\n",
            "lp_loss 0.360223681\n",
            "lp_loss 0.112230554\n",
            "lp_loss 0.0549577177\n",
            "lp_loss 0.440520614\n",
            "lp_loss 0.0805617\n",
            "lp_loss 0.0569325089\n",
            "lp_loss 0.028430298\n",
            "lp_loss 0.179492041\n",
            "lp_loss 0.622129083\n",
            "lp_loss 0.118885159\n",
            "lp_loss 0.116682947\n",
            "lp_loss 0.830343843\n",
            "lp_loss 0.654598296\n",
            "lp_loss 0.601835907\n",
            "lp_loss 0.135311007\n",
            "lp_loss 0.084568508\n",
            "lp_loss 0.0502763875\n",
            "lp_loss 0.198344633\n",
            "lp_loss 0.0543669872\n",
            "lp_loss 0.544269741\n",
            "lp_loss 0.756258607\n",
            "lp_loss 0.252088606\n",
            "lp_loss 0.224076062\n",
            "lp_loss 0.684848309\n",
            "lp_loss 1.27314401\n",
            "lp_loss 0.0793184116\n",
            "lp_loss 0.209775567\n",
            "lp_loss 0.101064131\n",
            "lp_loss 2.12901545\n",
            "lp_loss 0.226307198\n",
            "lp_loss 0.60659945\n",
            "lp_loss 0.0740361512\n",
            "lp_loss 0.0895782709\n",
            "lp_loss 1.06499636\n",
            "lp_loss 0.581708491\n",
            "lp_loss 0.356802076\n",
            "lp_loss 0.826982677\n",
            "lp_loss 0.611552119\n",
            "lp_loss 0.534307957\n",
            "lp_loss 0.0715581775\n",
            "lp_loss 0.745240271\n",
            "lp_loss 0.189675674\n",
            "lp_loss 0.0421318784\n",
            "lp_loss 0.231215626\n",
            "lp_loss 0.803061485\n",
            "lp_loss 0.916219354\n",
            "lp_loss 0.546730936\n",
            "lp_loss 0.306162208\n",
            "lp_loss 0.410853624\n",
            "lp_loss 0.189249605\n",
            "lp_loss 0.663863301\n",
            "lp_loss 0.231525332\n",
            "lp_loss 0.274291933\n",
            "lp_loss 0.222369477\n",
            "lp_loss 0.269345462\n",
            "lp_loss 1.02923024\n",
            "lp_loss 0.0582688674\n",
            "lp_loss 0.0692204535\n",
            "lp_loss 0.972463429\n",
            "lp_loss 1.32859015\n",
            "lp_loss 0.375334382\n",
            "lp_loss 0.386602163\n",
            "lp_loss 0.104687706\n",
            "lp_loss 0.705180943\n",
            "lp_loss 0.191914573\n",
            "lp_loss 0.25608483\n",
            "lp_loss 0.441900581\n",
            "lp_loss 0.237031057\n",
            "lp_loss 0.248691201\n",
            "lp_loss 0.0593974702\n",
            "lp_loss 0.398586184\n",
            "lp_loss 0.780174553\n",
            "lp_loss 0.293535709\n",
            "lp_loss 0.0249920469\n",
            "lp_loss 0.982744813\n",
            "lp_loss 0.417110682\n",
            "lp_loss 0.412233651\n",
            "lp_loss 0.472294509\n",
            "lp_loss 0.631039321\n",
            "lp_loss 0.552075207\n",
            "lp_loss 0.593513727\n",
            "lp_loss 1.50868201\n",
            "lp_loss 0.280139953\n",
            "lp_loss 0.637247324\n",
            "lp_loss 0.27584669\n",
            "lp_loss 0.199637532\n",
            "lp_loss 0.618667841\n",
            "lp_loss 0.702179074\n",
            "lp_loss 0.0599983633\n",
            "lp_loss 0.0550952926\n",
            "lp_loss 0.652208209\n",
            "lp_loss 0.788258255\n",
            "lp_loss 1.74059486\n",
            "lp_loss 0.226191565\n",
            "lp_loss 0.527325928\n",
            "lp_loss 0.0197936259\n",
            "lp_loss 0.0361019112\n",
            "lp_loss 0.706679463\n",
            "lp_loss 0.0601345114\n",
            "lp_loss 0.577155232\n",
            "lp_loss 0.143417791\n",
            "lp_loss 0.417417675\n",
            "lp_loss 0.562776625\n",
            "lp_loss 0.277372271\n",
            "lp_loss 0.469477564\n",
            "lp_loss 0.333437264\n",
            "lp_loss 2.38415742\n",
            "lp_loss 0.421844661\n",
            "lp_loss 0.403856844\n",
            "lp_loss 0.263036072\n",
            "lp_loss 0.184764341\n",
            "lp_loss 0.407775491\n",
            "lp_loss 0.223220915\n",
            "lp_loss 0.496989429\n",
            "lp_loss 1.54453158\n",
            "lp_loss 1.02377152\n",
            "lp_loss 0.272169381\n",
            "lp_loss 1.27387118\n",
            "lp_loss 0.3895064\n",
            "lp_loss 0.144995928\n",
            "lp_loss 0.602152467\n",
            "lp_loss 0.118086159\n",
            "lp_loss 0.936929405\n",
            "lp_loss 0.165440798\n",
            "lp_loss 0.283617318\n",
            "lp_loss 0.574459791\n",
            "lp_loss 1.65055084\n",
            "lp_loss 0.180039331\n",
            "lp_loss 0.181114256\n",
            "lp_loss 0.214813679\n",
            "lp_loss 0.380638182\n",
            "lp_loss 0.175180629\n",
            "lp_loss 0.45853883\n",
            "lp_loss 0.826891303\n",
            "lp_loss 0.280177534\n",
            "lp_loss 0.121716276\n",
            "lp_loss 0.704764247\n",
            "lp_loss 0.0822342113\n",
            "lp_loss 0.0505927689\n",
            "lp_loss 0.0724982098\n",
            "lp_loss 0.0480985865\n",
            "lp_loss 0.189672783\n",
            "lp_loss 0.516042471\n",
            "lp_loss 0.0883305445\n",
            "lp_loss 0.487868726\n",
            "lp_loss 0.18932566\n",
            "lp_loss 0.530476391\n",
            "2020-01-30 19:34:35.605362\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.857547164\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 6019\n",
            "label_prediction_accuracy - Target: 0.224242419\n",
            "Beginning of epoch: 22\n",
            "lp_loss 0.122200832\n",
            "lp_loss 0.142755538\n",
            "lp_loss 0.418575227\n",
            "lp_loss 1.06768203\n",
            "lp_loss 0.120696068\n",
            "lp_loss 0.255088031\n",
            "lp_loss 0.35034889\n",
            "lp_loss 0.572947323\n",
            "lp_loss 0.168859154\n",
            "lp_loss 0.053754963\n",
            "lp_loss 0.158901364\n",
            "lp_loss 0.209563807\n",
            "lp_loss 0.424395889\n",
            "lp_loss 0.637580752\n",
            "lp_loss 0.164866939\n",
            "lp_loss 1.41512561\n",
            "lp_loss 0.310260832\n",
            "lp_loss 0.569651\n",
            "lp_loss 0.0930966809\n",
            "lp_loss 0.165296435\n",
            "lp_loss 0.931257248\n",
            "lp_loss 1.21447289\n",
            "lp_loss 0.0902285576\n",
            "lp_loss 1.1683408\n",
            "lp_loss 0.103116654\n",
            "lp_loss 1.20375562\n",
            "lp_loss 0.0258414\n",
            "lp_loss 0.0261485614\n",
            "lp_loss 0.0803715214\n",
            "lp_loss 0.196688607\n",
            "lp_loss 0.515877426\n",
            "lp_loss 0.256869912\n",
            "lp_loss 0.459493458\n",
            "lp_loss 0.104416408\n",
            "lp_loss 0.201113299\n",
            "lp_loss 1.09614062\n",
            "lp_loss 0.2614972\n",
            "lp_loss 0.065984413\n",
            "lp_loss 0.548635125\n",
            "lp_loss 0.195685551\n",
            "lp_loss 0.588064313\n",
            "lp_loss 0.362862408\n",
            "lp_loss 1.72724116\n",
            "lp_loss 0.142782494\n",
            "lp_loss 0.355297267\n",
            "lp_loss 0.0855346695\n",
            "lp_loss 2.81999731\n",
            "lp_loss 0.659666181\n",
            "lp_loss 0.274571091\n",
            "lp_loss 0.0568190441\n",
            "lp_loss 0.395148188\n",
            "lp_loss 2.01686144\n",
            "lp_loss 0.914550126\n",
            "lp_loss 0.110644445\n",
            "lp_loss 0.388966382\n",
            "lp_loss 0.994754136\n",
            "lp_loss 0.261291265\n",
            "lp_loss 1.85458219\n",
            "lp_loss 0.0959628075\n",
            "lp_loss 0.0994719118\n",
            "lp_loss 1.39998317\n",
            "lp_loss 0.166680336\n",
            "lp_loss 0.385601223\n",
            "lp_loss 0.06823311\n",
            "lp_loss 1.17682195\n",
            "lp_loss 1.10901141\n",
            "lp_loss 0.309896559\n",
            "lp_loss 0.0491868\n",
            "lp_loss 0.618947387\n",
            "lp_loss 0.393562794\n",
            "lp_loss 0.194373578\n",
            "lp_loss 0.87024945\n",
            "lp_loss 0.687542379\n",
            "lp_loss 0.251579791\n",
            "lp_loss 0.523433566\n",
            "lp_loss 0.181720719\n",
            "lp_loss 1.17115176\n",
            "lp_loss 0.0644069165\n",
            "lp_loss 0.217863277\n",
            "lp_loss 0.221337467\n",
            "lp_loss 0.178527623\n",
            "lp_loss 0.76071918\n",
            "lp_loss 0.579417884\n",
            "lp_loss 0.689400852\n",
            "lp_loss 0.127606153\n",
            "lp_loss 0.0644605309\n",
            "lp_loss 0.196163282\n",
            "lp_loss 1.22534168\n",
            "lp_loss 0.237970755\n",
            "lp_loss 0.839713573\n",
            "lp_loss 0.501354098\n",
            "lp_loss 0.127773792\n",
            "lp_loss 0.33564648\n",
            "lp_loss 0.0237720367\n",
            "lp_loss 0.278580606\n",
            "lp_loss 0.0749972239\n",
            "lp_loss 0.40020138\n",
            "lp_loss 0.393785328\n",
            "lp_loss 0.353787959\n",
            "lp_loss 1.78395772\n",
            "lp_loss 0.581328273\n",
            "lp_loss 0.161900774\n",
            "lp_loss 1.64939344\n",
            "lp_loss 0.535052359\n",
            "lp_loss 0.214805439\n",
            "lp_loss 0.481631368\n",
            "lp_loss 0.202855259\n",
            "lp_loss 0.566738605\n",
            "lp_loss 0.0523096919\n",
            "lp_loss 0.0985805243\n",
            "lp_loss 0.0631134287\n",
            "lp_loss 0.369558871\n",
            "lp_loss 0.298577487\n",
            "lp_loss 0.0159693323\n",
            "lp_loss 0.696417868\n",
            "lp_loss 1.73020899\n",
            "lp_loss 0.335541487\n",
            "lp_loss 0.857160211\n",
            "lp_loss 1.00303018\n",
            "lp_loss 0.154100075\n",
            "lp_loss 0.126054838\n",
            "lp_loss 0.0665711612\n",
            "lp_loss 0.110683277\n",
            "lp_loss 0.341946602\n",
            "lp_loss 0.118863344\n",
            "lp_loss 0.101374187\n",
            "lp_loss 0.057769753\n",
            "lp_loss 0.132217526\n",
            "lp_loss 0.0648113936\n",
            "lp_loss 0.198341101\n",
            "lp_loss 0.176251277\n",
            "lp_loss 0.372137666\n",
            "lp_loss 0.0566459298\n",
            "lp_loss 3.09409285\n",
            "lp_loss 0.40433684\n",
            "lp_loss 1.00411439\n",
            "lp_loss 0.0575475693\n",
            "lp_loss 0.389415681\n",
            "lp_loss 0.146305859\n",
            "lp_loss 0.20703575\n",
            "lp_loss 0.839001656\n",
            "lp_loss 0.59823066\n",
            "lp_loss 0.18511036\n",
            "lp_loss 0.629894912\n",
            "lp_loss 0.204142541\n",
            "lp_loss 0.209507063\n",
            "lp_loss 0.221047401\n",
            "lp_loss 0.0587110035\n",
            "lp_loss 0.572712\n",
            "lp_loss 0.178621575\n",
            "lp_loss 1.72350478\n",
            "lp_loss 0.283669353\n",
            "lp_loss 0.144163221\n",
            "lp_loss 0.333097398\n",
            "lp_loss 0.454001755\n",
            "lp_loss 1.36261046\n",
            "lp_loss 0.357016563\n",
            "lp_loss 0.142127678\n",
            "lp_loss 3.23876643\n",
            "lp_loss 0.0229118355\n",
            "lp_loss 0.172018796\n",
            "lp_loss 0.388877094\n",
            "lp_loss 0.625194\n",
            "lp_loss 0.150027409\n",
            "lp_loss 0.135584414\n",
            "lp_loss 0.513490319\n",
            "lp_loss 1.44570518\n",
            "lp_loss 0.529000819\n",
            "lp_loss 0.619931638\n",
            "lp_loss 1.36806345\n",
            "lp_loss 0.0942342058\n",
            "lp_loss 0.150859773\n",
            "lp_loss 0.379604846\n",
            "lp_loss 0.417557776\n",
            "lp_loss 0.102450207\n",
            "lp_loss 0.659569919\n",
            "lp_loss 0.0704704449\n",
            "lp_loss 0.363273174\n",
            "lp_loss 0.36092639\n",
            "lp_loss 0.303101927\n",
            "lp_loss 0.118028507\n",
            "lp_loss 0.253898799\n",
            "lp_loss 0.0848877\n",
            "lp_loss 1.4682622\n",
            "lp_loss 0.100551091\n",
            "lp_loss 0.160422251\n",
            "lp_loss 0.172418162\n",
            "lp_loss 0.280982375\n",
            "lp_loss 0.577923417\n",
            "lp_loss 0.248108461\n",
            "lp_loss 0.364796251\n",
            "lp_loss 0.0183371976\n",
            "lp_loss 0.359216809\n",
            "lp_loss 0.491454124\n",
            "lp_loss 0.217285722\n",
            "lp_loss 0.0763106942\n",
            "lp_loss 0.593674898\n",
            "lp_loss 0.414675295\n",
            "lp_loss 0.241650909\n",
            "lp_loss 0.226917312\n",
            "lp_loss 0.532148719\n",
            "lp_loss 0.224415153\n",
            "lp_loss 0.562359\n",
            "lp_loss 0.162804157\n",
            "lp_loss 0.141599566\n",
            "lp_loss 0.287453324\n",
            "lp_loss 0.233155251\n",
            "lp_loss 0.647062361\n",
            "lp_loss 0.308211535\n",
            "lp_loss 0.330242753\n",
            "lp_loss 0.0661969259\n",
            "2020-01-30 19:34:47.853879\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.869194329\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 6230\n",
            "label_prediction_accuracy - Target: 0.24545455\n",
            "Beginning of epoch: 23\n",
            "lp_loss 0.173484296\n",
            "lp_loss 0.0384026766\n",
            "lp_loss 0.181155011\n",
            "lp_loss 0.012999706\n",
            "lp_loss 0.283661902\n",
            "lp_loss 0.232375979\n",
            "lp_loss 0.277282476\n",
            "lp_loss 1.17529213\n",
            "lp_loss 0.0429033116\n",
            "lp_loss 0.201123863\n",
            "lp_loss 0.267147064\n",
            "lp_loss 0.73733139\n",
            "lp_loss 1.24216509\n",
            "lp_loss 0.591998458\n",
            "lp_loss 0.520429254\n",
            "lp_loss 0.0406386405\n",
            "lp_loss 0.675361872\n",
            "lp_loss 0.359531283\n",
            "lp_loss 0.0493678711\n",
            "lp_loss 0.146992221\n",
            "lp_loss 0.245185703\n",
            "lp_loss 0.0355396047\n",
            "lp_loss 0.182886034\n",
            "lp_loss 0.447782904\n",
            "lp_loss 0.196792036\n",
            "lp_loss 0.799015641\n",
            "lp_loss 0.0565452762\n",
            "lp_loss 0.109958932\n",
            "lp_loss 0.226789445\n",
            "lp_loss 0.139587969\n",
            "lp_loss 0.32370609\n",
            "lp_loss 0.763744235\n",
            "lp_loss 0.0338149592\n",
            "lp_loss 0.192254573\n",
            "lp_loss 0.789429307\n",
            "lp_loss 0.140925646\n",
            "lp_loss 0.226251081\n",
            "lp_loss 1.04500699\n",
            "lp_loss 0.240489528\n",
            "lp_loss 0.454803288\n",
            "lp_loss 0.0134433554\n",
            "lp_loss 0.225442722\n",
            "lp_loss 0.0373335406\n",
            "lp_loss 0.898429573\n",
            "lp_loss 0.201589942\n",
            "lp_loss 0.0815685466\n",
            "lp_loss 0.297676653\n",
            "lp_loss 0.0614432469\n",
            "lp_loss 1.87688792\n",
            "lp_loss 0.265014976\n",
            "lp_loss 0.349596679\n",
            "lp_loss 0.199503407\n",
            "lp_loss 0.494058132\n",
            "lp_loss 0.464881182\n",
            "lp_loss 0.130549341\n",
            "lp_loss 0.97711\n",
            "lp_loss 1.40446949\n",
            "lp_loss 0.442358196\n",
            "lp_loss 1.00967205\n",
            "lp_loss 0.952565551\n",
            "lp_loss 0.0532529838\n",
            "lp_loss 0.397626966\n",
            "lp_loss 1.36993337\n",
            "lp_loss 0.117580727\n",
            "lp_loss 0.0753781646\n",
            "lp_loss 0.0407040603\n",
            "lp_loss 0.288255\n",
            "lp_loss 0.223414421\n",
            "lp_loss 0.466380417\n",
            "lp_loss 0.632055044\n",
            "lp_loss 0.461289018\n",
            "lp_loss 0.133199722\n",
            "lp_loss 0.225032091\n",
            "lp_loss 0.217190892\n",
            "lp_loss 0.285249174\n",
            "lp_loss 0.0554224625\n",
            "lp_loss 0.0435837433\n",
            "lp_loss 0.167615503\n",
            "lp_loss 0.0552229285\n",
            "lp_loss 0.0529269576\n",
            "lp_loss 0.334022462\n",
            "lp_loss 0.283149898\n",
            "lp_loss 0.209336355\n",
            "lp_loss 0.427538723\n",
            "lp_loss 0.0982403904\n",
            "lp_loss 0.249292642\n",
            "lp_loss 0.0779303\n",
            "lp_loss 0.655140162\n",
            "lp_loss 0.65220356\n",
            "lp_loss 0.127159357\n",
            "lp_loss 0.614765286\n",
            "lp_loss 0.442520916\n",
            "lp_loss 2.04504561\n",
            "lp_loss 0.185093254\n",
            "lp_loss 0.295412242\n",
            "lp_loss 0.384407252\n",
            "lp_loss 0.118986227\n",
            "lp_loss 0.842387676\n",
            "lp_loss 0.0710867941\n",
            "lp_loss 0.381422192\n",
            "lp_loss 0.0842410326\n",
            "lp_loss 0.501561701\n",
            "lp_loss 0.788191557\n",
            "lp_loss 0.354668915\n",
            "lp_loss 0.0949299783\n",
            "lp_loss 0.0840157792\n",
            "lp_loss 0.0255270787\n",
            "lp_loss 0.98660326\n",
            "lp_loss 0.728989363\n",
            "lp_loss 0.113768362\n",
            "lp_loss 0.340750158\n",
            "lp_loss 0.0901051685\n",
            "lp_loss 0.228637367\n",
            "lp_loss 0.342379242\n",
            "lp_loss 0.920052648\n",
            "lp_loss 0.0138755795\n",
            "lp_loss 0.342675745\n",
            "lp_loss 0.0538887568\n",
            "lp_loss 0.174646616\n",
            "lp_loss 0.0234994814\n",
            "lp_loss 0.0968718156\n",
            "lp_loss 0.160995662\n",
            "lp_loss 0.807944775\n",
            "lp_loss 1.3845948\n",
            "lp_loss 0.685696423\n",
            "lp_loss 0.368148744\n",
            "lp_loss 0.293771416\n",
            "lp_loss 0.630173683\n",
            "lp_loss 1.2655623\n",
            "lp_loss 0.312104404\n",
            "lp_loss 0.197798118\n",
            "lp_loss 0.272060037\n",
            "lp_loss 0.85801363\n",
            "lp_loss 0.326257497\n",
            "lp_loss 0.131596833\n",
            "lp_loss 0.0110668056\n",
            "lp_loss 0.0513801388\n",
            "lp_loss 0.45224309\n",
            "lp_loss 0.276521027\n",
            "lp_loss 0.100393496\n",
            "lp_loss 0.21117425\n",
            "lp_loss 0.572203\n",
            "lp_loss 0.179402441\n",
            "lp_loss 1.6461184\n",
            "lp_loss 0.0551062599\n",
            "lp_loss 1.34285235\n",
            "lp_loss 0.216590717\n",
            "lp_loss 0.876132\n",
            "lp_loss 0.302020729\n",
            "lp_loss 0.394868553\n",
            "lp_loss 0.366009355\n",
            "lp_loss 1.03619671\n",
            "lp_loss 0.187133387\n",
            "lp_loss 0.0688825548\n",
            "lp_loss 0.112857118\n",
            "lp_loss 0.0325714834\n",
            "lp_loss 0.420942545\n",
            "lp_loss 0.0836390629\n",
            "lp_loss 0.180465445\n",
            "lp_loss 0.100945473\n",
            "lp_loss 0.363915414\n",
            "lp_loss 0.176772669\n",
            "lp_loss 1.19399035\n",
            "lp_loss 0.0522206239\n",
            "lp_loss 0.452830851\n",
            "lp_loss 0.0956422761\n",
            "lp_loss 0.0739167184\n",
            "lp_loss 0.25222525\n",
            "lp_loss 0.0915282592\n",
            "lp_loss 0.450943321\n",
            "lp_loss 0.124082431\n",
            "lp_loss 0.407094538\n",
            "lp_loss 0.0938595682\n",
            "lp_loss 1.21772027\n",
            "lp_loss 0.113734424\n",
            "lp_loss 0.663814\n",
            "lp_loss 0.316743731\n",
            "lp_loss 0.120669343\n",
            "lp_loss 0.309609\n",
            "lp_loss 1.36913311\n",
            "lp_loss 1.24825215\n",
            "lp_loss 0.196697146\n",
            "lp_loss 0.332378656\n",
            "lp_loss 0.629918516\n",
            "lp_loss 0.880618274\n",
            "lp_loss 0.578103662\n",
            "lp_loss 0.0805137828\n",
            "lp_loss 0.0580866709\n",
            "lp_loss 0.468959332\n",
            "lp_loss 0.123571992\n",
            "lp_loss 0.590993583\n",
            "lp_loss 1.76584458\n",
            "lp_loss 0.390191853\n",
            "lp_loss 0.468355894\n",
            "lp_loss 0.0712362528\n",
            "lp_loss 0.233476788\n",
            "lp_loss 0.73933351\n",
            "lp_loss 0.173398152\n",
            "lp_loss 0.0344118\n",
            "lp_loss 0.111751691\n",
            "lp_loss 0.312746912\n",
            "lp_loss 0.114097461\n",
            "lp_loss 0.881322742\n",
            "lp_loss 0.0545796566\n",
            "lp_loss 2.00618696\n",
            "lp_loss 0.947109342\n",
            "lp_loss 1.49866796\n",
            "lp_loss 0.305374354\n",
            "lp_loss 0.0222406276\n",
            "lp_loss 0.805785298\n",
            "lp_loss 0.143872187\n",
            "2020-01-30 19:35:00.013816\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.887203813\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 6441\n",
            "label_prediction_accuracy - Target: 0.24242425\n",
            "Beginning of epoch: 24\n",
            "lp_loss 0.0105314627\n",
            "lp_loss 0.039052479\n",
            "lp_loss 0.189589426\n",
            "lp_loss 0.295511901\n",
            "lp_loss 0.0348935351\n",
            "lp_loss 0.248533159\n",
            "lp_loss 0.156117648\n",
            "lp_loss 0.381347537\n",
            "lp_loss 0.211118191\n",
            "lp_loss 0.174271658\n",
            "lp_loss 0.236236423\n",
            "lp_loss 0.465189517\n",
            "lp_loss 0.638272166\n",
            "lp_loss 0.0834403113\n",
            "lp_loss 0.256071568\n",
            "lp_loss 2.19606781\n",
            "lp_loss 0.547000051\n",
            "lp_loss 0.026438972\n",
            "lp_loss 0.0341648608\n",
            "lp_loss 0.603930831\n",
            "lp_loss 0.360645503\n",
            "lp_loss 0.311444581\n",
            "lp_loss 0.219137102\n",
            "lp_loss 0.808216751\n",
            "lp_loss 0.975770354\n",
            "lp_loss 0.473922312\n",
            "lp_loss 0.394743979\n",
            "lp_loss 0.0586484373\n",
            "lp_loss 0.113910593\n",
            "lp_loss 0.219183296\n",
            "lp_loss 0.222437412\n",
            "lp_loss 0.10943751\n",
            "lp_loss 0.390943199\n",
            "lp_loss 0.59044826\n",
            "lp_loss 0.0603068247\n",
            "lp_loss 0.218530327\n",
            "lp_loss 0.224965066\n",
            "lp_loss 0.131987959\n",
            "lp_loss 0.421267211\n",
            "lp_loss 0.0438544\n",
            "lp_loss 0.354459018\n",
            "lp_loss 0.039772246\n",
            "lp_loss 0.135792047\n",
            "lp_loss 0.395945191\n",
            "lp_loss 0.402123034\n",
            "lp_loss 0.0936486796\n",
            "lp_loss 0.606785893\n",
            "lp_loss 0.0601973608\n",
            "lp_loss 0.481672704\n",
            "lp_loss 0.733404219\n",
            "lp_loss 0.800289333\n",
            "lp_loss 0.245458245\n",
            "lp_loss 0.0970952064\n",
            "lp_loss 0.0679459497\n",
            "lp_loss 0.609471381\n",
            "lp_loss 0.388177693\n",
            "lp_loss 0.444579512\n",
            "lp_loss 0.44390291\n",
            "lp_loss 1.11436224\n",
            "lp_loss 0.0874868631\n",
            "lp_loss 0.579137683\n",
            "lp_loss 0.0551832616\n",
            "lp_loss 0.154479191\n",
            "lp_loss 0.20380035\n",
            "lp_loss 0.143237755\n",
            "lp_loss 0.488003194\n",
            "lp_loss 1.26651311\n",
            "lp_loss 1.62844503\n",
            "lp_loss 0.158155218\n",
            "lp_loss 0.222350985\n",
            "lp_loss 0.0224398579\n",
            "lp_loss 0.817995191\n",
            "lp_loss 4.04984903\n",
            "lp_loss 0.0642179325\n",
            "lp_loss 0.200564474\n",
            "lp_loss 0.483763635\n",
            "lp_loss 0.115046129\n",
            "lp_loss 0.313195139\n",
            "lp_loss 0.157960415\n",
            "lp_loss 0.258690804\n",
            "lp_loss 0.574368894\n",
            "lp_loss 0.51148653\n",
            "lp_loss 0.409662634\n",
            "lp_loss 1.32985175\n",
            "lp_loss 1.76611018\n",
            "lp_loss 0.0145844771\n",
            "lp_loss 0.902014077\n",
            "lp_loss 0.195262134\n",
            "lp_loss 0.157394126\n",
            "lp_loss 0.032116361\n",
            "lp_loss 0.272977769\n",
            "lp_loss 0.903799236\n",
            "lp_loss 1.07944179\n",
            "lp_loss 0.471506447\n",
            "lp_loss 0.291113347\n",
            "lp_loss 0.375598937\n",
            "lp_loss 0.270295322\n",
            "lp_loss 0.482121766\n",
            "lp_loss 1.58200204\n",
            "lp_loss 1.00017238\n",
            "lp_loss 0.435220152\n",
            "lp_loss 0.409597963\n",
            "lp_loss 0.313458443\n",
            "lp_loss 0.654883087\n",
            "lp_loss 0.0951126143\n",
            "lp_loss 0.368454605\n",
            "lp_loss 0.173651576\n",
            "lp_loss 0.129379854\n",
            "lp_loss 0.242944628\n",
            "lp_loss 0.761092067\n",
            "lp_loss 0.283146679\n",
            "lp_loss 0.460167885\n",
            "lp_loss 0.0143934833\n",
            "lp_loss 0.6196841\n",
            "lp_loss 0.274327576\n",
            "lp_loss 0.808207154\n",
            "lp_loss 0.0509597883\n",
            "lp_loss 0.16242151\n",
            "lp_loss 0.411063254\n",
            "lp_loss 0.0409760885\n",
            "lp_loss 0.292720616\n",
            "lp_loss 0.16451177\n",
            "lp_loss 0.253487289\n",
            "lp_loss 0.0871804729\n",
            "lp_loss 0.120140649\n",
            "lp_loss 0.451800406\n",
            "lp_loss 0.300807685\n",
            "lp_loss 0.129413575\n",
            "lp_loss 0.514873087\n",
            "lp_loss 0.353932261\n",
            "lp_loss 0.143257827\n",
            "lp_loss 0.0679608583\n",
            "lp_loss 0.052444\n",
            "lp_loss 0.861845374\n",
            "lp_loss 0.128530174\n",
            "lp_loss 0.130792513\n",
            "lp_loss 0.243433431\n",
            "lp_loss 1.59858632\n",
            "lp_loss 0.241877794\n",
            "lp_loss 0.199685737\n",
            "lp_loss 0.6538499\n",
            "lp_loss 0.0273681916\n",
            "lp_loss 0.081354484\n",
            "lp_loss 0.116036654\n",
            "lp_loss 0.0524463132\n",
            "lp_loss 0.422333419\n",
            "lp_loss 0.0902202874\n",
            "lp_loss 0.878026783\n",
            "lp_loss 0.145716876\n",
            "lp_loss 0.311185479\n",
            "lp_loss 0.0450082943\n",
            "lp_loss 0.387033373\n",
            "lp_loss 0.0395242386\n",
            "lp_loss 0.174555466\n",
            "lp_loss 0.195018351\n",
            "lp_loss 0.654031634\n",
            "lp_loss 0.517942429\n",
            "lp_loss 0.0890821368\n",
            "lp_loss 0.0316104367\n",
            "lp_loss 0.0213596504\n",
            "lp_loss 0.297118217\n",
            "lp_loss 0.31984362\n",
            "lp_loss 0.309393376\n",
            "lp_loss 0.0926826671\n",
            "lp_loss 0.0123375\n",
            "lp_loss 0.151485071\n",
            "lp_loss 0.855598569\n",
            "lp_loss 0.101196885\n",
            "lp_loss 0.591760159\n",
            "lp_loss 0.337913901\n",
            "lp_loss 0.16900067\n",
            "lp_loss 0.717081904\n",
            "lp_loss 0.0206365\n",
            "lp_loss 0.438267231\n",
            "lp_loss 1.44272292\n",
            "lp_loss 0.200026229\n",
            "lp_loss 0.262096941\n",
            "lp_loss 0.0843972415\n",
            "lp_loss 0.0258842409\n",
            "lp_loss 0.419650376\n",
            "lp_loss 0.370197326\n",
            "lp_loss 0.24329181\n",
            "lp_loss 0.486529201\n",
            "lp_loss 0.700653493\n",
            "lp_loss 0.193823233\n",
            "lp_loss 0.0245254673\n",
            "lp_loss 0.0407610759\n",
            "lp_loss 0.405154854\n",
            "lp_loss 0.474920273\n",
            "lp_loss 0.246666551\n",
            "lp_loss 0.0996518657\n",
            "lp_loss 0.735716522\n",
            "lp_loss 1.62673783\n",
            "lp_loss 0.657844186\n",
            "lp_loss 1.15149331\n",
            "lp_loss 0.0632550791\n",
            "lp_loss 0.404065073\n",
            "lp_loss 0.645131946\n",
            "lp_loss 0.762463689\n",
            "lp_loss 0.0670515\n",
            "lp_loss 0.0434207544\n",
            "lp_loss 0.621303618\n",
            "lp_loss 0.29298225\n",
            "lp_loss 0.0252844393\n",
            "lp_loss 0.449526489\n",
            "lp_loss 0.0159722809\n",
            "lp_loss 0.744664192\n",
            "lp_loss 0.755376041\n",
            "lp_loss 0.383220524\n",
            "lp_loss 0.242700458\n",
            "lp_loss 0.468879133\n",
            "2020-01-30 19:35:12.209241\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.877725124\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 6652\n",
            "label_prediction_accuracy - Target: 0.25757575\n",
            "Beginning of epoch: 25\n",
            "lp_loss 0.189115673\n",
            "lp_loss 0.0882262588\n",
            "lp_loss 0.409186512\n",
            "lp_loss 0.124447368\n",
            "lp_loss 0.168744162\n",
            "lp_loss 0.761002541\n",
            "lp_loss 0.132176533\n",
            "lp_loss 0.152730972\n",
            "lp_loss 0.891796708\n",
            "lp_loss 0.0273357388\n",
            "lp_loss 0.214322284\n",
            "lp_loss 0.698831439\n",
            "lp_loss 0.447173893\n",
            "lp_loss 0.0611189418\n",
            "lp_loss 0.549435079\n",
            "lp_loss 0.405410618\n",
            "lp_loss 0.0235485621\n",
            "lp_loss 0.0216986444\n",
            "lp_loss 0.0532721505\n",
            "lp_loss 0.451107651\n",
            "lp_loss 0.0370840169\n",
            "lp_loss 0.0497933701\n",
            "lp_loss 0.217197269\n",
            "lp_loss 0.209511712\n",
            "lp_loss 0.251469433\n",
            "lp_loss 0.137747929\n",
            "lp_loss 0.0872212425\n",
            "lp_loss 0.659235358\n",
            "lp_loss 0.312307924\n",
            "lp_loss 0.786312103\n",
            "lp_loss 1.03894329\n",
            "lp_loss 0.131132573\n",
            "lp_loss 0.180435\n",
            "lp_loss 0.198445827\n",
            "lp_loss 0.476099551\n",
            "lp_loss 0.202595875\n",
            "lp_loss 0.483192027\n",
            "lp_loss 1.89211655\n",
            "lp_loss 3.84106874\n",
            "lp_loss 0.412898362\n",
            "lp_loss 0.429626137\n",
            "lp_loss 0.105316222\n",
            "lp_loss 0.833274841\n",
            "lp_loss 0.119482599\n",
            "lp_loss 2.89178896\n",
            "lp_loss 0.32674247\n",
            "lp_loss 0.0719650239\n",
            "lp_loss 0.190251037\n",
            "lp_loss 0.399056494\n",
            "lp_loss 0.394074321\n",
            "lp_loss 1.18025112\n",
            "lp_loss 0.0448708199\n",
            "lp_loss 0.622059703\n",
            "lp_loss 0.119493857\n",
            "lp_loss 0.697808087\n",
            "lp_loss 0.714868903\n",
            "lp_loss 0.184166953\n",
            "lp_loss 1.09373546\n",
            "lp_loss 0.380532086\n",
            "lp_loss 0.215300441\n",
            "lp_loss 0.423480809\n",
            "lp_loss 0.184365138\n",
            "lp_loss 0.706837416\n",
            "lp_loss 0.281388879\n",
            "lp_loss 0.527719796\n",
            "lp_loss 0.120445631\n",
            "lp_loss 0.338804483\n",
            "lp_loss 0.025144\n",
            "lp_loss 0.0594811738\n",
            "lp_loss 0.467852294\n",
            "lp_loss 0.226653889\n",
            "lp_loss 0.0351605266\n",
            "lp_loss 0.190286517\n",
            "lp_loss 0.0841949582\n",
            "lp_loss 0.227975443\n",
            "lp_loss 0.353282422\n",
            "lp_loss 0.124559306\n",
            "lp_loss 0.216383293\n",
            "lp_loss 0.249748781\n",
            "lp_loss 0.289550632\n",
            "lp_loss 0.049895823\n",
            "lp_loss 1.01573324\n",
            "lp_loss 0.0408002138\n",
            "lp_loss 0.0958468\n",
            "lp_loss 0.0306087695\n",
            "lp_loss 0.166030109\n",
            "lp_loss 1.01615739\n",
            "lp_loss 0.147759169\n",
            "lp_loss 0.174877316\n",
            "lp_loss 0.668725073\n",
            "lp_loss 1.23248351\n",
            "lp_loss 0.0509881191\n",
            "lp_loss 0.536704957\n",
            "lp_loss 0.599247754\n",
            "lp_loss 0.802579403\n",
            "lp_loss 0.250865132\n",
            "lp_loss 0.43129459\n",
            "lp_loss 0.37383306\n",
            "lp_loss 0.418519884\n",
            "lp_loss 0.483355194\n",
            "lp_loss 0.0542706549\n",
            "lp_loss 0.296275437\n",
            "lp_loss 0.0886087567\n",
            "lp_loss 0.633425176\n",
            "lp_loss 0.0987573564\n",
            "lp_loss 0.307855189\n",
            "lp_loss 0.309205711\n",
            "lp_loss 1.54173052\n",
            "lp_loss 0.430752367\n",
            "lp_loss 0.916313469\n",
            "lp_loss 0.00682663405\n",
            "lp_loss 0.187160239\n",
            "lp_loss 0.293598801\n",
            "lp_loss 0.216897532\n",
            "lp_loss 0.776204169\n",
            "lp_loss 0.490493238\n",
            "lp_loss 0.527852535\n",
            "lp_loss 0.274892598\n",
            "lp_loss 0.0240127109\n",
            "lp_loss 0.0895126835\n",
            "lp_loss 0.441253573\n",
            "lp_loss 0.500187516\n",
            "lp_loss 0.316080719\n",
            "lp_loss 0.170986444\n",
            "lp_loss 0.0455294773\n",
            "lp_loss 0.0491446331\n",
            "lp_loss 0.10739474\n",
            "lp_loss 0.559571922\n",
            "lp_loss 0.0645813942\n",
            "lp_loss 0.186354637\n",
            "lp_loss 0.36777252\n",
            "lp_loss 0.38800779\n",
            "lp_loss 0.042309247\n",
            "lp_loss 0.11707221\n",
            "lp_loss 0.028058216\n",
            "lp_loss 0.106858969\n",
            "lp_loss 0.694295049\n",
            "lp_loss 0.270315\n",
            "lp_loss 0.401814073\n",
            "lp_loss 0.0455026403\n",
            "lp_loss 0.724898696\n",
            "lp_loss 0.58183527\n",
            "lp_loss 0.557820916\n",
            "lp_loss 0.115825176\n",
            "lp_loss 0.373902738\n",
            "lp_loss 1.41322827\n",
            "lp_loss 0.151077151\n",
            "lp_loss 0.261777699\n",
            "lp_loss 0.0374652222\n",
            "lp_loss 0.0960447639\n",
            "lp_loss 0.0931669176\n",
            "lp_loss 0.0751807541\n",
            "lp_loss 0.201215386\n",
            "lp_loss 0.0142475273\n",
            "lp_loss 0.48481527\n",
            "lp_loss 0.0353250541\n",
            "lp_loss 0.297811985\n",
            "lp_loss 0.3891626\n",
            "lp_loss 0.6853773\n",
            "lp_loss 0.112815656\n",
            "lp_loss 0.0661636218\n",
            "lp_loss 0.356483042\n",
            "lp_loss 0.23588948\n",
            "lp_loss 0.229079649\n",
            "lp_loss 1.14958012\n",
            "lp_loss 1.00684333\n",
            "lp_loss 0.0635570809\n",
            "lp_loss 0.206858397\n",
            "lp_loss 0.108063065\n",
            "lp_loss 0.317041099\n",
            "lp_loss 0.914280772\n",
            "lp_loss 0.400238931\n",
            "lp_loss 0.843084\n",
            "lp_loss 0.562543273\n",
            "lp_loss 0.340719283\n",
            "lp_loss 1.04215729\n",
            "lp_loss 0.606491089\n",
            "lp_loss 1.38884032\n",
            "lp_loss 0.115338169\n",
            "lp_loss 0.0532321557\n",
            "lp_loss 0.269880056\n",
            "lp_loss 0.481287062\n",
            "lp_loss 0.442618221\n",
            "lp_loss 0.0317195132\n",
            "lp_loss 1.04674792\n",
            "lp_loss 0.337640196\n",
            "lp_loss 0.586265862\n",
            "lp_loss 0.165304691\n",
            "lp_loss 0.42756933\n",
            "lp_loss 0.539022446\n",
            "lp_loss 0.0762845352\n",
            "lp_loss 0.0288413409\n",
            "lp_loss 0.197939485\n",
            "lp_loss 0.0779185519\n",
            "lp_loss 0.372441381\n",
            "lp_loss 0.104982123\n",
            "lp_loss 0.0168145448\n",
            "lp_loss 0.167118505\n",
            "lp_loss 0.613823831\n",
            "lp_loss 0.03225125\n",
            "lp_loss 0.14518705\n",
            "lp_loss 0.201612189\n",
            "lp_loss 0.106387831\n",
            "lp_loss 0.172498897\n",
            "lp_loss 0.430496603\n",
            "lp_loss 0.443551838\n",
            "lp_loss 0.55897969\n",
            "lp_loss 0.401048\n",
            "lp_loss 0.317500114\n",
            "lp_loss 0.0171318632\n",
            "lp_loss 0.458054453\n",
            "2020-01-30 19:35:24.341356\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.887203813\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 6863\n",
            "label_prediction_accuracy - Target: 0.25454545\n",
            "Beginning of epoch: 26\n",
            "lp_loss 0.257834\n",
            "lp_loss 0.289343208\n",
            "lp_loss 0.5333727\n",
            "lp_loss 0.134975106\n",
            "lp_loss 0.308895409\n",
            "lp_loss 0.169702321\n",
            "lp_loss 0.116890609\n",
            "lp_loss 0.0907908753\n",
            "lp_loss 0.128879458\n",
            "lp_loss 0.829470932\n",
            "lp_loss 0.170178935\n",
            "lp_loss 0.0914054811\n",
            "lp_loss 0.0853849798\n",
            "lp_loss 0.282713383\n",
            "lp_loss 0.432704777\n",
            "lp_loss 0.0328825861\n",
            "lp_loss 0.238804579\n",
            "lp_loss 0.202154785\n",
            "lp_loss 0.393106192\n",
            "lp_loss 0.0554380901\n",
            "lp_loss 0.215610355\n",
            "lp_loss 0.104446754\n",
            "lp_loss 0.471384287\n",
            "lp_loss 0.00819937233\n",
            "lp_loss 0.466428906\n",
            "lp_loss 0.296267956\n",
            "lp_loss 1.68101251\n",
            "lp_loss 0.17362693\n",
            "lp_loss 0.0307742357\n",
            "lp_loss 0.0634053797\n",
            "lp_loss 0.297375888\n",
            "lp_loss 0.207945868\n",
            "lp_loss 0.0322361775\n",
            "lp_loss 0.0878560841\n",
            "lp_loss 0.262587488\n",
            "lp_loss 0.349031061\n",
            "lp_loss 0.149016038\n",
            "lp_loss 0.252457112\n",
            "lp_loss 0.431992471\n",
            "lp_loss 0.0803405866\n",
            "lp_loss 0.974568665\n",
            "lp_loss 0.585054636\n",
            "lp_loss 0.169227391\n",
            "lp_loss 0.163204044\n",
            "lp_loss 0.241393179\n",
            "lp_loss 0.309118301\n",
            "lp_loss 1.58577883\n",
            "lp_loss 1.13670731\n",
            "lp_loss 0.157819062\n",
            "lp_loss 0.613985658\n",
            "lp_loss 0.225871369\n",
            "lp_loss 0.567850947\n",
            "lp_loss 0.199347317\n",
            "lp_loss 0.985355496\n",
            "lp_loss 0.27299276\n",
            "lp_loss 0.140940502\n",
            "lp_loss 0.610412121\n",
            "lp_loss 0.124261975\n",
            "lp_loss 0.119623795\n",
            "lp_loss 1.16645503\n",
            "lp_loss 0.425761759\n",
            "lp_loss 0.703716755\n",
            "lp_loss 1.04768336\n",
            "lp_loss 0.0525148921\n",
            "lp_loss 0.382448614\n",
            "lp_loss 0.388800502\n",
            "lp_loss 0.0291205589\n",
            "lp_loss 0.105813861\n",
            "lp_loss 0.122422621\n",
            "lp_loss 0.0739138275\n",
            "lp_loss 0.0302069932\n",
            "lp_loss 0.170073435\n",
            "lp_loss 0.428218275\n",
            "lp_loss 0.246726066\n",
            "lp_loss 0.0428098589\n",
            "lp_loss 0.804434657\n",
            "lp_loss 0.070165053\n",
            "lp_loss 0.0593732\n",
            "lp_loss 0.318972021\n",
            "lp_loss 0.103655994\n",
            "lp_loss 0.0529197082\n",
            "lp_loss 0.638718486\n",
            "lp_loss 0.146464348\n",
            "lp_loss 0.0100671174\n",
            "lp_loss 0.17123726\n",
            "lp_loss 0.706407964\n",
            "lp_loss 0.0300382189\n",
            "lp_loss 0.704141736\n",
            "lp_loss 0.0774495602\n",
            "lp_loss 1.48610723\n",
            "lp_loss 0.696729779\n",
            "lp_loss 0.392643154\n",
            "lp_loss 0.154536083\n",
            "lp_loss 0.346094042\n",
            "lp_loss 0.0306222346\n",
            "lp_loss 0.117912695\n",
            "lp_loss 0.293386042\n",
            "lp_loss 0.262164533\n",
            "lp_loss 0.0897654146\n",
            "lp_loss 0.181796432\n",
            "lp_loss 0.21769011\n",
            "lp_loss 0.119847514\n",
            "lp_loss 0.0536104962\n",
            "lp_loss 0.997700512\n",
            "lp_loss 0.66732347\n",
            "lp_loss 0.208732843\n",
            "lp_loss 0.0658480525\n",
            "lp_loss 0.365115\n",
            "lp_loss 0.551486611\n",
            "lp_loss 0.0257926341\n",
            "lp_loss 0.171147257\n",
            "lp_loss 0.291928887\n",
            "lp_loss 0.290024549\n",
            "lp_loss 0.360271752\n",
            "lp_loss 0.632602692\n",
            "lp_loss 0.067237325\n",
            "lp_loss 0.0979712531\n",
            "lp_loss 0.640483379\n",
            "lp_loss 0.11763034\n",
            "lp_loss 0.053697098\n",
            "lp_loss 0.0103844823\n",
            "lp_loss 0.667160869\n",
            "lp_loss 0.0977591202\n",
            "lp_loss 0.455852181\n",
            "lp_loss 0.32643503\n",
            "lp_loss 0.44853735\n",
            "lp_loss 0.216235802\n",
            "lp_loss 0.208192796\n",
            "lp_loss 0.794198155\n",
            "lp_loss 0.0167399738\n",
            "lp_loss 0.334964305\n",
            "lp_loss 0.363242805\n",
            "lp_loss 1.01024437\n",
            "lp_loss 0.0963116512\n",
            "lp_loss 0.124541663\n",
            "lp_loss 0.0157294609\n",
            "lp_loss 0.0166178141\n",
            "lp_loss 0.117820725\n",
            "lp_loss 0.231518939\n",
            "lp_loss 0.209449381\n",
            "lp_loss 0.0284609348\n",
            "lp_loss 0.105450869\n",
            "lp_loss 0.327726185\n",
            "lp_loss 0.307237089\n",
            "lp_loss 0.196731165\n",
            "lp_loss 0.429214776\n",
            "lp_loss 0.699249744\n",
            "lp_loss 0.520409286\n",
            "lp_loss 0.151118785\n",
            "lp_loss 0.297586143\n",
            "lp_loss 0.376726985\n",
            "lp_loss 0.0347158462\n",
            "lp_loss 0.194776759\n",
            "lp_loss 0.263325542\n",
            "lp_loss 0.0917668343\n",
            "lp_loss 0.51842773\n",
            "lp_loss 0.13609007\n",
            "lp_loss 0.607365072\n",
            "lp_loss 1.50273\n",
            "lp_loss 0.740897119\n",
            "lp_loss 0.221015811\n",
            "lp_loss 0.506516755\n",
            "lp_loss 0.136942893\n",
            "lp_loss 0.608705401\n",
            "lp_loss 0.100218549\n",
            "lp_loss 0.690261781\n",
            "lp_loss 0.616667509\n",
            "lp_loss 0.193268746\n",
            "lp_loss 0.443575\n",
            "lp_loss 0.0818380937\n",
            "lp_loss 0.242783308\n",
            "lp_loss 0.490344197\n",
            "lp_loss 0.155547887\n",
            "lp_loss 0.884345829\n",
            "lp_loss 0.826832414\n",
            "lp_loss 0.254094094\n",
            "lp_loss 0.125322953\n",
            "lp_loss 0.780112863\n",
            "lp_loss 0.148260817\n",
            "lp_loss 0.0521028638\n",
            "lp_loss 0.151985884\n",
            "lp_loss 0.511461258\n",
            "lp_loss 0.148602769\n",
            "lp_loss 0.171087071\n",
            "lp_loss 0.177504495\n",
            "lp_loss 0.624627829\n",
            "lp_loss 1.37034273\n",
            "lp_loss 0.12109977\n",
            "lp_loss 0.237166077\n",
            "lp_loss 0.232320398\n",
            "lp_loss 0.140272021\n",
            "lp_loss 0.437341869\n",
            "lp_loss 0.493391663\n",
            "lp_loss 2.6982007\n",
            "lp_loss 0.607769608\n",
            "lp_loss 0.458003134\n",
            "lp_loss 0.313108057\n",
            "lp_loss 0.696669698\n",
            "lp_loss 0.0484805852\n",
            "lp_loss 0.23743625\n",
            "lp_loss 0.0959907323\n",
            "lp_loss 0.178256631\n",
            "lp_loss 0.319870055\n",
            "lp_loss 0.357638478\n",
            "lp_loss 1.04421103\n",
            "lp_loss 0.0999763086\n",
            "lp_loss 0.122906789\n",
            "lp_loss 0.198526382\n",
            "lp_loss 0.329830319\n",
            "lp_loss 1.15902746\n",
            "lp_loss 0.205665037\n",
            "lp_loss 0.0515057333\n",
            "2020-01-30 19:35:36.836403\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.900943398\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 7075\n",
            "label_prediction_accuracy - Target: 0.2\n",
            "Beginning of epoch: 27\n",
            "lp_loss 0.480493695\n",
            "lp_loss 0.308593392\n",
            "lp_loss 0.865115047\n",
            "lp_loss 0.582051396\n",
            "lp_loss 0.109931782\n",
            "lp_loss 0.753179729\n",
            "lp_loss 0.0225047488\n",
            "lp_loss 0.159944296\n",
            "lp_loss 0.0340668485\n",
            "lp_loss 1.86141264\n",
            "lp_loss 0.251514971\n",
            "lp_loss 0.157368854\n",
            "lp_loss 0.0451512635\n",
            "lp_loss 0.0271211527\n",
            "lp_loss 0.359818518\n",
            "lp_loss 0.0909017101\n",
            "lp_loss 0.714418292\n",
            "lp_loss 0.29847151\n",
            "lp_loss 1.01145244\n",
            "lp_loss 0.0825404\n",
            "lp_loss 0.83429\n",
            "lp_loss 1.15007508\n",
            "lp_loss 0.105294369\n",
            "lp_loss 0.118223488\n",
            "lp_loss 0.865970492\n",
            "lp_loss 0.356381625\n",
            "lp_loss 0.146686703\n",
            "lp_loss 0.446290106\n",
            "lp_loss 0.940094113\n",
            "lp_loss 0.0680648834\n",
            "lp_loss 0.6811167\n",
            "lp_loss 0.548919141\n",
            "lp_loss 0.586511195\n",
            "lp_loss 0.244775563\n",
            "lp_loss 1.40191746\n",
            "lp_loss 0.389562935\n",
            "lp_loss 0.0882422477\n",
            "lp_loss 0.550503135\n",
            "lp_loss 0.145043582\n",
            "lp_loss 0.0742941648\n",
            "lp_loss 0.0431833081\n",
            "lp_loss 0.104858242\n",
            "lp_loss 0.897294223\n",
            "lp_loss 0.0606362447\n",
            "lp_loss 0.074041836\n",
            "lp_loss 0.186312079\n",
            "lp_loss 0.242431432\n",
            "lp_loss 0.198753268\n",
            "lp_loss 1.08160615\n",
            "lp_loss 0.183992952\n",
            "lp_loss 0.112531699\n",
            "lp_loss 0.884051681\n",
            "lp_loss 0.135409251\n",
            "lp_loss 0.424343288\n",
            "lp_loss 0.0377084836\n",
            "lp_loss 0.104750536\n",
            "lp_loss 0.0330338441\n",
            "lp_loss 0.120355405\n",
            "lp_loss 0.261074752\n",
            "lp_loss 0.377148867\n",
            "lp_loss 0.153078645\n",
            "lp_loss 0.75278312\n",
            "lp_loss 0.175822109\n",
            "lp_loss 0.137980834\n",
            "lp_loss 0.449622571\n",
            "lp_loss 0.0725803897\n",
            "lp_loss 0.11260017\n",
            "lp_loss 0.126349851\n",
            "lp_loss 0.400132596\n",
            "lp_loss 0.140908569\n",
            "lp_loss 0.281296462\n",
            "lp_loss 0.114220478\n",
            "lp_loss 0.684378862\n",
            "lp_loss 0.795514107\n",
            "lp_loss 1.24473095\n",
            "lp_loss 0.404677868\n",
            "lp_loss 0.636692\n",
            "lp_loss 0.110727236\n",
            "lp_loss 0.663506866\n",
            "lp_loss 0.334666938\n",
            "lp_loss 0.275434792\n",
            "lp_loss 0.576564193\n",
            "lp_loss 1.06236756\n",
            "lp_loss 0.0403676406\n",
            "lp_loss 0.422631413\n",
            "lp_loss 0.0454563722\n",
            "lp_loss 0.480959833\n",
            "lp_loss 1.17206573\n",
            "lp_loss 0.373804629\n",
            "lp_loss 0.188011467\n",
            "lp_loss 0.42244941\n",
            "lp_loss 0.0483980402\n",
            "lp_loss 0.032203868\n",
            "lp_loss 0.122684523\n",
            "lp_loss 0.368638217\n",
            "lp_loss 0.558247328\n",
            "lp_loss 0.0726364255\n",
            "lp_loss 0.00417954614\n",
            "lp_loss 0.0685274\n",
            "lp_loss 0.0788799077\n",
            "lp_loss 0.316600502\n",
            "lp_loss 0.0229171067\n",
            "lp_loss 0.028061891\n",
            "lp_loss 0.33952558\n",
            "lp_loss 0.492519051\n",
            "lp_loss 0.363839835\n",
            "lp_loss 0.567851126\n",
            "lp_loss 0.436445\n",
            "lp_loss 0.925191224\n",
            "lp_loss 0.228345469\n",
            "lp_loss 0.210896879\n",
            "lp_loss 0.627759814\n",
            "lp_loss 0.093956992\n",
            "lp_loss 0.0967018381\n",
            "lp_loss 0.517387688\n",
            "lp_loss 0.0619679615\n",
            "lp_loss 0.424585968\n",
            "lp_loss 0.222014636\n",
            "lp_loss 0.0531423576\n",
            "lp_loss 0.87240684\n",
            "lp_loss 0.465794235\n",
            "lp_loss 0.0330078565\n",
            "lp_loss 0.119916916\n",
            "lp_loss 0.837311149\n",
            "lp_loss 0.082751669\n",
            "lp_loss 0.802017212\n",
            "lp_loss 0.136289746\n",
            "lp_loss 0.16127798\n",
            "lp_loss 0.21597746\n",
            "lp_loss 0.46682173\n",
            "lp_loss 0.660695195\n",
            "lp_loss 0.0524536967\n",
            "lp_loss 0.0874370039\n",
            "lp_loss 0.0676496252\n",
            "lp_loss 0.687905431\n",
            "lp_loss 0.14365077\n",
            "lp_loss 0.416802496\n",
            "lp_loss 0.454130739\n",
            "lp_loss 0.717405677\n",
            "lp_loss 0.670406222\n",
            "lp_loss 0.401911825\n",
            "lp_loss 0.0881678909\n",
            "lp_loss 0.359437823\n",
            "lp_loss 0.297382534\n",
            "lp_loss 0.528014\n",
            "lp_loss 0.00608403748\n",
            "lp_loss 0.0567746647\n",
            "lp_loss 1.4823873\n",
            "lp_loss 0.0667396\n",
            "lp_loss 0.031545613\n",
            "lp_loss 0.590364873\n",
            "lp_loss 0.0858402848\n",
            "lp_loss 0.358675212\n",
            "lp_loss 0.154877931\n",
            "lp_loss 0.884888\n",
            "lp_loss 0.313006043\n",
            "lp_loss 0.107040212\n",
            "lp_loss 0.280665964\n",
            "lp_loss 0.878404737\n",
            "lp_loss 0.111405432\n",
            "lp_loss 0.764508\n",
            "lp_loss 1.11368632\n",
            "lp_loss 0.22780104\n",
            "lp_loss 0.554631054\n",
            "lp_loss 0.158994198\n",
            "lp_loss 0.121643923\n",
            "lp_loss 1.28202271\n",
            "lp_loss 0.496970981\n",
            "lp_loss 0.0714128241\n",
            "lp_loss 0.0326318331\n",
            "lp_loss 0.120432064\n",
            "lp_loss 0.932836831\n",
            "lp_loss 0.022229176\n",
            "lp_loss 0.543296933\n",
            "lp_loss 0.285518676\n",
            "lp_loss 0.136598796\n",
            "lp_loss 0.38523069\n",
            "lp_loss 0.0670360774\n",
            "lp_loss 0.668476701\n",
            "lp_loss 0.384361625\n",
            "lp_loss 0.288800508\n",
            "lp_loss 0.375386059\n",
            "lp_loss 0.512211204\n",
            "lp_loss 0.661932945\n",
            "lp_loss 0.124988481\n",
            "lp_loss 0.30872944\n",
            "lp_loss 0.256766766\n",
            "lp_loss 0.860669255\n",
            "lp_loss 0.459608465\n",
            "lp_loss 0.0553528368\n",
            "lp_loss 1.93158185\n",
            "lp_loss 0.682320237\n",
            "lp_loss 0.32852596\n",
            "lp_loss 0.237505481\n",
            "lp_loss 0.325688809\n",
            "lp_loss 0.219976902\n",
            "lp_loss 0.0575691573\n",
            "lp_loss 0.246751517\n",
            "lp_loss 0.103591062\n",
            "lp_loss 0.0198926125\n",
            "lp_loss 0.321536511\n",
            "lp_loss 0.0810485706\n",
            "lp_loss 0.147104949\n",
            "lp_loss 0.411116838\n",
            "lp_loss 0.978362679\n",
            "lp_loss 0.207174018\n",
            "lp_loss 0.11627461\n",
            "lp_loss 0.970021248\n",
            "lp_loss 0.0479297861\n",
            "lp_loss 0.14672637\n",
            "lp_loss 0.184224159\n",
            "2020-01-30 19:35:49.413376\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.890047371\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 7286\n",
            "label_prediction_accuracy - Target: 0.239393935\n",
            "Beginning of epoch: 28\n",
            "lp_loss 0.123540901\n",
            "lp_loss 0.752285659\n",
            "lp_loss 0.374488\n",
            "lp_loss 0.493823051\n",
            "lp_loss 0.075496681\n",
            "lp_loss 0.271329761\n",
            "lp_loss 0.183521435\n",
            "lp_loss 0.232762933\n",
            "lp_loss 0.230963469\n",
            "lp_loss 0.436629355\n",
            "lp_loss 0.0425329097\n",
            "lp_loss 0.252905369\n",
            "lp_loss 0.243787572\n",
            "lp_loss 0.076107122\n",
            "lp_loss 0.0813076571\n",
            "lp_loss 0.032526549\n",
            "lp_loss 0.846537232\n",
            "lp_loss 1.38379693\n",
            "lp_loss 0.102325797\n",
            "lp_loss 0.852730393\n",
            "lp_loss 0.150713786\n",
            "lp_loss 0.196691245\n",
            "lp_loss 0.114036165\n",
            "lp_loss 0.125840038\n",
            "lp_loss 0.217582822\n",
            "lp_loss 0.101066969\n",
            "lp_loss 0.0783561\n",
            "lp_loss 0.313059\n",
            "lp_loss 0.367515475\n",
            "lp_loss 0.0893699303\n",
            "lp_loss 0.00469903322\n",
            "lp_loss 1.01400352\n",
            "lp_loss 0.195337057\n",
            "lp_loss 0.582106233\n",
            "lp_loss 0.18304944\n",
            "lp_loss 0.198673353\n",
            "lp_loss 0.737599432\n",
            "lp_loss 0.0469005778\n",
            "lp_loss 0.386026651\n",
            "lp_loss 0.391712368\n",
            "lp_loss 0.0779412091\n",
            "lp_loss 0.614913106\n",
            "lp_loss 0.430291176\n",
            "lp_loss 0.313425362\n",
            "lp_loss 0.294210315\n",
            "lp_loss 0.179856703\n",
            "lp_loss 1.09703577\n",
            "lp_loss 0.0680432841\n",
            "lp_loss 0.0765234381\n",
            "lp_loss 1.3427875\n",
            "lp_loss 0.0782988295\n",
            "lp_loss 0.0418109559\n",
            "lp_loss 0.135706052\n",
            "lp_loss 0.0407675579\n",
            "lp_loss 0.190659538\n",
            "lp_loss 0.0481708944\n",
            "lp_loss 0.114413165\n",
            "lp_loss 0.510893881\n",
            "lp_loss 0.0690648407\n",
            "lp_loss 0.621935725\n",
            "lp_loss 0.01952805\n",
            "lp_loss 0.0843140855\n",
            "lp_loss 0.36248\n",
            "lp_loss 0.019174695\n",
            "lp_loss 0.148700818\n",
            "lp_loss 0.0427787676\n",
            "lp_loss 0.412710339\n",
            "lp_loss 0.181657538\n",
            "lp_loss 0.164631397\n",
            "lp_loss 0.313196599\n",
            "lp_loss 0.0420876034\n",
            "lp_loss 0.0291594677\n",
            "lp_loss 0.0698671937\n",
            "lp_loss 1.04075766\n",
            "lp_loss 0.636195421\n",
            "lp_loss 0.608774066\n",
            "lp_loss 0.0712976232\n",
            "lp_loss 0.0100130085\n",
            "lp_loss 0.355447352\n",
            "lp_loss 0.990600884\n",
            "lp_loss 0.274164945\n",
            "lp_loss 0.861614227\n",
            "lp_loss 0.12412741\n",
            "lp_loss 0.884012222\n",
            "lp_loss 0.0426504835\n",
            "lp_loss 0.197647125\n",
            "lp_loss 0.0142585952\n",
            "lp_loss 0.0872162953\n",
            "lp_loss 0.803848565\n",
            "lp_loss 0.564911246\n",
            "lp_loss 0.085532032\n",
            "lp_loss 0.408591926\n",
            "lp_loss 0.0168066882\n",
            "lp_loss 0.326437563\n",
            "lp_loss 0.271258801\n",
            "lp_loss 0.141652316\n",
            "lp_loss 0.15519473\n",
            "lp_loss 0.222322747\n",
            "lp_loss 0.0600402\n",
            "lp_loss 0.0311460309\n",
            "lp_loss 0.210365444\n",
            "lp_loss 0.101319931\n",
            "lp_loss 0.32592535\n",
            "lp_loss 0.0580825321\n",
            "lp_loss 0.692041099\n",
            "lp_loss 1.07823634\n",
            "lp_loss 0.699093\n",
            "lp_loss 0.111519083\n",
            "lp_loss 0.114228584\n",
            "lp_loss 0.0359991379\n",
            "lp_loss 0.969238102\n",
            "lp_loss 0.151791066\n",
            "lp_loss 0.285832793\n",
            "lp_loss 0.129030526\n",
            "lp_loss 0.210259348\n",
            "lp_loss 0.00958788581\n",
            "lp_loss 0.0478969328\n",
            "lp_loss 0.258865386\n",
            "lp_loss 0.603863418\n",
            "lp_loss 1.02462602\n",
            "lp_loss 0.0904315561\n",
            "lp_loss 0.13278082\n",
            "lp_loss 0.0280624963\n",
            "lp_loss 0.40987888\n",
            "lp_loss 0.999377072\n",
            "lp_loss 0.641207516\n",
            "lp_loss 0.00592963211\n",
            "lp_loss 0.118998252\n",
            "lp_loss 0.151833311\n",
            "lp_loss 0.103358604\n",
            "lp_loss 1.11282325\n",
            "lp_loss 0.0841139108\n",
            "lp_loss 1.58745778\n",
            "lp_loss 0.185125515\n",
            "lp_loss 0.136294276\n",
            "lp_loss 0.0530701354\n",
            "lp_loss 0.056548439\n",
            "lp_loss 0.0377196074\n",
            "lp_loss 0.0156292766\n",
            "lp_loss 0.1171216\n",
            "lp_loss 0.264997512\n",
            "lp_loss 0.560591102\n",
            "lp_loss 0.112095796\n",
            "lp_loss 0.965465844\n",
            "lp_loss 0.274993718\n",
            "lp_loss 0.160661176\n",
            "lp_loss 0.0194678511\n",
            "lp_loss 0.0466148928\n",
            "lp_loss 0.258690029\n",
            "lp_loss 0.0439223871\n",
            "lp_loss 0.566787124\n",
            "lp_loss 0.0846821815\n",
            "lp_loss 0.164792255\n",
            "lp_loss 0.589540839\n",
            "lp_loss 0.0543733649\n",
            "lp_loss 0.224898025\n",
            "lp_loss 0.040425282\n",
            "lp_loss 0.0906227529\n",
            "lp_loss 0.213609055\n",
            "lp_loss 0.0932579264\n",
            "lp_loss 0.166840956\n",
            "lp_loss 0.355285555\n",
            "lp_loss 0.356146753\n",
            "lp_loss 0.433771431\n",
            "lp_loss 1.1549964\n",
            "lp_loss 0.105260715\n",
            "lp_loss 0.543008864\n",
            "lp_loss 0.0908579\n",
            "lp_loss 0.0918785408\n",
            "lp_loss 0.530550122\n",
            "lp_loss 0.440159\n",
            "lp_loss 0.407779276\n",
            "lp_loss 0.625287652\n",
            "lp_loss 0.0419238135\n",
            "lp_loss 0.084988758\n",
            "lp_loss 0.059412878\n",
            "lp_loss 0.298959464\n",
            "lp_loss 0.326426834\n",
            "lp_loss 0.20142737\n",
            "lp_loss 0.0186763164\n",
            "lp_loss 0.0259807948\n",
            "lp_loss 0.0100635458\n",
            "lp_loss 0.465891063\n",
            "lp_loss 0.423513234\n",
            "lp_loss 1.25785899\n",
            "lp_loss 0.0661983863\n",
            "lp_loss 0.480273813\n",
            "lp_loss 0.218883321\n",
            "lp_loss 0.13650994\n",
            "lp_loss 0.155908152\n",
            "lp_loss 0.781996906\n",
            "lp_loss 0.0308708251\n",
            "lp_loss 1.66181433\n",
            "lp_loss 0.114846423\n",
            "lp_loss 0.126417369\n",
            "lp_loss 1.61861229\n",
            "lp_loss 0.329302967\n",
            "lp_loss 0.288514078\n",
            "lp_loss 0.112312913\n",
            "lp_loss 0.21398\n",
            "lp_loss 0.111332595\n",
            "lp_loss 0.195388034\n",
            "lp_loss 0.0701393932\n",
            "lp_loss 0.0279560033\n",
            "lp_loss 0.712185383\n",
            "lp_loss 0.726378083\n",
            "lp_loss 0.103149809\n",
            "lp_loss 0.639152825\n",
            "lp_loss 0.175854623\n",
            "lp_loss 0.26678583\n",
            "lp_loss 0.126640379\n",
            "2020-01-30 19:36:02.076735\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.906161129\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 7497\n",
            "label_prediction_accuracy - Target: 0.209090903\n",
            "Beginning of epoch: 29\n",
            "lp_loss 0.279106438\n",
            "lp_loss 0.0121168643\n",
            "lp_loss 0.0594105\n",
            "lp_loss 0.0947007686\n",
            "lp_loss 0.423967451\n",
            "lp_loss 0.258543\n",
            "lp_loss 0.171134681\n",
            "lp_loss 0.0954836607\n",
            "lp_loss 0.165510654\n",
            "lp_loss 0.350929886\n",
            "lp_loss 0.3348611\n",
            "lp_loss 0.773395419\n",
            "lp_loss 0.0663674772\n",
            "lp_loss 0.559004605\n",
            "lp_loss 0.26243192\n",
            "lp_loss 0.132953331\n",
            "lp_loss 0.0824201703\n",
            "lp_loss 0.0491864122\n",
            "lp_loss 1.83095098\n",
            "lp_loss 0.150321066\n",
            "lp_loss 0.83963269\n",
            "lp_loss 0.129016548\n",
            "lp_loss 0.00581556605\n",
            "lp_loss 0.101989508\n",
            "lp_loss 0.0604511723\n",
            "lp_loss 0.134437308\n",
            "lp_loss 0.00155257026\n",
            "lp_loss 1.09195435\n",
            "lp_loss 0.0473259501\n",
            "lp_loss 5.14543295\n",
            "lp_loss 0.0755803734\n",
            "lp_loss 0.505419552\n",
            "lp_loss 0.341757953\n",
            "lp_loss 1.64331818\n",
            "lp_loss 0.59592545\n",
            "lp_loss 1.06097865\n",
            "lp_loss 0.0243160184\n",
            "lp_loss 0.43741864\n",
            "lp_loss 0.0360825509\n",
            "lp_loss 0.612558\n",
            "lp_loss 0.134000257\n",
            "lp_loss 0.056948334\n",
            "lp_loss 2.39471936\n",
            "lp_loss 0.209383339\n",
            "lp_loss 0.429285347\n",
            "lp_loss 0.149720564\n",
            "lp_loss 0.727293849\n",
            "lp_loss 0.0220866594\n",
            "lp_loss 0.0581401959\n",
            "lp_loss 0.508583069\n",
            "lp_loss 0.0814784616\n",
            "lp_loss 0.245473936\n",
            "lp_loss 1.20618367\n",
            "lp_loss 0.269900471\n",
            "lp_loss 0.547111094\n",
            "lp_loss 1.57610893\n",
            "lp_loss 0.1105479\n",
            "lp_loss 0.0232303049\n",
            "lp_loss 0.0363748297\n",
            "lp_loss 0.135252208\n",
            "lp_loss 0.16326268\n",
            "lp_loss 0.554771423\n",
            "lp_loss 0.583242297\n",
            "lp_loss 1.22003782\n",
            "lp_loss 0.648116887\n",
            "lp_loss 0.305811644\n",
            "lp_loss 0.502801239\n",
            "lp_loss 0.395667642\n",
            "lp_loss 0.315746158\n",
            "lp_loss 0.203621119\n",
            "lp_loss 0.397386968\n",
            "lp_loss 0.156253397\n",
            "lp_loss 0.0760313869\n",
            "lp_loss 0.012719579\n",
            "lp_loss 0.818622589\n",
            "lp_loss 0.0610063672\n",
            "lp_loss 0.312232971\n",
            "lp_loss 0.308652163\n",
            "lp_loss 0.465343654\n",
            "lp_loss 0.118945852\n",
            "lp_loss 0.511602521\n",
            "lp_loss 0.101036884\n",
            "lp_loss 0.0414466932\n",
            "lp_loss 0.320263803\n",
            "lp_loss 0.323725164\n",
            "lp_loss 0.502536058\n",
            "lp_loss 0.199667841\n",
            "lp_loss 0.0112614641\n",
            "lp_loss 0.136273786\n",
            "lp_loss 0.436261803\n",
            "lp_loss 0.266688615\n",
            "lp_loss 0.336758941\n",
            "lp_loss 0.54643631\n",
            "lp_loss 0.288951606\n",
            "lp_loss 0.0775778368\n",
            "lp_loss 0.0263403915\n",
            "lp_loss 0.0645673126\n",
            "lp_loss 0.135287285\n",
            "lp_loss 0.292562395\n",
            "lp_loss 1.54140615\n",
            "lp_loss 0.190660879\n",
            "lp_loss 0.905476868\n",
            "lp_loss 0.36722818\n",
            "lp_loss 0.0985197723\n",
            "lp_loss 0.551611245\n",
            "lp_loss 0.481500477\n",
            "lp_loss 0.00946510769\n",
            "lp_loss 0.180325419\n",
            "lp_loss 0.158838585\n",
            "lp_loss 0.608948112\n",
            "lp_loss 1.83697629\n",
            "lp_loss 1.70243096\n",
            "lp_loss 0.373940557\n",
            "lp_loss 0.096946463\n",
            "lp_loss 0.967052639\n",
            "lp_loss 2.0689311\n",
            "lp_loss 0.149238974\n",
            "lp_loss 0.13773641\n",
            "lp_loss 0.189101905\n",
            "lp_loss 0.0695156083\n",
            "lp_loss 0.8113904\n",
            "lp_loss 0.294513702\n",
            "lp_loss 0.384275734\n",
            "lp_loss 0.0426941626\n",
            "lp_loss 0.777546465\n",
            "lp_loss 0.0463222861\n",
            "lp_loss 0.198881358\n",
            "lp_loss 0.101954386\n",
            "lp_loss 0.310090929\n",
            "lp_loss 0.286747098\n",
            "lp_loss 1.72767484\n",
            "lp_loss 0.0841537118\n",
            "lp_loss 0.516517699\n",
            "lp_loss 0.0246081576\n",
            "lp_loss 0.0470703803\n",
            "lp_loss 0.030657405\n",
            "lp_loss 0.307911187\n",
            "lp_loss 0.0866255388\n",
            "lp_loss 0.0937091485\n",
            "lp_loss 0.241456583\n",
            "lp_loss 0.283752769\n",
            "lp_loss 1.22024441\n",
            "lp_loss 0.161868736\n",
            "lp_loss 0.0125853941\n",
            "lp_loss 0.206787542\n",
            "lp_loss 0.302831829\n",
            "lp_loss 0.116260387\n",
            "lp_loss 0.0882261172\n",
            "lp_loss 0.632739246\n",
            "lp_loss 0.674176931\n",
            "lp_loss 0.578712106\n",
            "lp_loss 0.407719702\n",
            "lp_loss 0.12494912\n",
            "lp_loss 0.0764279\n",
            "lp_loss 0.27427572\n",
            "lp_loss 0.11301358\n",
            "lp_loss 0.196125314\n",
            "lp_loss 0.00307648722\n",
            "lp_loss 0.688282847\n",
            "lp_loss 0.484893799\n",
            "lp_loss 0.120375432\n",
            "lp_loss 0.0332951918\n",
            "lp_loss 0.147191167\n",
            "lp_loss 1.14641619\n",
            "lp_loss 0.147043779\n",
            "lp_loss 0.0158332586\n",
            "lp_loss 0.565843344\n",
            "lp_loss 0.0262168385\n",
            "lp_loss 0.455613911\n",
            "lp_loss 0.40686661\n",
            "lp_loss 0.308584183\n",
            "lp_loss 0.0395946428\n",
            "lp_loss 0.0696986839\n",
            "lp_loss 0.553926706\n",
            "lp_loss 0.0250050761\n",
            "lp_loss 0.441954315\n",
            "lp_loss 0.197960898\n",
            "lp_loss 0.710356116\n",
            "lp_loss 0.13694787\n",
            "lp_loss 0.042759411\n",
            "lp_loss 0.973487854\n",
            "lp_loss 0.0611256547\n",
            "lp_loss 0.229206\n",
            "lp_loss 0.388656676\n",
            "lp_loss 0.129096419\n",
            "lp_loss 0.0646094158\n",
            "lp_loss 0.675793767\n",
            "lp_loss 0.05054\n",
            "lp_loss 0.0507032461\n",
            "lp_loss 0.965803921\n",
            "lp_loss 0.145042896\n",
            "lp_loss 0.137423202\n",
            "lp_loss 0.46337074\n",
            "lp_loss 0.267960161\n",
            "lp_loss 0.168138251\n",
            "lp_loss 0.688971519\n",
            "lp_loss 0.020929087\n",
            "lp_loss 0.781074524\n",
            "lp_loss 0.173808858\n",
            "lp_loss 0.0508208349\n",
            "lp_loss 1.0271666\n",
            "lp_loss 0.140021205\n",
            "lp_loss 0.607051313\n",
            "lp_loss 0.0560164675\n",
            "lp_loss 0.110140398\n",
            "lp_loss 0.205777377\n",
            "lp_loss 1.30662251\n",
            "lp_loss 0.0905004293\n",
            "lp_loss 0.321913034\n",
            "lp_loss 0.0617928728\n",
            "lp_loss 0.114060916\n",
            "2020-01-30 19:36:14.656149\n",
            "testing\n",
            "label_prediction_accuracy - Source:  0.883412302\n",
            "domain_classification_accuracy: 0\n",
            "label_prediction_accuracy - Test: 0 7708\n",
            "label_prediction_accuracy - Target: 0.25151515\n",
            "Beginning of epoch: 30\n",
            "lp_loss 0.550906718\n",
            "lp_loss 0.0782294199\n",
            "lp_loss 0.00269931275\n",
            "lp_loss 0.0642875433\n",
            "lp_loss 0.0214648284\n",
            "lp_loss 0.858821273\n",
            "lp_loss 0.0101930248\n",
            "lp_loss 0.00530683342\n",
            "lp_loss 1.61720312\n",
            "lp_loss 0.0229732487\n",
            "lp_loss 0.723713577\n",
            "lp_loss 0.189303383\n",
            "lp_loss 0.275845706\n",
            "lp_loss 0.0543771274\n",
            "lp_loss 0.0416092239\n",
            "lp_loss 0.12342988\n",
            "lp_loss 0.364080131\n",
            "lp_loss 0.2266635\n",
            "lp_loss 0.0884644091\n",
            "lp_loss 0.168027714\n",
            "lp_loss 0.0707200542\n",
            "lp_loss 0.22938168\n",
            "lp_loss 1.08301127\n",
            "lp_loss 0.0891959518\n",
            "lp_loss 1.6416918\n",
            "lp_loss 0.141532719\n",
            "lp_loss 0.206467196\n",
            "lp_loss 0.0492346771\n",
            "lp_loss 0.0662096\n",
            "lp_loss 0.021552477\n",
            "lp_loss 0.896807671\n",
            "lp_loss 0.0944087282\n",
            "lp_loss 0.731864274\n",
            "lp_loss 1.82012975\n",
            "lp_loss 0.100158788\n",
            "lp_loss 0.194938168\n",
            "lp_loss 0.0531088\n",
            "lp_loss 0.148309141\n",
            "lp_loss 0.851516545\n",
            "lp_loss 0.327662408\n",
            "lp_loss 0.137043685\n",
            "lp_loss 0.125773042\n",
            "lp_loss 0.256082833\n",
            "lp_loss 0.270900726\n",
            "lp_loss 0.540935874\n",
            "lp_loss 0.295743644\n",
            "lp_loss 0.186575249\n",
            "lp_loss 0.434174061\n",
            "lp_loss 0.168210432\n",
            "lp_loss 0.210784525\n",
            "lp_loss 0.117549837\n",
            "lp_loss 0.34627074\n",
            "lp_loss 0.26485002\n",
            "lp_loss 0.0643981844\n",
            "lp_loss 1.55229855\n",
            "lp_loss 0.547179103\n",
            "lp_loss 0.106577158\n",
            "lp_loss 0.0835652202\n",
            "lp_loss 0.166403338\n",
            "lp_loss 0.973495603\n",
            "lp_loss 0.683994472\n",
            "lp_loss 1.38995719\n",
            "lp_loss 0.150456578\n",
            "lp_loss 0.0264047477\n",
            "lp_loss 0.224307463\n",
            "lp_loss 0.0376871414\n",
            "lp_loss 0.0865457281\n",
            "lp_loss 0.507819\n",
            "lp_loss 0.429527581\n",
            "lp_loss 0.113113366\n",
            "lp_loss 0.186288327\n",
            "lp_loss 0.101061799\n",
            "lp_loss 0.174439013\n",
            "lp_loss 0.174146667\n",
            "lp_loss 0.133251473\n",
            "lp_loss 0.0504432619\n",
            "lp_loss 0.445971429\n",
            "lp_loss 0.085010685\n",
            "lp_loss 0.913076043\n",
            "lp_loss 0.237198278\n",
            "lp_loss 0.0188566577\n",
            "lp_loss 0.0806422532\n",
            "lp_loss 0.263244718\n",
            "lp_loss 0.476499498\n",
            "lp_loss 0.156319037\n",
            "lp_loss 0.0939702243\n",
            "lp_loss 0.153563708\n",
            "lp_loss 0.182658374\n",
            "lp_loss 0.237840503\n",
            "lp_loss 0.767124355\n",
            "lp_loss 0.815761864\n",
            "lp_loss 0.0983897224\n",
            "lp_loss 0.404503673\n",
            "lp_loss 0.610254288\n",
            "lp_loss 0.354215622\n",
            "lp_loss 0.354414612\n",
            "lp_loss 0.587539375\n",
            "lp_loss 0.180422127\n",
            "lp_loss 0.0699166\n",
            "lp_loss 0.0389812551\n",
            "lp_loss 0.131689936\n",
            "lp_loss 0.114181682\n",
            "lp_loss 0.456723362\n",
            "lp_loss 0.0268924683\n",
            "lp_loss 0.161677271\n",
            "lp_loss 0.394797742\n",
            "lp_loss 0.0682410598\n",
            "lp_loss 0.932882786\n",
            "lp_loss 0.714291394\n",
            "lp_loss 0.153879017\n",
            "lp_loss 0.0542806759\n",
            "lp_loss 0.0763775334\n",
            "lp_loss 0.0569949858\n",
            "lp_loss 1.24367881\n",
            "lp_loss 0.203264669\n",
            "lp_loss 1.15459228\n",
            "lp_loss 0.145639256\n",
            "lp_loss 0.151892737\n",
            "lp_loss 0.0930921286\n",
            "lp_loss 0.416277498\n",
            "lp_loss 0.161793619\n",
            "lp_loss 0.0293552689\n",
            "lp_loss 0.0353362933\n",
            "lp_loss 0.168671086\n",
            "lp_loss 0.440610468\n",
            "lp_loss 0.928465188\n",
            "lp_loss 0.161128297\n",
            "lp_loss 0.0588981286\n",
            "lp_loss 0.0785155445\n",
            "lp_loss 0.068311438\n",
            "lp_loss 0.908676744\n",
            "lp_loss 0.139958814\n",
            "lp_loss 0.0273622684\n",
            "lp_loss 0.609779358\n",
            "lp_loss 0.650827348\n",
            "lp_loss 0.151852071\n",
            "lp_loss 0.283279926\n",
            "lp_loss 0.667979121\n",
            "lp_loss 0.0803938583\n",
            "lp_loss 0.806501031\n",
            "lp_loss 0.249219969\n",
            "lp_loss 0.325882405\n",
            "lp_loss 0.935656726\n",
            "lp_loss 0.543661594\n",
            "lp_loss 0.0435922705\n",
            "lp_loss 0.886479855\n",
            "lp_loss 0.0970071\n",
            "lp_loss 0.558458567\n",
            "lp_loss 0.208703756\n",
            "lp_loss 0.16753009\n",
            "lp_loss 0.0594273806\n",
            "lp_loss 0.14182283\n",
            "lp_loss 0.0979317501\n",
            "lp_loss 0.153971344\n",
            "lp_loss 0.735488057\n",
            "lp_loss 2.9218812\n",
            "lp_loss 0.0310365744\n",
            "lp_loss 0.155898109\n",
            "lp_loss 0.605517268\n",
            "lp_loss 0.032921575\n",
            "lp_loss 0.122213319\n",
            "lp_loss 0.330471605\n",
            "lp_loss 0.337904364\n",
            "lp_loss 0.0414033905\n",
            "lp_loss 0.18934162\n",
            "lp_loss 0.00545445736\n",
            "lp_loss 0.0784479\n",
            "lp_loss 0.0374862924\n",
            "lp_loss 0.107673548\n",
            "lp_loss 0.355586648\n",
            "lp_loss 0.335486472\n",
            "lp_loss 0.426904589\n",
            "lp_loss 0.530887783\n",
            "lp_loss 0.524072409\n",
            "lp_loss 0.67695868\n",
            "lp_loss 0.229103372\n",
            "lp_loss 0.655523181\n",
            "lp_loss 0.24659276\n",
            "lp_loss 0.227734566\n",
            "lp_loss 0.109584376\n",
            "lp_loss 0.0669835955\n",
            "lp_loss 2.15907645\n",
            "lp_loss 0.163514331\n",
            "lp_loss 0.121427938\n",
            "lp_loss 0.545611739\n",
            "lp_loss 0.177609131\n",
            "lp_loss 0.0347361192\n",
            "lp_loss 0.0628465638\n",
            "lp_loss 0.0740190446\n",
            "lp_loss 0.179365799\n",
            "lp_loss 0.199008614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-229-06415867f82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsampling\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdataset_crazy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-228-4e9b8a4d72d5>\u001b[0m in \u001b[0;36mtrain_basic\u001b[0;34m(model_to_train, model_fe, dataset, batch_size, epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mmodel_to_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#if (counter % 10) == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkJs40tpaGJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swLvau_olPUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}